{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/olonok69/LLM_Notebooks/blob/main/ml_tricks/colab/colab_connect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"ubgiAABGmadO"},"source":["# This Colab notebook is ment to be executed for using the GPU units in Colab\n","The idea is to remotely execute the repo files (classes, main, etc)"]},{"cell_type":"markdown","metadata":{"id":"Kc3SGLPSX_7E"},"source":["# 0: Before starting, verifiy that: **After pulling the repo, you have copied the .env file into the Github repo !**"]},{"cell_type":"markdown","metadata":{"id":"r0sG1QyylCkW"},"source":["# 1 Mount Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16552,"status":"ok","timestamp":1755626224063,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"w69hWB_qkwLI","outputId":"13cf7a87-fe7c-46d0-f5e7-4b67488097ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"FPK232yxlHD1"},"source":["# 2 config Git"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":174,"status":"ok","timestamp":1755626224225,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"GradLm7NkxKN"},"outputs":[],"source":["# !git config --global user.name \"zbotta\"\n","# !git config --global user.email \"zbotta@proton.me\"\n","\n","!git config --global user.name \"SamdGuizani\"\n","!git config --global user.email \"samd.guizani@gmail.com\""]},{"cell_type":"markdown","metadata":{"id":"tQRJVtrHynSw"},"source":["## RUN THIS CELL ONLY ONCE!\n","To clone the Github repo"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":563,"status":"ok","timestamp":1755626224792,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"E1otG_64l1Qu"},"outputs":[],"source":["from google.colab import userdata\n","# github_token = userdata.get('zbotta_token')\n","github_token = userdata.get('GitHub_Samd_ReportAgent_GoogleColab')\n","\n","token = github_token\n","username = \"zbotta\"\n","repo = 'reportingAgent'\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":908,"status":"ok","timestamp":1755626225662,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"PQgo_qSExuXm","outputId":"17bee15a-e6f0-4dd1-d36c-7f2c9d1fe84e"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path '/content/drive/MyDrive/GitHub/reportingAgent' already exists and is not an empty directory.\n"]}],"source":["!git clone https://{username}:{github_token}@github.com/{username}/{repo}.git /content/drive/MyDrive/GitHub/{repo}"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1755626225701,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"ze8qK-7nmx_O","outputId":"0c1157a1-bb6b-473b-f9d2-27386518376f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GitHub/reportingAgent\n"]}],"source":["%cd /content/drive/MyDrive/GitHub/{repo}"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"kVgHJTXrHLIX","executionInfo":{"status":"ok","timestamp":1755626225705,"user_tz":-120,"elapsed":2,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}}},"outputs":[],"source":["#!git remote set-url origin https://{username}:{github_token}@github.com/{username}/{repo}.git"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"0Rwp4A70m_2U","executionInfo":{"status":"ok","timestamp":1755626225711,"user_tz":-120,"elapsed":2,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}}},"outputs":[],"source":["#!git remote get-url origin"]},{"cell_type":"markdown","metadata":{"id":"q0fNz_r7m4UG"},"source":["# Use git commands"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31004,"status":"ok","timestamp":1755626256717,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"ybZIZbg2-qhU","outputId":"22024eea-9380-4b45-9471-8922f1a8d5cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["M\tPoC/PoC_00_Setup and GitHub management.ipynb\n","D\tPoC/PoC_Prompt and report gen.ipynb\n","M\tPoC/reportAgent-remote_Samd.ipynb\n","Already on 'dev'\n","Your branch is up to date with 'origin/dev'.\n"]}],"source":["!git fetch\n","!git checkout dev"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":994,"status":"ok","timestamp":1755626257724,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"g9D7zP_oRsaN","outputId":"9ef7c2b0-d0fd-4114-de20-74fa8d8789da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}],"source":["!git pull"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1755626258444,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"ooqu1-hlm7Af","outputId":"ea3b61cc-dc61-432e-8286-34962b8f89eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["On branch dev\n","Your branch is up to date with 'origin/dev'.\n","\n","Changes not staged for commit:\n","  (use \"git add/rm <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   PoC/PoC_00_Setup and GitHub management.ipynb\u001b[m\n","\t\u001b[31mdeleted:    PoC/PoC_Prompt and report gen.ipynb\u001b[m\n","\t\u001b[31mmodified:   PoC/reportAgent-remote_Samd.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mPoC/Archive/\u001b[m\n","\t\u001b[31mPoC/python_env_setup.sh\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}],"source":["!git status"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1755626258488,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"BsN8-zMZ8Z-n"},"outputs":[],"source":["# !git push origin dev\n"]},{"cell_type":"markdown","metadata":{"id":"nXz98pxKo8oH"},"source":["# Using project scripts\n","\n","Reference : [Importing python library from Drive](https://colab.research.google.com/drive/12qC2abKAIAlUM_jNAokGlooKY-idbSxi#scrollTo=prUMpfLaB-D7)"]},{"cell_type":"markdown","metadata":{"id":"mvLEUb7VzVD0"},"source":["## Install project dependencies\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1755626258515,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"S6sPDJjVSHQf","outputId":"0f88a76a-b91b-4ee5-ca8b-5acccf8a7b2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GitHub/reportingAgent\n"]}],"source":["%cd /content/drive/MyDrive/GitHub/{repo}"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-lZSS9qFzSLk","outputId":"42d9f419-56b4-4a4d-f086-3223c2107134","collapsed":true,"executionInfo":{"status":"ok","timestamp":1755626295653,"user_tz":-120,"elapsed":37136,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: absl-py~=1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 1)) (1.4.0)\n","Requirement already satisfied: aiohappyeyeballs~=2.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 2)) (2.6.1)\n","Requirement already satisfied: aiohttp~=3.12.15 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 3)) (3.12.15)\n","Requirement already satisfied: aiosignal~=1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 4)) (1.4.0)\n","Requirement already satisfied: annotated-types~=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 5)) (0.7.0)\n","Requirement already satisfied: anyio~=4.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 6)) (4.10.0)\n","Requirement already satisfied: attrs~=25.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 7)) (25.3.0)\n","Requirement already satisfied: audioread~=3.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 8)) (3.0.1)\n","Collecting bert-score~=0.3.13 (from -r requirements_colab.txt (line 9))\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: certifi~=2025.8.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 10)) (2025.8.3)\n","Requirement already satisfied: charset-normalizer~=3.4.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 11)) (3.4.3)\n","Requirement already satisfied: click~=8.2.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 12)) (8.2.1)\n","Requirement already satisfied: cloudpickle~=3.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 13)) (3.1.1)\n","Collecting colorama~=0.4.6 (from -r requirements_colab.txt (line 14))\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: contourpy~=1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 15)) (1.3.3)\n","Requirement already satisfied: cycler~=0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 16)) (0.12.1)\n","Requirement already satisfied: datasets~=4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 17)) (4.0.0)\n","Requirement already satisfied: dill~=0.3.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 18)) (0.3.8)\n","Requirement already satisfied: distributed~=2025.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 19)) (2025.5.0)\n","Collecting diskcache~=5.6.3 (from -r requirements_colab.txt (line 20))\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: distro~=1.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 21)) (1.9.0)\n","Requirement already satisfied: docstring_parser~=0.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 22)) (0.17.0)\n","Requirement already satisfied: docutils~=0.21.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 23)) (0.21.2)\n","Collecting dotenv~=0.9.9 (from -r requirements_colab.txt (line 24))\n","  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n","Requirement already satisfied: et_xmlfile~=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 25)) (2.0.0)\n","Collecting evaluate~=0.4.5 (from -r requirements_colab.txt (line 26))\n","  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: Farama-Notifications~=0.0.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 27)) (0.0.4)\n","Requirement already satisfied: fastapi~=0.116.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 28)) (0.116.1)\n","Collecting filelock~=3.18.0 (from -r requirements_colab.txt (line 29))\n","  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: fonttools~=4.59.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 30)) (4.59.1)\n","Requirement already satisfied: frozenlist~=1.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 31)) (1.7.0)\n","Requirement already satisfied: fsspec~=2025.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 32)) (2025.3.0)\n","Collecting genson~=1.3.0 (from -r requirements_colab.txt (line 33))\n","  Downloading genson-1.3.0-py3-none-any.whl.metadata (28 kB)\n","Collecting groq~=0.26.0 (from -r requirements_colab.txt (line 34))\n","  Downloading groq-0.26.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: h11~=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 35)) (0.16.0)\n","Requirement already satisfied: httpcore~=1.0.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 36)) (1.0.9)\n","Requirement already satisfied: httpx~=0.28.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 37)) (0.28.1)\n","Requirement already satisfied: huggingface-hub~=0.34.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 38)) (0.34.4)\n","Requirement already satisfied: idna~=3.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 39)) (3.10)\n","Requirement already satisfied: iniconfig~=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 40)) (2.1.0)\n","Collecting instructor~=1.10.0 (from -r requirements_colab.txt (line 41))\n","  Downloading instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n","Collecting interegular~=0.3.3 (from -r requirements_colab.txt (line 42))\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Collecting iso3166~=2.1.1 (from -r requirements_colab.txt (line 43))\n","  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: Jinja2~=3.1.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 44)) (3.1.6)\n","Requirement already satisfied: jiter~=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 45)) (0.10.0)\n","Requirement already satisfied: joblib~=1.5.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 46)) (1.5.1)\n","Collecting jsonpath-ng~=1.7.0 (from -r requirements_colab.txt (line 47))\n","  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: jsonpickle~=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 48)) (4.1.1)\n","Requirement already satisfied: jsonpointer~=3.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 49)) (3.0.0)\n","Requirement already satisfied: jsonschema~=4.25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 50)) (4.25.0)\n","Requirement already satisfied: jsonschema-specifications~=2025.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 51)) (2025.4.1)\n","Requirement already satisfied: kiwisolver~=1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 52)) (1.4.9)\n","Collecting lark~=1.2.2 (from -r requirements_colab.txt (line 53))\n","  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: markdown-it-py~=4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 54)) (4.0.0)\n","Requirement already satisfied: MarkupSafe~=3.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 55)) (3.0.2)\n","Requirement already satisfied: matplotlib~=3.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 56)) (3.10.0)\n","Requirement already satisfied: mdurl~=0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 57)) (0.1.2)\n","Requirement already satisfied: mpmath~=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 58)) (1.3.0)\n","Requirement already satisfied: multidict~=6.6.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 59)) (6.6.4)\n","Requirement already satisfied: multiprocess~=0.70.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 60)) (0.70.16)\n","Requirement already satisfied: nest-asyncio~=1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 61)) (1.6.0)\n","Requirement already satisfied: networkx~=3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 62)) (3.5)\n","Requirement already satisfied: nltk~=3.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 63)) (3.9.1)\n","Requirement already satisfied: numpy~=2.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 64)) (2.0.2)\n","Requirement already satisfied: openai~=1.99.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 65)) (1.99.9)\n","Requirement already satisfied: openpyxl~=3.1.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 66)) (3.1.5)\n","Collecting outlines~=1.1.1 (from -r requirements_colab.txt (line 67))\n","  Downloading outlines-1.1.1-py3-none-any.whl.metadata (27 kB)\n","Collecting outlines_core~=0.1.26 (from -r requirements_colab.txt (line 68))\n","  Downloading outlines_core-0.1.27-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: packaging~=25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 69)) (25.0)\n","Requirement already satisfied: pandas~=2.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 70)) (2.2.2)\n","Requirement already satisfied: pillow~=11.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 71)) (11.3.0)\n","Requirement already satisfied: pluggy~=1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 72)) (1.6.0)\n","Requirement already satisfied: ply~=3.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 73)) (3.11)\n","Requirement already satisfied: propcache~=0.3.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 74)) (0.3.2)\n","Requirement already satisfied: pyarrow~=18.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 75)) (18.1.0)\n","Requirement already satisfied: pydantic~=2.11.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 76)) (2.11.7)\n","Requirement already satisfied: pydantic_core~=2.33.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 77)) (2.33.2)\n","Requirement already satisfied: Pygments~=2.19.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 78)) (2.19.2)\n","Requirement already satisfied: pyparsing~=3.2.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 79)) (3.2.3)\n","Requirement already satisfied: pytest~=8.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 80)) (8.4.1)\n","Requirement already satisfied: python-dateutil~=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 81)) (2.9.0.post0)\n","Requirement already satisfied: python-louvain~=0.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 82)) (0.16)\n","Collecting python-dotenv~=1.1.1 (from -r requirements_colab.txt (line 83))\n","  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: pytz~=2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 84)) (2025.2)\n","Requirement already satisfied: PyYAML~=6.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 85)) (6.0.2)\n","Requirement already satisfied: referencing~=0.36.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 86)) (0.36.2)\n","Requirement already satisfied: regex~=2024.11.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 87)) (2024.11.6)\n","Collecting reportlab>=3.6 (from -r requirements_colab.txt (line 88))\n","  Downloading reportlab-4.4.3-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: requests~=2.32.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 89)) (2.32.3)\n","Requirement already satisfied: rich~=13.9.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 90)) (13.9.4)\n","Collecting rouge_score~=0.1.2 (from -r requirements_colab.txt (line 91))\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: rpds-py~=0.27.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 92)) (0.27.0)\n","Requirement already satisfied: safetensors~=0.6.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 93)) (0.6.2)\n","Requirement already satisfied: scikit-learn~=1.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 94)) (1.6.1)\n","Requirement already satisfied: scipy~=1.16.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 95)) (1.16.1)\n","Requirement already satisfied: sentence-transformers~=5.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 96)) (5.1.0)\n","Requirement already satisfied: shellingham~=1.5.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 97)) (1.5.4)\n","Requirement already satisfied: six~=1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 98)) (1.17.0)\n","Requirement already satisfied: sniffio~=1.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 99)) (1.3.1)\n","Requirement already satisfied: starlette~=0.47.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 100)) (0.47.2)\n","Collecting streamlit>=1.35 (from -r requirements_colab.txt (line 101))\n","  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n","Collecting streamlit-extras>=0.4.0 (from -r requirements_colab.txt (line 102))\n","  Downloading streamlit_extras-0.7.6-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: sympy~=1.13.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 103)) (1.13.3)\n","Requirement already satisfied: tenacity~=9.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 104)) (9.1.2)\n","Requirement already satisfied: threadpoolctl~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 105)) (3.6.0)\n","Requirement already satisfied: tokenizers~=0.21.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 106)) (0.21.4)\n","Requirement already satisfied: torch~=2.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 107)) (2.8.0+cu126)\n","Requirement already satisfied: tqdm~=4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 108)) (4.67.1)\n","Collecting transformers~=4.53.3 (from -r requirements_colab.txt (line 109))\n","  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer~=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 110)) (0.16.0)\n","Requirement already satisfied: typing-inspection~=0.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 111)) (0.4.1)\n","Requirement already satisfied: typing_extensions~=4.14.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 112)) (4.14.1)\n","Requirement already satisfied: tzdata~=2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 113)) (2025.2)\n","Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 114)) (2.5.0)\n","Requirement already satisfied: xxhash~=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 115)) (3.5.0)\n","Requirement already satisfied: yarl~=1.20.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 116)) (1.20.1)\n","Requirement already satisfied: dask==2025.5.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (2025.5.0)\n","Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (1.1.1)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (5.9.5)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (2.4.0)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (3.1.0)\n","Requirement already satisfied: toolz>=0.11.2 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (0.12.1)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (6.4.2)\n","Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (3.0.0)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask==2025.5.0->distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (1.4.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub~=0.34.4->-r requirements_colab.txt (line 38)) (1.1.7)\n","Collecting airportsdata (from outlines~=1.1.1->-r requirements_colab.txt (line 67))\n","  Downloading airportsdata-20250811-py3-none-any.whl.metadata (9.1 kB)\n","Collecting outlines_core~=0.1.26 (from -r requirements_colab.txt (line 68))\n","  Downloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.5.2)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.29.5)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (0.10.2)\n","Collecting watchdog<7,>=2.1.5 (from streamlit>=1.35->-r requirements_colab.txt (line 101))\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (3.1.45)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit>=1.35->-r requirements_colab.txt (line 101))\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Collecting altex>=0.2.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading altex-0.2.0-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: entrypoints>=0.4 in /usr/local/lib/python3.12/dist-packages (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (0.4)\n","Collecting htbuilder>=0.6.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading htbuilder-0.9.0.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting markdownlit>=0.0.7 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading markdownlit-0.0.7-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: plotly>=5.23.0 in /usr/local/lib/python3.12/dist-packages (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (5.24.1)\n","Requirement already satisfied: prometheus-client>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (0.22.1)\n","Collecting snowflake-snowpark-python>=1.30.0 (from snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading snowflake_snowpark_python-1.37.0-py3-none-any.whl.metadata (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting st-annotated-text>=4.0.1 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading st_annotated_text-4.0.2-py3-none-any.whl.metadata (2.4 kB)\n","Collecting st-theme>=1.2.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading st_theme-1.2.3-py3-none-any.whl.metadata (6.9 kB)\n","Collecting streamlit-avatar>=0.1.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_avatar-0.1.3-py3-none-any.whl.metadata (2.1 kB)\n","Collecting streamlit-camera-input-live>=0.2.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting streamlit-card>=1.0.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_card-1.0.2-py3-none-any.whl.metadata (4.0 kB)\n","Collecting streamlit-embedcode>=0.1.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl.metadata (414 bytes)\n","Collecting streamlit-faker>=0.0.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_faker-0.0.4-py3-none-any.whl.metadata (2.1 kB)\n","Collecting streamlit-image-coordinates>=0.1.9 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_image_coordinates-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting streamlit-keyup>=0.2.4 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_keyup-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit-notify>=0.3.1 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_notify-0.3.1-py3-none-any.whl.metadata (3.4 kB)\n","Collecting streamlit-toggle-switch>=1.0.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl.metadata (395 bytes)\n","Collecting streamlit-vertical-slider>=2.5.5 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl.metadata (2.2 kB)\n","Collecting validators>=0.33.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (75.2.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (3.4.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.35->-r requirements_colab.txt (line 101)) (2.1.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35->-r requirements_colab.txt (line 101)) (4.0.12)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (3.8.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (5.4.0)\n","Collecting favicon (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading favicon-0.7.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Collecting pymdown-extensions (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading pymdown_extensions-10.16.1-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from snowflake-snowpark-python>=1.30.0->snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (0.45.1)\n","Collecting snowflake-connector-python<4.0.0,>=3.14.0 (from snowflake-snowpark-python>=1.30.0->snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading snowflake_connector_python-3.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of snowflake-snowpark-python to determine which version is compatible with other requirements. This could take a while.\n","Collecting snowflake-snowpark-python>=1.30.0 (from snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading snowflake_snowpark_python-1.36.0-py3-none-any.whl.metadata (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.35.0-py3-none-any.whl.metadata (150 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.34.0-py3-none-any.whl.metadata (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.4/148.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.33.0-py3-none-any.whl.metadata (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.32.0-py3-none-any.whl.metadata (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.31.1-py3-none-any.whl.metadata (136 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.31.0-py3-none-any.whl.metadata (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is still looking at multiple versions of snowflake-snowpark-python to determine which version is compatible with other requirements. This could take a while.\n","  Downloading snowflake_snowpark_python-1.30.0-py3-none-any.whl.metadata (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting streamlit-extras>=0.4.0 (from -r requirements_colab.txt (line 102))\n","  Downloading streamlit_extras-0.7.5-py3-none-any.whl.metadata (4.2 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading streamlit_extras-0.7.1-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading streamlit_extras-0.7.0-py3-none-any.whl.metadata (3.7 kB)\n","Collecting htbuilder==0.6.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading htbuilder-0.6.2-py3-none-any.whl.metadata (5.9 kB)\n","Collecting plotly==5.23.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading plotly-5.23.0-py3-none-any.whl.metadata (7.3 kB)\n","Collecting prometheus-client==0.20.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting protobuf<7,>=3.20 (from streamlit>=1.35->-r requirements_colab.txt (line 101))\n","  Downloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n","Collecting st-annotated-text==4.0.1 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading st_annotated_text-4.0.1-py3-none-any.whl.metadata (2.2 kB)\n","Collecting streamlit-faker==0.0.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_faker-0.0.3-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit-image-coordinates==0.1.9 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit-keyup==0.2.4 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_keyup-0.2.4-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit>=1.35 (from -r requirements_colab.txt (line 101))\n","  Downloading streamlit-1.37.0-py2.py3-none-any.whl.metadata (8.5 kB)\n","Collecting validators==0.33.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading validators-0.33.0-py3-none-any.whl.metadata (3.8 kB)\n","INFO: pip is looking at multiple versions of streamlit to determine which version is compatible with other requirements. This could take a while.\n","Collecting streamlit-extras>=0.4.0 (from -r requirements_colab.txt (line 102))\n","  Downloading streamlit_extras-0.6.0-py3-none-any.whl.metadata (4.0 kB)\n","Collecting faker (from streamlit-faker>=0.0.3->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading faker-37.5.3-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.0.2)\n","Requirement already satisfied: beautifulsoup4>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from favicon->markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (4.13.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (2.7)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n","Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n","Downloading genson-1.3.0-py3-none-any.whl (21 kB)\n","Downloading groq-0.26.0-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading instructor-1.10.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n","Downloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n","Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines-1.1.1-py3-none-any.whl (100 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.2/343.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n","Downloading reportlab-4.4.3-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_extras-0.6.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n","Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading st_annotated_text-4.0.2-py3-none-any.whl (9.1 kB)\n","Downloading st_theme-1.2.3-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_avatar-0.1.3-py3-none-any.whl (779 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n","Downloading streamlit_card-1.0.2-py3-none-any.whl (680 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n","Downloading streamlit_faker-0.0.4-py3-none-any.whl (14 kB)\n","Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl (7.0 kB)\n","Downloading streamlit_keyup-0.3.0-py3-none-any.whl (7.5 kB)\n","Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_vertical_slider-2.5.5-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading airportsdata-20250811-py3-none-any.whl (912 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading altex-0.2.0-py3-none-any.whl (25 kB)\n","Downloading faker-37.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n","Downloading pymdown_extensions-10.16.1-py3-none-any.whl (266 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: rouge_score, htbuilder\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=1022a24bc48c2e4cc15dc02abb39668b0af525a748c23a6f9d3ee5b925f54588\n","  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n","  Building wheel for htbuilder (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for htbuilder: filename=htbuilder-0.9.0-py3-none-any.whl size=12786 sha256=abd3e1c5f13d20b863500f9b0cc0c84428fa76f85d7ab1cef1d588ea32191000\n","  Stored in directory: /root/.cache/pip/wheels/e3/4e/ff/760211ab527c50cca237ac2c2458fc7614a7d15624cdceb537\n","Successfully built rouge_score htbuilder\n","Installing collected packages: genson, watchdog, validators, reportlab, python-dotenv, pymdown-extensions, lark, jsonpath-ng, iso3166, interegular, htbuilder, filelock, faker, diskcache, colorama, airportsdata, st-annotated-text, rouge_score, pydeck, favicon, dotenv, groq, transformers, outlines_core, instructor, streamlit, outlines, evaluate, bert-score, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, streamlit-avatar, st-theme, altex, streamlit-faker, markdownlit, streamlit-extras\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.19.1\n","    Uninstalling filelock-3.19.1:\n","      Successfully uninstalled filelock-3.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.55.2\n","    Uninstalling transformers-4.55.2:\n","      Successfully uninstalled transformers-4.55.2\n","Successfully installed airportsdata-20250811 altex-0.2.0 bert-score-0.3.13 colorama-0.4.6 diskcache-5.6.3 dotenv-0.9.9 evaluate-0.4.5 faker-37.5.3 favicon-0.7.0 filelock-3.18.0 genson-1.3.0 groq-0.26.0 htbuilder-0.9.0 instructor-1.10.0 interegular-0.3.3 iso3166-2.1.1 jsonpath-ng-1.7.0 lark-1.2.2 markdownlit-0.0.7 outlines-1.1.1 outlines_core-0.1.26 pydeck-0.9.1 pymdown-extensions-10.16.1 python-dotenv-1.1.1 reportlab-4.4.3 rouge_score-0.1.2 st-annotated-text-4.0.2 st-theme-1.2.3 streamlit-1.48.1 streamlit-avatar-0.1.3 streamlit-camera-input-live-0.2.0 streamlit-card-1.0.2 streamlit-embedcode-0.1.2 streamlit-extras-0.6.0 streamlit-faker-0.0.4 streamlit-image-coordinates-0.1.9 streamlit-keyup-0.3.0 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-2.5.5 transformers-4.53.3 validators-0.35.0 watchdog-6.0.0\n"]}],"source":["# !pip install -r requirements.txt\n","!pip install -r requirements_colab.txt"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9618,"status":"ok","timestamp":1755626305328,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"7jbcWB1PGsoj","outputId":"f08c8ff5-6fde-4e94-dfb7-3221343469cf","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"]}],"source":["!pip install --upgrade torch torchvision"]},{"cell_type":"markdown","metadata":{"id":"-2wXabjgzszt"},"source":["## Import a python script from project"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1755626305339,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"a8WjxROAzwUT","outputId":"5a1a8f39-8e27-4b77-bfad-433bbbe08412"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GitHub/reportingAgent\n"]}],"source":["%cd /content/drive/MyDrive/GitHub/{repo}"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":714,"status":"ok","timestamp":1755626306077,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"-oZlOWBODm4M","outputId":"1afdb612-0694-43fd-85b6-1c86f1ce9a0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}],"source":["!git pull"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":774,"status":"ok","timestamp":1755626306858,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"4r_Hif3sXJDN","outputId":"08890d82-ffc7-4f30-b980-18ca061265d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["08/19/2025 17:46:24 - __main__ - INFO - Parameters passed to main script: \n","{'max_workers': [4], 'threaded': False, 'model_id': ['Qwen/Qwen2.5-0.5B-Instruct'], 'prompt_method': ['A', 'B', 'C'], 'dataset_filename': 'pharma_dev_reports_collection.xlsx', 'start_idx': [1], 'end_idx': [1], 'temperature': [0.3, 0.7, 1.0, 1.3], 'top_p': [0.3, 0.6, 0.9], 'top_k': [50], 'max_new_tokens': [300.0], 'do_sample': [True], 'repetition_penalty': [1.0]}\n","08/19/2025 17:46:24 - projectSetup - INFO - Loading device and environment variables:\n","               device=cuda, torch_dtype=torch.float32\n","08/19/2025 17:46:24 - projectSetup - INFO - Loading environment variables from: /content/drive/MyDrive/GitHub/reportingAgent/.env\n","08/19/2025 17:46:24 - evaluate.utils.file_utils - INFO - https://huggingface.co/spaces/evaluate-metric/bertscore/resolve/main/bertscore.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/evaluate/downloads/tmpjp12y1ki\n","08/19/2025 17:46:24 - evaluate.utils.file_utils - INFO - storing https://huggingface.co/spaces/evaluate-metric/bertscore/resolve/main/bertscore.py in cache at /root/.cache/huggingface/evaluate/downloads/2fb1405ec250844307c59b3bad240bb98cf25006711d08add1afcaf365fa5899.a4fc40aee04c356ddb89f55c1f36393b16fa831e9b5a9daa80e5e77cac867d1c.py\n","08/19/2025 17:46:24 - evaluate.utils.file_utils - INFO - creating metadata file for /root/.cache/huggingface/evaluate/downloads/2fb1405ec250844307c59b3bad240bb98cf25006711d08add1afcaf365fa5899.a4fc40aee04c356ddb89f55c1f36393b16fa831e9b5a9daa80e5e77cac867d1c.py\n","08/19/2025 17:46:25 - evaluate.utils.file_utils - INFO - https://huggingface.co/spaces/evaluate-metric/rouge/resolve/main/rouge.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/evaluate/downloads/tmp3z2mvgvi\n","08/19/2025 17:46:25 - evaluate.utils.file_utils - INFO - storing https://huggingface.co/spaces/evaluate-metric/rouge/resolve/main/rouge.py in cache at /root/.cache/huggingface/evaluate/downloads/f33d50f5632af0ef2678cccf7f88df5449118eba1d33c0da28db234521c747d0.a97a122920a4096f714c952a10cffc18e2ef77125c6885353cdfe9ff895ff29f.py\n","08/19/2025 17:46:25 - evaluate.utils.file_utils - INFO - creating metadata file for /root/.cache/huggingface/evaluate/downloads/f33d50f5632af0ef2678cccf7f88df5449118eba1d33c0da28db234521c747d0.a97a122920a4096f714c952a10cffc18e2ef77125c6885353cdfe9ff895ff29f.py\n","08/19/2025 17:46:27 - evaluate.utils.file_utils - INFO - https://huggingface.co/spaces/evaluate-metric/bleu/resolve/main/bleu.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/evaluate/downloads/tmpn7n4tm7z\n","08/19/2025 17:46:27 - evaluate.utils.file_utils - INFO - storing https://huggingface.co/spaces/evaluate-metric/bleu/resolve/main/bleu.py in cache at /root/.cache/huggingface/evaluate/downloads/d0b3308e01108848dfc40221e43f917a9008a497e22f3fea50be57da6bc88625.c5e3521d2a7097f08ecf9e859463a29b2aa1ecdf5d31f312d77fd1a2f38f71c5.py\n","08/19/2025 17:46:27 - evaluate.utils.file_utils - INFO - creating metadata file for /root/.cache/huggingface/evaluate/downloads/d0b3308e01108848dfc40221e43f917a9008a497e22f3fea50be57da6bc88625.c5e3521d2a7097f08ecf9e859463a29b2aa1ecdf5d31f312d77fd1a2f38f71c5.py\n","08/19/2025 17:46:27 - evaluate.utils.file_utils - INFO - https://github.com/tensorflow/nmt/raw/master/nmt/scripts/bleu.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/evaluate/downloads/tmp62k0oli9\n","08/19/2025 17:46:27 - evaluate.utils.file_utils - INFO - storing https://github.com/tensorflow/nmt/raw/master/nmt/scripts/bleu.py in cache at /root/.cache/huggingface/evaluate/downloads/4951487bc22fd428873d4efd0c480ee993ab015bfd5b3c5711d30f6c60bbee00.152c3065402c124a671a3944aec1a7fc305056ce21ebdc009b799235e6001dd9.py\n","08/19/2025 17:46:27 - evaluate.utils.file_utils - INFO - creating metadata file for /root/.cache/huggingface/evaluate/downloads/4951487bc22fd428873d4efd0c480ee993ab015bfd5b3c5711d30f6c60bbee00.152c3065402c124a671a3944aec1a7fc305056ce21ebdc009b799235e6001dd9.py\n","08/19/2025 17:46:28 - evaluate.utils.file_utils - INFO - https://huggingface.co/spaces/evaluate-metric/bleu/resolve/main/tokenizer_13a.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/evaluate/downloads/tmps8_zkz7r\n","08/19/2025 17:46:28 - evaluate.utils.file_utils - INFO - storing https://huggingface.co/spaces/evaluate-metric/bleu/resolve/main/tokenizer_13a.py in cache at /root/.cache/huggingface/evaluate/downloads/0ebd6ae5966249b65996f2e59bc3ba7acddae51ce31eb492a1ea4d2a2115d2d3.a36fe3f59d3bb009ffa47e12967b5aee81c053e90f64df4e43530d1d4e7d4387.py\n","08/19/2025 17:46:28 - evaluate.utils.file_utils - INFO - creating metadata file for /root/.cache/huggingface/evaluate/downloads/0ebd6ae5966249b65996f2e59bc3ba7acddae51ce31eb492a1ea4d2a2115d2d3.a36fe3f59d3bb009ffa47e12967b5aee81c053e90f64df4e43530d1d4e7d4387.py\n","08/19/2025 17:46:28 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0\n","08/19/2025 17:46:28 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n","08/19/2025 17:46:28 - huggingface_hub.file_download - INFO - Downloading './modules.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/952a9b81c0bfd99800fabf352f69c7ccd46c5e43.incomplete'\n","08/19/2025 17:46:28 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/952a9b81c0bfd99800fabf352f69c7ccd46c5e43\n","08/19/2025 17:46:28 - huggingface_hub.file_download - INFO - Downloading './config_sentence_transformers.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/fd1b291129c607e5d49799f87cb219b27f98acdf.incomplete'\n","08/19/2025 17:46:28 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/fd1b291129c607e5d49799f87cb219b27f98acdf\n","08/19/2025 17:46:28 - huggingface_hub.file_download - INFO - Downloading './README.md' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/58d4a9a45664eb9e12de9549c548c09b6134c17f.incomplete'\n","08/19/2025 17:46:28 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/58d4a9a45664eb9e12de9549c548c09b6134c17f\n","08/19/2025 17:46:29 - huggingface_hub.file_download - INFO - Downloading './sentence_bert_config.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/59d594003bf59880a884c574bf88ef7555bb0202.incomplete'\n","08/19/2025 17:46:29 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/59d594003bf59880a884c574bf88ef7555bb0202\n","08/19/2025 17:46:29 - huggingface_hub.file_download - INFO - Downloading 'config.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/72b987fd805cfa2b58c4c8c952b274a11bfd5a00.incomplete'\n","08/19/2025 17:46:29 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/72b987fd805cfa2b58c4c8c952b274a11bfd5a00\n","08/19/2025 17:46:29 - transformers.configuration_utils - INFO - loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json\n","08/19/2025 17:46:29 - transformers.configuration_utils - INFO - Model config BertConfig {\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 384,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 1536,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.53.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","08/19/2025 17:46:34 - huggingface_hub.file_download - INFO - Downloading 'model.safetensors' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/53aa51172d142c89d9012cce15ae4d6cc0ca6895895114379cacb4fab128d9db.incomplete'\n","08/19/2025 17:46:35 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/53aa51172d142c89d9012cce15ae4d6cc0ca6895895114379cacb4fab128d9db\n","08/19/2025 17:46:35 - transformers.modeling_utils - INFO - loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/model.safetensors\n","08/19/2025 17:46:36 - transformers.modeling_utils - INFO - All model checkpoint weights were used when initializing BertModel.\n","\n","08/19/2025 17:46:36 - transformers.modeling_utils - INFO - All the weights of BertModel were initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Downloading 'tokenizer_config.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/c79f2b6a0cea6f4b564fed1938984bace9d30ff0.incomplete'\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/c79f2b6a0cea6f4b564fed1938984bace9d30ff0\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Downloading 'vocab.txt' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938.incomplete'\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Downloading 'tokenizer.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/cb202bfe2e3c98645018a6d12f182a434c9d3e02.incomplete'\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/cb202bfe2e3c98645018a6d12f182a434c9d3e02\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Downloading 'special_tokens_map.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/e7b0375001f109a6b8873d756ad4f7bbb15fbaa5.incomplete'\n","08/19/2025 17:46:36 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/e7b0375001f109a6b8873d756ad4f7bbb15fbaa5\n","08/19/2025 17:46:37 - transformers.tokenization_utils_base - INFO - loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/vocab.txt\n","08/19/2025 17:46:37 - transformers.tokenization_utils_base - INFO - loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer.json\n","08/19/2025 17:46:37 - transformers.tokenization_utils_base - INFO - loading file added_tokens.json from cache at None\n","08/19/2025 17:46:37 - transformers.tokenization_utils_base - INFO - loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/special_tokens_map.json\n","08/19/2025 17:46:37 - transformers.tokenization_utils_base - INFO - loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json\n","08/19/2025 17:46:37 - transformers.tokenization_utils_base - INFO - loading file chat_template.jinja from cache at None\n","08/19/2025 17:46:37 - huggingface_hub.file_download - INFO - Downloading '1_Pooling/config.json' to '/root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/d1514c3162bbe87b343f565fadc62e6c06f04f03.incomplete'\n","08/19/2025 17:46:37 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/blobs/d1514c3162bbe87b343f565fadc62e6c06f04f03\n","08/19/2025 17:46:37 - huggingface_hub.file_download - INFO - Downloading 'config.json' to '/root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/88bc4f74b33a2073abc9a66cb532b889448ac3ed.incomplete'\n","08/19/2025 17:46:37 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/88bc4f74b33a2073abc9a66cb532b889448ac3ed\n","08/19/2025 17:46:37 - transformers.configuration_utils - INFO - loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/snapshots/ce0834f22110de6d9222af7a7a03628121708969/config.json\n","08/19/2025 17:46:37 - transformers.configuration_utils - INFO - Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 384,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 1536,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"sbert_ce_default_activation_function\": \"torch.nn.modules.linear.Identity\",\n","  \"transformers_version\": \"4.53.3\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","08/19/2025 17:46:37 - huggingface_hub.file_download - INFO - Downloading 'model.safetensors' to '/root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/821d1aa69520101d6e0737f78a042ae25b19e5cb9160701909d10434f4aeb0ae.incomplete'\n","08/19/2025 17:46:39 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/821d1aa69520101d6e0737f78a042ae25b19e5cb9160701909d10434f4aeb0ae\n","08/19/2025 17:46:39 - transformers.modeling_utils - INFO - loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/snapshots/ce0834f22110de6d9222af7a7a03628121708969/model.safetensors\n","08/19/2025 17:46:39 - transformers.modeling_utils - INFO - All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","08/19/2025 17:46:39 - transformers.modeling_utils - INFO - All the weights of BertForSequenceClassification were initialized from the model checkpoint at cross-encoder/ms-marco-MiniLM-L6-v2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","08/19/2025 17:46:39 - huggingface_hub.file_download - INFO - Downloading 'tokenizer_config.json' to '/root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/a2435fedfac32b9ad70f052d4f84007730cd3109.incomplete'\n","08/19/2025 17:46:39 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/a2435fedfac32b9ad70f052d4f84007730cd3109\n","08/19/2025 17:46:39 - huggingface_hub.file_download - INFO - Downloading 'vocab.txt' to '/root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938.incomplete'\n","08/19/2025 17:46:39 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938\n","08/19/2025 17:46:39 - huggingface_hub.file_download - INFO - Downloading 'tokenizer.json' to '/root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/688882a79f44442ddc1f60d70334a7ff5df0fb47.incomplete'\n","08/19/2025 17:46:39 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/688882a79f44442ddc1f60d70334a7ff5df0fb47\n","08/19/2025 17:46:40 - huggingface_hub.file_download - INFO - Downloading 'special_tokens_map.json' to '/root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/7520992f25914d962f0e2fd0e0566fc33d19ec59.incomplete'\n","08/19/2025 17:46:40 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/7520992f25914d962f0e2fd0e0566fc33d19ec59\n","08/19/2025 17:46:40 - transformers.tokenization_utils_base - INFO - loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/snapshots/ce0834f22110de6d9222af7a7a03628121708969/vocab.txt\n","08/19/2025 17:46:40 - transformers.tokenization_utils_base - INFO - loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/snapshots/ce0834f22110de6d9222af7a7a03628121708969/tokenizer.json\n","08/19/2025 17:46:40 - transformers.tokenization_utils_base - INFO - loading file added_tokens.json from cache at None\n","08/19/2025 17:46:40 - transformers.tokenization_utils_base - INFO - loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/snapshots/ce0834f22110de6d9222af7a7a03628121708969/special_tokens_map.json\n","08/19/2025 17:46:40 - transformers.tokenization_utils_base - INFO - loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/snapshots/ce0834f22110de6d9222af7a7a03628121708969/tokenizer_config.json\n","08/19/2025 17:46:40 - transformers.tokenization_utils_base - INFO - loading file chat_template.jinja from cache at None\n","08/19/2025 17:46:40 - huggingface_hub.file_download - INFO - Downloading './README.md' to '/root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/4783b64ce66b94c7c387672de541d10678980574.incomplete'\n","08/19/2025 17:46:40 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--cross-encoder--ms-marco-MiniLM-L6-v2/blobs/4783b64ce66b94c7c387672de541d10678980574\n","08/19/2025 17:46:40 - sentence_transformers.cross_encoder.CrossEncoder - INFO - Use pytorch device: cuda:0\n","08/19/2025 17:46:41 - mods.dataHandler - INFO - Dataset loaded from path : /content/drive/MyDrive/GitHub/reportingAgent/app/datasets/pharma_dev_reports_collection.xlsx\n","08/19/2025 17:46:41 - huggingface_hub.file_download - INFO - Downloading 'generation_config.json' to '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/dfc11073787daf1b0f9c0f1499487ab5f4c93738.incomplete'\n","08/19/2025 17:46:41 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/dfc11073787daf1b0f9c0f1499487ab5f4c93738\n","08/19/2025 17:46:41 - transformers.generation.configuration_utils - INFO - loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\n","08/19/2025 17:46:41 - transformers.generation.configuration_utils - INFO - Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"do_sample\": true,\n","  \"eos_token_id\": [\n","    151645,\n","    151643\n","  ],\n","  \"pad_token_id\": 151643,\n","  \"repetition_penalty\": 1.1,\n","  \"temperature\": 0.7,\n","  \"top_k\": 20,\n","  \"top_p\": 0.8\n","}\n","\n","08/19/2025 17:46:41 - mods.modelLoader - WARNING - No attribute frequency_penalty found in GenerationConfig, for model_id=Qwen/Qwen2.5-0.5B-Instruct\n","08/19/2025 17:46:41 - mods.modelLoader - WARNING - No attribute presence_penalty found in GenerationConfig, for model_id=Qwen/Qwen2.5-0.5B-Instruct\n","08/19/2025 17:46:41 - mods.modelLoader - WARNING - No attribute stop found in GenerationConfig, for model_id=Qwen/Qwen2.5-0.5B-Instruct\n","08/19/2025 17:46:41 - mods.modelLoader - INFO - The default parameters of the model are:\n"," {'temperature': 0.7, 'top_k': 20, 'top_p': 0.8, 'repetition_penalty': 1.1, 'do_sample': True}\n","08/19/2025 17:46:41 - mods.testBench - INFO - Test Bench loaded\n","08/19/2025 17:46:41 - huggingface_hub.file_download - INFO - Downloading 'tokenizer_config.json' to '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/07bfe0640cb5a0037f9322287fbfc682806cf672.incomplete'\n","08/19/2025 17:46:42 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/07bfe0640cb5a0037f9322287fbfc682806cf672\n","08/19/2025 17:46:42 - huggingface_hub.file_download - INFO - Downloading 'vocab.json' to '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/4783fe10ac3adce15ac8f358ef5462739852c569.incomplete'\n","08/19/2025 17:46:42 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/4783fe10ac3adce15ac8f358ef5462739852c569\n","08/19/2025 17:46:42 - huggingface_hub.file_download - INFO - Downloading 'merges.txt' to '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0.incomplete'\n","08/19/2025 17:46:43 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0\n","08/19/2025 17:46:43 - huggingface_hub.file_download - INFO - Downloading 'tokenizer.json' to '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/443909a61d429dff23010e5bddd28ff530edda00.incomplete'\n","08/19/2025 17:46:43 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/443909a61d429dff23010e5bddd28ff530edda00\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/vocab.json\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/merges.txt\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/tokenizer.json\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - loading file added_tokens.json from cache at None\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - loading file special_tokens_map.json from cache at None\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/tokenizer_config.json\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - loading file chat_template.jinja from cache at None\n","08/19/2025 17:46:44 - transformers.tokenization_utils_base - INFO - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","08/19/2025 17:46:45 - huggingface_hub.file_download - INFO - Downloading 'config.json' to '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/0dbb161213629a23f0fc00ef286e6b1e366d180f.incomplete'\n","08/19/2025 17:46:45 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/0dbb161213629a23f0fc00ef286e6b1e366d180f\n","08/19/2025 17:46:45 - transformers.configuration_utils - INFO - loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/config.json\n","08/19/2025 17:46:45 - transformers.configuration_utils - INFO - Model config Qwen2Config {\n","  \"architectures\": [\n","    \"Qwen2ForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151645,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 896,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4864,\n","  \"layer_types\": [\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\",\n","    \"full_attention\"\n","  ],\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 21,\n","  \"model_type\": \"qwen2\",\n","  \"num_attention_heads\": 14,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 2,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": null,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.53.3\",\n","  \"use_cache\": true,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151936\n","}\n","\n","08/19/2025 17:46:45 - huggingface_hub.file_download - INFO - Downloading 'model.safetensors' to '/root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/fdf756fa7fcbe7404d5c60e26bff1a0c8b8aa1f72ced49e7dd0210fe288fb7fe.incomplete'\n","08/19/2025 17:46:56 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/blobs/fdf756fa7fcbe7404d5c60e26bff1a0c8b8aa1f72ced49e7dd0210fe288fb7fe\n","08/19/2025 17:46:56 - transformers.modeling_utils - INFO - loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/model.safetensors\n","08/19/2025 17:46:56 - transformers.modeling_utils - INFO - Instantiating Qwen2ForCausalLM model under default dtype torch.float32.\n","08/19/2025 17:46:56 - transformers.generation.configuration_utils - INFO - Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151645\n","}\n","\n","08/19/2025 17:46:57 - transformers.modeling_utils - INFO - All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n","\n","08/19/2025 17:46:57 - transformers.modeling_utils - INFO - All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-0.5B-Instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n","08/19/2025 17:46:57 - transformers.generation.configuration_utils - INFO - loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\n","08/19/2025 17:46:57 - transformers.generation.configuration_utils - INFO - Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"do_sample\": true,\n","  \"eos_token_id\": [\n","    151645,\n","    151643\n","  ],\n","  \"pad_token_id\": 151643,\n","  \"repetition_penalty\": 1.1,\n","  \"temperature\": 0.7,\n","  \"top_k\": 20,\n","  \"top_p\": 0.8\n","}\n","\n","08/19/2025 17:46:59 - transformers.generation.configuration_utils - INFO - loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\n","08/19/2025 17:46:59 - transformers.generation.configuration_utils - INFO - Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"do_sample\": true,\n","  \"eos_token_id\": [\n","    151645,\n","    151643\n","  ],\n","  \"pad_token_id\": 151643,\n","  \"repetition_penalty\": 1.1,\n","  \"temperature\": 0.7,\n","  \"top_k\": 20,\n","  \"top_p\": 0.8\n","}\n","\n","08/19/2025 17:46:59 - mods.testBench - INFO - Results file is expected to have 36 rows.\n","08/19/2025 17:46:59 - mods.testBench - INFO - Starting experiment in TestBench with experiment_id=Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-46-59\n","08/19/2025 17:46:59 - transformers.generation.configuration_utils - INFO - loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\n","08/19/2025 17:46:59 - transformers.generation.configuration_utils - INFO - Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"do_sample\": true,\n","  \"eos_token_id\": [\n","    151645,\n","    151643\n","  ],\n","  \"pad_token_id\": 151643,\n","  \"repetition_penalty\": 1.1,\n","  \"temperature\": 0.7,\n","  \"top_k\": 20,\n","  \"top_p\": 0.8\n","}\n","\n","08/19/2025 17:46:59 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:47:07 - huggingface_hub.file_download - INFO - Downloading 'tokenizer_config.json' to '/root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/e5c73d8a50df1f56fb5b0b8002d7cf4010afdccb.incomplete'\n","08/19/2025 17:47:07 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/e5c73d8a50df1f56fb5b0b8002d7cf4010afdccb\n","08/19/2025 17:47:08 - huggingface_hub.file_download - INFO - Downloading 'config.json' to '/root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/150367d8744161cd17b3f6462a14f3a9648752da.incomplete'\n","08/19/2025 17:47:08 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/150367d8744161cd17b3f6462a14f3a9648752da\n","08/19/2025 17:47:08 - transformers.configuration_utils - INFO - loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n","08/19/2025 17:47:08 - transformers.configuration_utils - INFO - Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.53.3\",\n","  \"vocab_size\": 30522\n","}\n","\n","08/19/2025 17:47:08 - huggingface_hub.file_download - INFO - Downloading 'vocab.txt' to '/root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938.incomplete'\n","08/19/2025 17:47:09 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938\n","08/19/2025 17:47:09 - huggingface_hub.file_download - INFO - Downloading 'tokenizer.json' to '/root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/949a6f013d67eb8a5b4b5b46026217b888021b88.incomplete'\n","08/19/2025 17:47:09 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/949a6f013d67eb8a5b4b5b46026217b888021b88\n","08/19/2025 17:47:09 - transformers.tokenization_utils_base - INFO - loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\n","08/19/2025 17:47:09 - transformers.tokenization_utils_base - INFO - loading file added_tokens.json from cache at None\n","08/19/2025 17:47:09 - transformers.tokenization_utils_base - INFO - loading file special_tokens_map.json from cache at None\n","08/19/2025 17:47:09 - transformers.tokenization_utils_base - INFO - loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\n","08/19/2025 17:47:09 - transformers.tokenization_utils_base - INFO - loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer.json\n","08/19/2025 17:47:09 - transformers.tokenization_utils_base - INFO - loading file chat_template.jinja from cache at None\n","08/19/2025 17:47:09 - transformers.configuration_utils - INFO - loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n","08/19/2025 17:47:09 - transformers.configuration_utils - INFO - Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.53.3\",\n","  \"vocab_size\": 30522\n","}\n","\n","08/19/2025 17:47:10 - transformers.configuration_utils - INFO - loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n","08/19/2025 17:47:10 - transformers.configuration_utils - INFO - Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.53.3\",\n","  \"vocab_size\": 30522\n","}\n","\n","08/19/2025 17:47:10 - huggingface_hub.file_download - INFO - Downloading 'model.safetensors' to '/root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/5e3f1108e3cb34ee048634875d8482665b65ac713291a7e32396fb18f6ff0063.incomplete'\n","08/19/2025 17:47:19 - huggingface_hub.file_download - INFO - Download complete. Moving file to /root/.cache/huggingface/hub/models--distilbert-base-uncased/blobs/5e3f1108e3cb34ee048634875d8482665b65ac713291a7e32396fb18f6ff0063\n","08/19/2025 17:47:19 - transformers.modeling_utils - INFO - loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n","08/19/2025 17:47:20 - transformers.modeling_utils - INFO - All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n","08/19/2025 17:47:20 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:20 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:47:20 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:20 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:20 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:47:30 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:30 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:47:30 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:30 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:30 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:47:38 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:38 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:47:38 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:38 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:38 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:47:43 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:43 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:47:43 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:43 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:43 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:47:51 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:51 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:47:51 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:51 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:51 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:47:58 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:59 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:47:59 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:59 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:47:59 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:48:07 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:07 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:48:07 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:07 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:07 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:48:17 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:17 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:48:17 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:17 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:17 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:48:33 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:33 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:48:33 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:33 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:33 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:48:40 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:40 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:48:40 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:40 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:40 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:48:49 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:49 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:48:49 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:49 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:48:49 - mods.testBench - INFO - Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:00 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:00 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:00 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:00 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:00 - transformers.generation.configuration_utils - INFO - loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\n","08/19/2025 17:49:00 - transformers.generation.configuration_utils - INFO - Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"do_sample\": true,\n","  \"eos_token_id\": [\n","    151645,\n","    151643\n","  ],\n","  \"pad_token_id\": 151643,\n","  \"repetition_penalty\": 1.1,\n","  \"temperature\": 0.7,\n","  \"top_k\": 20,\n","  \"top_p\": 0.8\n","}\n","\n","08/19/2025 17:49:00 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:06 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:06 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:06 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:06 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:06 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:14 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:14 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:14 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:14 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:14 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:22 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:22 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:23 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:23 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:23 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:29 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:29 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:29 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:29 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:29 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:41 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:41 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:41 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:41 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:42 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:50 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:50 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:50 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:50 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:50 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:49:56 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:56 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:49:56 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:56 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:49:57 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:50:06 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:06 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:50:06 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:06 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:06 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:50:13 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:13 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:50:13 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:13 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:13 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:50:22 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:22 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:50:22 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:22 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:22 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:50:31 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:31 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:50:31 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:31 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:31 - mods.testBench - INFO - Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:50:38 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:38 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:50:38 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:38 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:39 - transformers.generation.configuration_utils - INFO - loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\n","08/19/2025 17:50:39 - transformers.generation.configuration_utils - INFO - Generate config GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"do_sample\": true,\n","  \"eos_token_id\": [\n","    151645,\n","    151643\n","  ],\n","  \"pad_token_id\": 151643,\n","  \"repetition_penalty\": 1.1,\n","  \"temperature\": 0.7,\n","  \"top_k\": 20,\n","  \"top_p\": 0.8\n","}\n","\n","08/19/2025 17:50:39 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:50:46 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:46 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:50:47 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:47 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:47 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:50:53 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:53 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:50:53 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:53 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:50:53 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:01 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:01 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:01 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:01 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:01 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:09 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:09 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:09 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:09 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:09 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:16 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:16 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:16 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:16 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:16 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:24 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:24 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:24 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:24 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:24 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:31 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:31 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:31 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:31 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:31 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:39 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:39 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:39 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:39 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:39 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:46 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:46 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:46 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:46 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:46 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:51:54 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:54 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:51:54 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:54 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:51:54 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:52:01 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:52:01 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:52:01 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:52:01 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:52:01 - mods.testBench - INFO - Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0} \n","08/19/2025 17:52:10 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bert_score/default/default_experiment-1-0.arrow\n","08/19/2025 17:52:10 - absl - INFO - Using default tokenizer.\n","08/19/2025 17:52:10 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/rouge/default/default_experiment-1-0.arrow\n","08/19/2025 17:52:10 - evaluate.module - INFO - Removing /root/.cache/huggingface/metrics/bleu/default/default_experiment-1-0.arrow\n","08/19/2025 17:52:10 - mods.dataHandler - INFO - Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/test-bench/tb-Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-46-59.xlsx\n","08/19/2025 17:52:10 - mods.dataHandler - INFO - Removing tmp file /content/drive/MyDrive/GitHub/reportingAgent/app/results/test-bench/tmp-Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-46-59.csv\n","08/19/2025 17:52:10 - mods.testBench - INFO - Ending experiment in TestBench with experiment_id=Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-46-59\n","08/19/2025 17:52:19 - __main__ - INFO - reportParamGridSearch time --- 5.929443808396657 minutes ---\n","08/19/2025 17:52:19 - torch._dynamo.eval_frame - INFO - TorchDynamo attempted to trace the following frames: [\n","\n","]\n","08/19/2025 17:52:19 - torch._dynamo.utils - INFO - TorchDynamo compilation metrics:\n","Function    Runtimes (s)\n","----------  --------------\n","08/19/2025 17:55:06 - projectSetup - INFO - Loading device and environment variables:\n","               device=cuda, torch_dtype=torch.float32\n","08/19/2025 17:55:06 - projectSetup - INFO - Loading environment variables from: /content/drive/MyDrive/GitHub/reportingAgent/.env\n","08/19/2025 17:55:27 - app.mods.modelLoader - WARNING - No attribute frequency_penalty found in GenerationConfig, for model_id=gpt2\n","08/19/2025 17:55:27 - app.mods.modelLoader - WARNING - No attribute presence_penalty found in GenerationConfig, for model_id=gpt2\n","08/19/2025 17:55:27 - app.mods.modelLoader - WARNING - No attribute stop found in GenerationConfig, for model_id=gpt2\n","08/19/2025 17:55:27 - app.mods.modelLoader - INFO - The default parameters of the model are:\n"," {'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'repetition_penalty': 1.0, 'do_sample': False}\n","08/19/2025 17:55:27 - __main__ - INFO - Added ENV = /content/drive/MyDrive/GitHub/reportingAgent\n","08/19/2025 17:55:29 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n","08/19/2025 17:55:30 - datasets - INFO - TensorFlow version 2.19.0 available.\n","08/19/2025 17:55:30 - datasets - INFO - JAX version 0.5.3 available.\n","08/19/2025 17:55:31 - transformers.utils.import_utils - INFO - JAX version 0.5.3, Flax version 0.10.6 available.\n","08/19/2025 17:55:33 - torch._inductor.config - INFO - compile_threads set to 2\n","08/19/2025 17:55:33 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp4_hcqfa0\n","08/19/2025 17:55:33 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp4_hcqfa0/_remote_module_non_scriptable.py\n","08/19/2025 17:55:39 - evaluate.config - INFO - PyTorch version 2.8.0+cu126 available.\n","08/19/2025 17:55:39 - evaluate.config - INFO - TensorFlow version 2.19.0 available.\n","08/19/2025 17:55:39 - evaluate.config - INFO - JAX version 0.5.3 available.\n","08/19/2025 17:55:42 - torch._dynamo.eval_frame - INFO - TorchDynamo attempted to trace the following frames: [\n","\n","]\n","08/19/2025 17:55:42 - torch._dynamo.utils - INFO - TorchDynamo compilation metrics:\n","Function    Runtimes (s)\n","----------  --------------\n"]}],"source":["!cat app/logs/logfile.log"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"i79nllcxdMwy","executionInfo":{"status":"ok","timestamp":1755626317406,"user_tz":-120,"elapsed":10545,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}}},"outputs":[],"source":["!python projectSetup.py"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["9b8343c3f4db4c90a401939ab84facd0","30585c1573c241a78b362f2c4d75cfc1","bee37d2bc30145749cd502aa6f24665b","d6f9cafff65d4785b90f0aa0789faf14","a65541e12acf413f8286a8a72444a67a","15deeaa5a9514a6098d6faa280a8285d","9549940c671f4fe59094e5ed1d295305","6d77098b439b4c9591835bf0330b86d0","6633070eee934f268f93455e2fdc7ddc","5db5173fce2742d09fd94be39aca84c4","62e125956a564a0d8ad641fea1634685"]},"executionInfo":{"elapsed":17876,"status":"ok","timestamp":1755626335287,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"Srd-wh7zg8Qt","outputId":"126cb59c-b838-49b2-f8f1-d7e5f776b774"},"outputs":[{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b8343c3f4db4c90a401939ab84facd0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["08/19/2025 17:58:55 - app.mods.modelLoader - WARNING - No attribute frequency_penalty found in GenerationConfig, for model_id=gpt2\n","08/19/2025 17:58:55 - app.mods.modelLoader - WARNING - No attribute presence_penalty found in GenerationConfig, for model_id=gpt2\n","08/19/2025 17:58:55 - app.mods.modelLoader - WARNING - No attribute stop found in GenerationConfig, for model_id=gpt2\n"]}],"source":["import sys, os\n","import torch\n","from pathlib import Path\n","sys.path.append(os.getcwd())\n","sys.path.append(os.getcwd() + '/app')\n","\n","from app.mods.promptGenerator import PromptGenerator\n","from app.mods.modelLoader import ModelLoader\n","from app.mods.reportGenerator import ReportGenerator\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch_dtype = torch.float32 if torch.cuda.is_available() else torch.float32\n","\n","ml = ModelLoader(model_id=\"gpt2\", device=device, torch_dtype=torch_dtype)"]},{"cell_type":"markdown","metadata":{"id":"rfGNcNvTUhdj"},"source":["## microsoft/phi-2\n","It allocates 12 GB in RAM, the extra depends on the number of workers"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"P57w5lE7nDyX","executionInfo":{"status":"ok","timestamp":1755626335287,"user_tz":-120,"elapsed":31,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}},"collapsed":true},"outputs":[],"source":["# !python app/reportParamGridSearch.py --model_id microsoft/phi-2 --non-threaded --prompt_method B C --max_workers 4 --dataset_filename pharma_dev_reports_collection.xlsx --start_idx 1 --end_idx 2 --temperature 1.0 --top_p 0.9 1 --top_k 50 --max_new_tokens 300 --do_sample True"]},{"cell_type":"markdown","metadata":{"id":"vVTm54F1UaHq"},"source":["## HuggingFaceTB/SmolLM3-3B\n","It allocates 14 GB in RAM"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"DdF2u_DS5WaO","collapsed":true,"executionInfo":{"status":"ok","timestamp":1755626335288,"user_tz":-120,"elapsed":21,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}}},"outputs":[],"source":["# !python app/reportParamGridSearch.py --model_id HuggingFaceTB/SmolLM3-3B  --non-threaded --prompt_method A B C --max_workers 4 --dataset_filename pharma_dev_reports_collection.xlsx --start_idx 1 --end_idx 80  --temperature 0.3 0.7 1.0 1.3 --top_p 0.3 0.6 0.9 --top_k 50 --max_new_tokens 300 --do_sample True"]},{"cell_type":"markdown","metadata":{"id":"GBWVQWjZUUrm"},"source":["## GPT2-XL\n","It allocates 7.2 GB in RAM"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1755626335289,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"},"user_tz":-120},"id":"XmhpRs4v6SBP","collapsed":true},"outputs":[],"source":["# !python app/reportParamGridSearch.py --model_id openai-community/gpt2-xl --non-threaded --prompt_method B C --max_workers 4 --dataset_filename pharma_dev_reports_collection.xlsx --start_idx 1 --end_idx 2  --temperature 0.7 1.0 1.3 --top_p 0.3 0.6 0.9 --top_k 30 50 70 --max_new_tokens 300 --do_sample True"]},{"cell_type":"markdown","source":["## Qwen/Qwen2.5-0.5B-Instruct"],"metadata":{"id":"7XvVPx1EOtm-"}},{"cell_type":"markdown","source":["It allocates 2.7 GB in RAM"],"metadata":{"id":"f-BjaRZzO_Ar"}},{"cell_type":"code","source":["try:\n","    !python app/reportParamGridSearch.py --model_id Qwen/Qwen2.5-0.5B-Instruct --non-threaded --prompt_method A B C --max_workers 4 --dataset_filename pharma_dev_reports_collection.xlsx --start_idx 1 --end_idx 80  --temperature 0.3 0.7 1.0 1.3 --top_p 0.3 0.6 0.9 --top_k 50 --max_new_tokens 300 --do_sample True --repetition_penalty 1.0\n","except Exception as e:\n","    print(e)\n","    # KILL SESSION TO AVOID LEAVING SESSION ON AND CONSUME GPU UNITS\n","    from google.colab import runtime\n","    runtime.unassign()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"JJdiTKC3PCzm","executionInfo":{"status":"ok","timestamp":1755652275363,"user_tz":-120,"elapsed":25940082,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}},"outputId":"23667fc6-1749-4068-afa5-d86f2680ac2b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","  Invalid JSON: EOF while parsing a string at line 1 column 1512 [type=json_invalid, input_value='{\"title\":\"Report on Cont...nown. The root cause of', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 119.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.53it/s]\n","Ref_row:46 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.31it/s]\n","Ref_row:46 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.83it/s]\n","Ref_row:46 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.17it/s]\n","Ref_row:46 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.91it/s]\n","Ref_row:46 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.41it/s]\n","Ref_row:46 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.60it/s]\n","Ref_row:46 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.26it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.05it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.09it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.26it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.62it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.46it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.56it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.98it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.30it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.30it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.93it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.91it/s]\n","Ref_row:46 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.88it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.40it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.43it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 96.33it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.00it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.40it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.67it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.89it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.93it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.08it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.28it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.10it/s]\n","Ref_row:47 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.10it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.40it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.38it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.23it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.94it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.06it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.09it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.07it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.85it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.12it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.82it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.47it/s]\n","Ref_row:47 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.11it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.58it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.56it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.82it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.91it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.78it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.70it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.17it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 96.45it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.71it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.60it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.50it/s]\n","Ref_row:47 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.26it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.58it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.18it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.41it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.97it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.93it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 96.94it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.30it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.30it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.92it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.67it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.11it/s]\n","Ref_row:48 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.68it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.30it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.70it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.07it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.27it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.60it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.05it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.95it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.26it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/19/2025 22:08:01 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1653 [type=json_invalid, input_value='{\"title\":\"Temperature ex...ering review confirming', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 117.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.30it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.99it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.84it/s]\n","Ref_row:48 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.65it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.16it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.64it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.98it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.14it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.11it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.44it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.21it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.94it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.92it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.16it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.61it/s]\n","Ref_row:48 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.21it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.58it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.80it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.46it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.78it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.40it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 102.25it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.97it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.03it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.36it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.05it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.31it/s]\n","Ref_row:49 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.69it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.18it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.87it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.41it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 96.86it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.96it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.58it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.71it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.25it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.84it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.58it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.75it/s]\n","Ref_row:49 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.57it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.52it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.37it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.13it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.58it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.47it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.61it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.06it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.41it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.52it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.71it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.74it/s]\n","Ref_row:49 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 93.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.85it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.90it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.14it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.21it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.49it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.80it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.74it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.58it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.67it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.84it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.20it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.71it/s]\n","Ref_row:50 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.35it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.51it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.98it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.82it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.43it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.89it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.94it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.45it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.77it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.71it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.37it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.99it/s]\n","Ref_row:50 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/19/2025 22:21:34 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1383 [type=json_invalid, input_value='{\"title\":\"Raw material t...erature excursions that', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 126.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.35it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.55it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.35it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.33it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.37it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.05it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.75it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.41it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.86it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.23it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.68it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.81it/s]\n","Ref_row:50 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.67it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.95it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.04it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.91it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.57it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.11it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.90it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.78it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.88it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.15it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.46it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.15it/s]\n","Ref_row:51 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.73it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.84it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.87it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.46it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.97it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.29it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.19it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.66it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.48it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.81it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.12it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.88it/s]\n","Ref_row:51 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.08it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.96it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.87it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.34it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.86it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.04it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.55it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.09it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.04it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.66it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.85it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.40it/s]\n","Ref_row:51 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.22it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.09it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.24it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.82it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.87it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.46it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.66it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.88it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.53it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.62it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.60it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.63it/s]\n","Ref_row:52 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.52it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.92it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.92it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.95it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.57it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.01it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.79it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.66it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.54it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.61it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.78it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 95.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.71it/s]\n","Ref_row:52 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.74it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.17it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 101.38it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.00it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.78it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.97it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.08it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.10it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.07it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.69it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 101.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 107.92it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.43it/s]\n","Ref_row:52 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.50it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.77it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.33it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.20it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 107.25it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.39it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.98it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 107.32it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.19it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.65it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.59it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.93it/s]\n","Ref_row:53 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/19/2025 22:36:56 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1453 [type=json_invalid, input_value='{\"title\":\"Report on Inci...r the current policy of', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 124.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.33it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.79it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.85it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.50it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.55it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.10it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.34it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.77it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.39it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.24it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.19it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.89it/s]\n","Ref_row:53 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.94it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.74it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.86it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 99.09it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 134.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.68it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.93it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.15it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.65it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.85it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.94it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.44it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.74it/s]\n","Ref_row:53 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.54it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.82it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.25it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.09it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.12it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.14it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 93.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.82it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.22it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.88it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.84it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 135.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.21it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.90it/s]\n","Ref_row:54 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 98.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.00it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.24it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.73it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.95it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.39it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.16it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 98.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 101.65it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.95it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.08it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.37it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.34it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.64it/s]\n","Ref_row:54 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.10it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 134.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.30it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.13it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.59it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.16it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.55it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.88it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.70it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.51it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.80it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.22it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.95it/s]\n","Ref_row:54 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.07it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.91it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.93it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.78it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 102.13it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.88it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.36it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.26it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.97it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.11it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.64it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.96it/s]\n","Ref_row:55 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 93.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.95it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.97it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.16it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.24it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.83it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.09it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.15it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.11it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.23it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.26it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.04it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.76it/s]\n","Ref_row:55 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.96it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.06it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.69it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.95it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.50it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.49it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.63it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.01it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.69it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.41it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.11it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.23it/s]\n","Ref_row:55 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.21it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.95it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.27it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.14it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.06it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.08it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.49it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.90it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.13it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.51it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.13it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.34it/s]\n","Ref_row:56 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.77it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.59it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.92it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.72it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.80it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.93it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.22it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.31it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.71it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 101.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.05it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.21it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.24it/s]\n","Ref_row:56 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.93it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.66it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.54it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.76it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.59it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.64it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.88it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.95it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.66it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.61it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.68it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.83it/s]\n","Ref_row:56 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.08it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.55it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.88it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.70it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.86it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.26it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.48it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.99it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.38it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 102.42it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.81it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.97it/s]\n","Ref_row:57 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.86it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.51it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.42it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.12it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.36it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.02it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.84it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.86it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.84it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.81it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.74it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.06it/s]\n","Ref_row:57 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.01it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.92it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.07it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.99it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.81it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.16it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.82it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.17it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.62it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.43it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.72it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.17it/s]\n","Ref_row:57 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.45it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.94it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.33it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.65it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.30it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.22it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.15it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.41it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.78it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.11it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.01it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.61it/s]\n","Ref_row:58 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.72it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.02it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.57it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.62it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.53it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.61it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.73it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.19it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.14it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.82it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.98it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.07it/s]\n","Ref_row:58 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.62it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 135.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.55it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 142.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 147.56it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.69it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 139.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.63it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.13it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.25it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.28it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.44it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.25it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.64it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.98it/s]\n","Ref_row:58 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.16it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.45it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.08it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 95.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.87it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.40it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.20it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.32it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.18it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 101.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.33it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.55it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.86it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.42it/s]\n","Ref_row:59 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.83it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.63it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.87it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.40it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.87it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.45it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.43it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.25it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.62it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.12it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.16it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.94it/s]\n","Ref_row:59 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.51it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.29it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.25it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.63it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.20it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.06it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.14it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.41it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.13it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.10it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.25it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 134.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.09it/s]\n","Ref_row:59 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.76it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 96.64it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.10it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.75it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 135.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 141.78it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.80it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.01it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.37it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.08it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.85it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.22it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.33it/s]\n","Ref_row:60 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.41it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.43it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.41it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.45it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.19it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.63it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.38it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.17it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.19it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.78it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.51it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.91it/s]\n","Ref_row:60 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.19it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.81it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.73it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.63it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.81it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.90it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.60it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.56it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.62it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.94it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.92it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.97it/s]\n","Ref_row:60 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.63it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 99.32it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.85it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.93it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.31it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.24it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.05it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/19/2025 23:20:03 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1551 [type=json_invalid, input_value='{\"title\":\"Report on Cros...oduction was halted and', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 124.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.87it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.37it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.34it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.46it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.27it/s]\n","Ref_row:61 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.53it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.33it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.96it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.18it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.67it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.44it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.13it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.88it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.65it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.46it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.04it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.67it/s]\n","Ref_row:61 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.15it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.49it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.62it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.47it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.45it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.64it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.94it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.61it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.28it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.10it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.24it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.12it/s]\n","Ref_row:61 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.25it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.13it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.25it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.18it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.09it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.26it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.58it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.99it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.02it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.48it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.03it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.39it/s]\n","Ref_row:62 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.93it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.32it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.21it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.09it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.55it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.39it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.77it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.51it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.42it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.70it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.61it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 98.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.55it/s]\n","Ref_row:62 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 57.69it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.14it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.34it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.23it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.21it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 93.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.31it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.41it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.45it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 135.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.11it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.05it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.19it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.66it/s]\n","Ref_row:62 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.92it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.95it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.93it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.03it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.38it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.98it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.48it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.90it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.64it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.56it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.88it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.98it/s]\n","Ref_row:63 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 99.27it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.40it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.29it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.08it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.29it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.21it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/19/2025 23:33:44 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1474 [type=json_invalid, input_value='{\"title\":\"Report on Prin...ncluded, and the proper', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 97.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.24it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 93.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.25it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.09it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.24it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.09it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.40it/s]\n","Ref_row:63 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.59it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.72it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.86it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.33it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.61it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.39it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.68it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.15it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.26it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.19it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.98it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 139.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.14it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.71it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.70it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.19it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.12it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.15it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.01it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.63it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.08it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.74it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.92it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.37it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.59it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.76it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.28it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.57it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.69it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.36it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.37it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 98.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.14it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.25it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.65it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.74it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.50it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 135.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.16it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 142.49it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 135.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.90it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.17it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.09it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 139.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.81it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.69it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.36it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.79it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.11it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.06it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.73it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.61it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.20it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.49it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.79it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.58it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.41it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.15it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.10it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.57it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.86it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.91it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.98it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.83it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.50it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.62it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.59it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.83it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.46it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.81it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.64it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.50it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 101.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.65it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.50it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.33it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 141.94it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.59it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.53it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.96it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.70it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.86it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.23it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.52it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.97it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.47it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 137.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.49it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.10it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 141.13it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.44it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.56it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.54it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.45it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.38it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.67it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.17it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.80it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.58it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.33it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.22it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.59it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.02it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.13it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 101.57it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.62it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.22it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.78it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.35it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.55it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.99it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.29it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.00it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.72it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.95it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.66it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.43it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.97it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.97it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 99.43it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.52it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.18it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.79it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 107.06it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.83it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.42it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.45it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.62it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.02it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.03it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.19it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.71it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 135.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.54it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.05it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.33it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.30it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.13it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.32it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.99it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.77it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.43it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.93it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.03it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.00it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.27it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.63it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.80it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.28it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.44it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.11it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.07it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.09it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.77it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.74it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.53it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.39it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.36it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.08it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.08it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 52.04it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 134.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.08it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.54it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.79it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.95it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.59it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.42it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.99it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.57it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.00it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.60it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.82it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.30it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.25it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.31it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.32it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.14it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.33it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.34it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 103.64it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.06it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.11it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.42it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.84it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.08it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.93it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 107.96it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 43.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.99it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.91it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.80it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.23it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.20it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.37it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.64it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.78it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.78it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 101.82it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.57it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.67it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.87it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.37it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.58it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.88it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.02it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.29it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.95it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.70it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.24it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.84it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.43it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.45it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 99.27it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.06it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.14it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.50it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.05it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.22it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.46it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.25it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.07it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.78it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.22it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.38it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.24it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.22it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.46it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.89it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.73it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.03it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.37it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.26it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.18it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.61it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.83it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.42it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.51it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.41it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.88it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.91it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.54it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.55it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.06it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.32it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.85it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.52it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.12it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.39it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.27it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.18it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.46it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.42it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.56it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.79it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 103.22it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.47it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.14it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.84it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.60it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.29it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.97it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.41it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.55it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.52it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.69it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.57it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.77it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.18it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.11it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.23it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.35it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.66it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.08it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.92it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.16it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.22it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.93it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.68it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.56it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.44it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.32it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.60it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.01it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.24it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.89it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.53it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.09it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.98it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.91it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.68it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.92it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.22it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.28it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.56it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.10it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.44it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.48it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.66it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.43it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.33it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.32it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.13it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 137.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.22it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.50it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.71it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.63it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.74it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.92it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.89it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.46it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.31it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.48it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.05it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.83it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.64it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.34it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.95it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.07it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.82it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.33it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.20it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.08it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.35it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 103.02it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.06it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.20it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.77it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.13it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.52it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.33it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.70it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.98it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.43it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 101.83it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.87it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.09it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.17it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.27it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.29it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.12it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.78it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.80it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.76it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.06it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.88it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.94it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.73it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.71it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.83it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.43it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.71it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.86it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.53it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.02it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.34it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.14it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 102.97it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.45it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.44it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.85it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.60it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.04it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.64it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.89it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 98.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 99.07it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.98it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.18it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.62it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.34it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.04it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.25it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.91it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.56it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.95it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.04it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.91it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.50it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 98.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 103.71it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 137.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 141.80it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.49it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.67it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 144.17it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 141.40it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.22it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 102.87it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.19it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 134.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.09it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.56it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.01it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.74it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.06it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.30it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.88it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.74it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.42it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.71it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.06it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.48it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.68it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 143.73it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.57it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.95it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.75it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 134.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.71it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.71it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.45it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.50it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.55it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 141.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.32it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.60it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 139.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.79it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.08it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 137.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.56it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.71it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.52it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.50it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.18it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.63it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.66it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.28it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 93.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.15it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.72it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.31it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.50it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.54it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.33it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.35it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.90it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.23it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.86it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.21it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 102.56it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.75it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.38it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.10it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.01it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 95.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.41it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.25it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.23it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.25it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.77it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 138.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.76it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.07it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.05it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.06it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.18it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.92it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 96.70it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.66it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.51it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.28it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 136.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.95it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.80it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.43it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.41it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.89it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.26it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.66it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.98it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.40it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 134.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 141.64it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 137.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.73it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.44it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.11it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.62it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.90it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.44it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.95it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.96it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.69it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.89it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.99it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.79it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.88it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.82it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.47it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.77it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.15it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.68it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.87it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.89it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.33it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.20it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.95it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.53it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.06it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.53it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.69it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.35it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.17it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.17it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.48it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.77it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.38it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.99it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.31it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.09it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.92it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.15it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.22it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.53it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.36it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.19it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.10it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.28it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.41it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.00it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.76it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.45it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.19it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.39it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.73it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.40it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.49it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.61it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.69it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.37it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.98it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.19it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.36it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.72it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.51it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.22it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.13it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.33it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.45it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.68it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.66it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.83it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 142.34it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.64it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.88it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.55it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 150.13it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.79it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.03it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.43it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.68it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 100.01it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 139.33it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.58it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.74it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.89it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.18it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.14it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.44it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.33it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.04it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.41it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 133.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 143.19it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.05it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.36it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 142.16it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 97.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 96.74it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.92it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.09it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 137.39it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 141.03it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 95.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.26it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.79it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 101.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 103.71it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.31it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 103.14it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.39it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 136.89it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.20it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.40it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.52it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 100.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.20it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.45it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.83it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.42it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.09it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.50it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 95.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.53it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.98it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:01:53 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1557 [type=json_invalid, input_value='{\"title\":\"Report on Inco...ent was classified as a', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 135.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.96it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.73it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.51it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.02it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.22it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.15it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.68it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.07it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.55it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.12it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.60it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.73it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.27it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.17it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 142.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.90it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.05it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.90it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 140.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.21it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 135.67it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.68it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.21it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 140.55it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 101.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 101.49it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.61it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 144.13it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.97it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.15it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.95it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.48it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.98it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 127.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.03it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.50it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.77it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.94it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.94it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.21it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.63it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 129.37it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.52it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.16it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.96it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.41it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.04it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.35it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.08it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 132.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.18it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 126.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.09it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 138.93it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.34it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.96it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.83it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.97it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.54it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 134.34it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.15it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.21it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 133.02it/s]\n","***** Starting statistical analyisis for the experiment_id=Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-59-44 ***** \n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-mean-Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-59-44.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_A-Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-59-44.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_B-Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-59-44.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_C-Qwen-Qwen2.5-0.5B-Instruct-19-082025_17-59-44.xlsx\n","reportParamGridSearch time --- 432.0089717547099 minutes ---\n"]}]},{"cell_type":"markdown","metadata":{"id":"JozIHMbjZGtI"},"source":["# Several models run in parallel\n","In linux command with the & we can run several programs in parallel\n","**Careful it fills GPU RAM quickly if models are > 2 B parameters**\n","\n","**NOTA:** Better use the Colab L4 GPU for charging two models in parallel. The L4 GPU size is 25 GB, so it could admit up to 5B parameters more or less, i.e.:\n","\n","- two models of at most 2.5 B parameters.\n","- Three models of 1 B parameters each\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"yCGd0oBQZbTL","executionInfo":{"status":"ok","timestamp":1755652275396,"user_tz":-120,"elapsed":29,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}}},"outputs":[],"source":["# !python app/reportParamGridSearch.py --model_id microsoft/phi-2 --start_idx 20 --end_idx 22  --temperature 0.3 0.7 1.3 2.0 --top_p 0.2 0.5 0.8 1 --top_k 10 30 50 --max_new_tokens 300 --do_sample True & python app/reportParamGridSearch.py --model_id HuggingFaceTB/SmolLM3-3B --start_idx 20 --end_idx 22  --temperature 0.3 0.7 1.3 2.0 --top_p 0.2 0.5 0.8 1 --top_k 10 30 50 --max_new_tokens 300 --do_sample True"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"j0P1LHHOXp0d","executionInfo":{"status":"ok","timestamp":1755652275564,"user_tz":-120,"elapsed":162,"user":{"displayName":"Samd Guizani","userId":"17513899638189689902"}}},"outputs":[],"source":["# KILL SESSION TO AVOID LEAVING SESSION ON AND CONSUME GPU UNITS\n","\n","from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9b8343c3f4db4c90a401939ab84facd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30585c1573c241a78b362f2c4d75cfc1","IPY_MODEL_bee37d2bc30145749cd502aa6f24665b","IPY_MODEL_d6f9cafff65d4785b90f0aa0789faf14"],"layout":"IPY_MODEL_a65541e12acf413f8286a8a72444a67a"}},"30585c1573c241a78b362f2c4d75cfc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15deeaa5a9514a6098d6faa280a8285d","placeholder":"​","style":"IPY_MODEL_9549940c671f4fe59094e5ed1d295305","value":"generation_config.json: 100%"}},"bee37d2bc30145749cd502aa6f24665b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d77098b439b4c9591835bf0330b86d0","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6633070eee934f268f93455e2fdc7ddc","value":124}},"d6f9cafff65d4785b90f0aa0789faf14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5db5173fce2742d09fd94be39aca84c4","placeholder":"​","style":"IPY_MODEL_62e125956a564a0d8ad641fea1634685","value":" 124/124 [00:00&lt;00:00, 13.3kB/s]"}},"a65541e12acf413f8286a8a72444a67a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15deeaa5a9514a6098d6faa280a8285d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9549940c671f4fe59094e5ed1d295305":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d77098b439b4c9591835bf0330b86d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6633070eee934f268f93455e2fdc7ddc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5db5173fce2742d09fd94be39aca84c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e125956a564a0d8ad641fea1634685":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}