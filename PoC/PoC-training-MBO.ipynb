{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"18c19d669c4f49f6b8bd22ccf8336596":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c17e2bc8b4a54a86a4a832cdffb77bef","IPY_MODEL_e03ead8593b34b0fb5cc6dea29bd24ed","IPY_MODEL_afd5e57dbb314634af555c20dd557e2c"],"layout":"IPY_MODEL_c1aa6e0633f24df38f70587a2c19a669"}},"c17e2bc8b4a54a86a4a832cdffb77bef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f854478b7b704eb48e18e1012316aeb7","placeholder":"​","style":"IPY_MODEL_8be9d2bde5384971829c9d4235bf69ad","value":"Processing Files (1 / 1)                : 100%"}},"e03ead8593b34b0fb5cc6dea29bd24ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bf2d71ca57848e2bfbcea88235cc02e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6831fbc76a7044e38c1266b9abe01d9d","value":1}},"afd5e57dbb314634af555c20dd557e2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36eb45d08dfd4f3abc0d31b09411a417","placeholder":"​","style":"IPY_MODEL_7a942e473b7c4189a5065825ddb50fe3","value":"  724MB /  724MB, 38.2MB/s  "}},"c1aa6e0633f24df38f70587a2c19a669":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f854478b7b704eb48e18e1012316aeb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8be9d2bde5384971829c9d4235bf69ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bf2d71ca57848e2bfbcea88235cc02e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6831fbc76a7044e38c1266b9abe01d9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36eb45d08dfd4f3abc0d31b09411a417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a942e473b7c4189a5065825ddb50fe3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36fa8dd002a5448c9c310c60eb411c0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40613beeefbe4b81a6897942b5727b44","IPY_MODEL_666c794759b54469a0c21e01901c70da","IPY_MODEL_57ac790166714428ae6385e7dc9c83e0"],"layout":"IPY_MODEL_63afc55e213d4ed08bbb9e57963691c2"}},"40613beeefbe4b81a6897942b5727b44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd4d3fb25cc74c878bca6591aad77179","placeholder":"​","style":"IPY_MODEL_0047c645a37b42eea8be831b6d0a8501","value":"New Data Upload                         : 100%"}},"666c794759b54469a0c21e01901c70da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd3abb8a24e44fc3bff54dc9053d93c6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e86b5dd9b47249ca84cd32b434e243c4","value":1}},"57ac790166714428ae6385e7dc9c83e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9d31d52efa4dfcb8bcfb19a2cbf379","placeholder":"​","style":"IPY_MODEL_99fe8d365406433d9294d2ca218d8111","value":"  629MB /  629MB, 38.2MB/s  "}},"63afc55e213d4ed08bbb9e57963691c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd4d3fb25cc74c878bca6591aad77179":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0047c645a37b42eea8be831b6d0a8501":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd3abb8a24e44fc3bff54dc9053d93c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e86b5dd9b47249ca84cd32b434e243c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b9d31d52efa4dfcb8bcfb19a2cbf379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99fe8d365406433d9294d2ca218d8111":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10ddc72219644195b53a5bffdae9ca0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36e6f2b784464f57a84ea47c1de0b462","IPY_MODEL_a8c181ad1d7c42ee947146c09781d6c5","IPY_MODEL_657c7fe1cd694e6f86ac40d928a55a66"],"layout":"IPY_MODEL_ea3834b055654687bc81087baf64f3ee"}},"36e6f2b784464f57a84ea47c1de0b462":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33a9feae5e334f6db6e7f82da5c0d4ca","placeholder":"​","style":"IPY_MODEL_3b5f0e74637542918dddad28dcf30294","value":"  ...t_reporter_merged/model.safetensors: 100%"}},"a8c181ad1d7c42ee947146c09781d6c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_640099882a55480ba4ee986912660ad4","max":723674912,"min":0,"orientation":"horizontal","style":"IPY_MODEL_385986716a1c4e2c9244a24f69adda46","value":723674912}},"657c7fe1cd694e6f86ac40d928a55a66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb3b2d23af3746069df784974b15a9ee","placeholder":"​","style":"IPY_MODEL_0e02d13a39db47adb644a189c18efb89","value":"  724MB /  724MB            "}},"ea3834b055654687bc81087baf64f3ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33a9feae5e334f6db6e7f82da5c0d4ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b5f0e74637542918dddad28dcf30294":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"640099882a55480ba4ee986912660ad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"385986716a1c4e2c9244a24f69adda46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb3b2d23af3746069df784974b15a9ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e02d13a39db47adb644a189c18efb89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7ehcE6hOQKd","outputId":"a51173c7-c92a-46fb-e269-00d3d7771b33","executionInfo":{"status":"ok","timestamp":1756132117665,"user_tz":-120,"elapsed":26364,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","github_token = userdata.get('zbotta_token')\n","\n","token = github_token\n","username = \"zbotta\"\n","repo = 'reportingAgent'\n","%cd /content/drive/MyDrive/GitHub/{repo}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y9EgSGSJOVWU","outputId":"b1091063-329d-479e-90bb-59b992a3c23d","executionInfo":{"status":"ok","timestamp":1756132119383,"user_tz":-120,"elapsed":1721,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GitHub/reportingAgent\n"]}]},{"cell_type":"code","source":["!git config --global user.name \"zbotta\"\n","!git config --global user.email \"zbotta@proton.me\"\n","!git pull\n","!git checkout dev"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y7QaVVbhpJ1q","executionInfo":{"status":"ok","timestamp":1756132201283,"user_tz":-120,"elapsed":81896,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"90969bfa-594a-40b2-b0ea-5fc12cb03120"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n","M\tPoC/reportAgent-remote.ipynb\n","A\tapp/datasets/training/eval.json\n","A\tapp/datasets/training/eval.jsonl\n","A\tapp/datasets/training/train.json\n","A\tapp/datasets/training/train.jsonl\n","Already on 'dev'\n","Your branch is up to date with 'origin/dev'.\n"]}]},{"cell_type":"markdown","source":["# Testing models < 1B"],"metadata":{"id":"9hVgw73hO9eE"}},{"cell_type":"code","source":["!pip -q install -U \"transformers>=4.43\" \"accelerate>=0.33\" bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxfkShoHOUV-","executionInfo":{"status":"ok","timestamp":1755610286609,"user_tz":-120,"elapsed":118737,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"74c2ebfc-1dcd-4c94-9ea0-d72b24bb3ca5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Qwen 2.5-0.5B-Instruct"],"metadata":{"id":"iJ4X9JEhPBgY"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import torch, re\n","\n","MODEL_ID = \"Qwen/Qwen2.5-0.5B-Instruct\"\n","\n","bnb_cfg = BitsAndBytesConfig(\n","    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, trust_remote_code=True)\n","if tok.pad_token_id is None:\n","    tok.pad_token = tok.eos_token\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_ID, quantization_config=bnb_cfg, device_map=\"auto\",\n","    torch_dtype=torch.float16, trust_remote_code=True\n",")\n","\n","SYSTEM_INSTR = (\n","  \"You are an incident-report generator.\\n\"\n","  \"Language: {lang_directive}\\n\"\n","  \"Write ONE SINGLE PARAGRAPH that includes ALL facts provided: what happened, when, where, who, how, why (root cause), and contingency/corrective actions. \"\n","  \"Constraints: neutral factual tone; no bullet points, no headings, no lists, no JSON; \"\n","  \"do NOT invent details; include only information given; output must be a single line with no line breaks; \"\n","  \"preserve numbers, times, names, and proper nouns; limit length to {max_chars} characters.\"\n",")\n","\n","def extract_lang(user_text:str):\n","    # Optional inline directive, e.g. \"Language: French\"\n","    m = re.search(r\"(?i)\\bLanguage\\s*:\\s*([A-Za-zÀ-ÿ \\-]+)\", user_text)\n","    return m.group(1).strip() if m else None\n","\n","def build_prompt(user_text, max_chars=400, lang=\"auto\"):\n","    inline = extract_lang(user_text)\n","    if inline:\n","        lang_directive = f\"write in {inline}\"\n","    elif lang and lang.lower() != \"auto\":\n","        lang_directive = f\"write in {lang}\"\n","    else:\n","        lang_directive = \"match the dominant language of the INPUT\"\n","\n","    return (\n","        SYSTEM_INSTR.format(lang_directive=lang_directive, max_chars=max_chars)\n","        + \"\\n\\nINPUT:\\n\" + user_text.strip()\n","        + f\"\\n\\nOUTPUT (single paragraph, ≤{max_chars} chars):\"\n","    )\n","\n","def _one_line(s: str) -> str:\n","    s = s.replace(\"\\n\", \" \")\n","    return re.sub(r\"\\s+\", \" \", s).strip()\n","\n","def _clip_paragraph(s: str, max_chars: int) -> str:\n","    if len(s) <= max_chars: return s\n","    clipped = s[:max_chars]\n","    end = max(clipped.rfind(\".\"), clipped.rfind(\"!\"), clipped.rfind(\"?\"))\n","    return clipped[:end+1] if end > 50 else clipped  # prefer a sentence end\n","\n","def generate_event_report(user_text, max_chars=400, max_new_tokens=260,\n","                          temperature=0.0, top_p=1.0, lang=\"auto\"):\n","    prompt = build_prompt(user_text, max_chars=max_chars, lang=lang)\n","    messages = [{\"role\":\"user\",\"content\":prompt}]\n","    input_ids = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n","\n","    out = model.generate(\n","        input_ids, max_new_tokens=max_new_tokens,\n","        do_sample=(temperature>0), temperature=temperature, top_p=top_p,\n","        eos_token_id=tok.eos_token_id\n","    )\n","    gen_ids = out[0, input_ids.shape[-1]:]\n","    text = tok.decode(gen_ids, skip_special_tokens=True)\n","    text = _one_line(text)\n","    return _clip_paragraph(text, int(max_chars))\n","\n","\n"],"metadata":{"id":"ArswDhaUdJsG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tests several languages\n","\n","As Qwen model is multilingual, we can make a test of the output when the a language directive is done.\n","\n","This could be interesting to include in the APP deployment."],"metadata":{"id":"uS82CYPkx0LA"}},{"cell_type":"markdown","source":["#### ENGLISH"],"metadata":{"id":"xfug7wS8x2qh"}},{"cell_type":"code","source":["# Smoke test (English, auto)\n","example = \"\"\"What: Incorrect pH adjustment in buffer preparation\n","When: June 10, 2025, 9:15 AM\n","Where: Formulation Area, Production Building 2\n","Who: Rahul Mehta, Process Technician\n","How: pH meter not calibrated before use\n","Why: Technician skipped calibration step due to time pressure\n","ContingencyActions: Buffer batch discarded, technician retrained, equipment calibration logs reviewed\"\"\"\n","print(generate_event_report(example, lang=\"auto\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IY8HiLNgx6tn","executionInfo":{"status":"ok","timestamp":1755615557694,"user_tz":-120,"elapsed":13689,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"9476f4d7-a07b-4d62-c29a-d9a9bb12d39c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["On June 10, 2025, at 9:15 AM, during the process of preparing a buffer solution for a production batch, an incorrect pH adjustment was made. The pH meter had not been calibrated before its use, leading to an uncontrolled pH level. This oversight occurred after the technician had already started the preparation process without checking the calibration status.\n"]}]},{"cell_type":"markdown","source":["#### FRENCH"],"metadata":{"id":"uETmG4JWx5Ve"}},{"cell_type":"code","source":["# Smoke test with your 5W1H-style input:\n","example = \"\"\"What: Ajustement incorrect du pH lors de la préparation du tampon\n","When: 10 juin 2025, 9 h 15\n","Where: Zone de formulation, Bâtiment de production 2\n","Who: Rahul Mehta, technicien de procédé\n","How: pH-mètre non étalonné avant utilisation\n","Why: Le technicien a sauté l’étape d’étalonnage par manque de temps\n","ContingencyActions : Lot de tampons éliminé, technicien formé à nouveau, journaux d’étalonnage des équipements examinés\"\"\"\n","print(generate_event_report(example, temperature=0.0, lang=\"FRENCH\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xV2WqypAx6_Y","executionInfo":{"status":"ok","timestamp":1755615586006,"user_tz":-120,"elapsed":17439,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"55ee39b9-b288-4395-a568-a5c5071c2aee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Le pH incorrecte lors de la préparation du tampon a été détecté en juillet 2025, au sein de la zone de formation de la Bâtiment de Production 2, dans le Bâtiment de Production 2. L'ajout de pH-mètres n'était pas effectué avant cette utilisation. Le technicien de procédé, Rahul Mehta, s'est fait sauter l'étape d'étalonnage par manque de temps.\n"]}]},{"cell_type":"markdown","source":["#### SPANISH"],"metadata":{"id":"zWe3KCXNzfpY"}},{"cell_type":"code","source":["example = \"\"\"What: Ajuste incorrecto del pH en la preparación de la solución tampón\n","When: 10 de junio de 2025, 9:15 a. m.\n","Where: Área de Formulación, Edificio de Producción 2\n","Who: Rahul Mehta, Técnico de Procesos\n","How: El medidor de pH no se calibró antes de su uso\n","Why: El técnico omitió el paso de calibración por falta de tiempo\n","ContingencyActions : Se descartó el lote de solución tampón, se capacitó al técnico y se revisaron los registros de calibración del equipo\"\"\"\n","print(generate_event_report(example, temperature=0.0, lang=\"SPANISH\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzkiIrY6zfIT","executionInfo":{"status":"ok","timestamp":1755615612065,"user_tz":-120,"elapsed":11024,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"8e330f65-46cf-49e4-d509-2c4fa3c20355"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["Un ajuste incorrecto del pH en la preparación de la solución tampón ocurrió el 10 de junio de 2025, a las 9:15 a. m., en el área de Formulación del edificio de producción 2. El medidor de pH no se había calibrado antes de su uso. El técnico Rahul Mehta, un técnico de procesos, omitió el paso de calibración por falta de tiempo. La causa fue la falta de tiempo para realizar la calificación correcta.\n"]}]},{"cell_type":"code","source":["!pip install evaluate sentence_transformers numpy bert_score rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34e0NWzeiCZG","executionInfo":{"status":"ok","timestamp":1755610472759,"user_tz":-120,"elapsed":5863,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"f19ca2ea-f1f9-41c1-ebc3-a617dbfa623b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (5.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: bert_score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n","Collecting rouge_score\n","  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.55.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.16.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.3.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.14.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.7)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=23294bdcc1c45770cc05ac0f21d137877906e92c73c07d67a150ccd752b633c9\n","  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","source":["REF = \"On June 10, 2025, at 9:15 AM in the Formulation Area (Production Building 2), technician Rahul Mehta used a non-calibrated pH meter to adjust the buffer, leading to an incorrect pH. The calibration step was skipped due to time pressure. The buffer batch was discarded, Rahul was retrained, and calibration logs were reviewed to prevent recurrence.\"\n","PRED = \"On June 10, 2025, the buffer preparation process at the Production Building 2 of the Formulation Area encountered an incorrect pH adjustment. The pH meter had not been calibrated before its use, leading to an unadjusted pH value. This oversight resulted in a significant deviation from the desired pH range, causing a critical safety hazard.\"\n","PRED2 = \"On June 10, 2025, at 9:15 AM, the buffer preparation process for batch number 4667 failed due to incorrect pH adjustment in the buffer preparation area of the production building. The technician, Rahul Mehta, had been tasked with preparing a buffer solution, but he had not performed a pH correction step as per his calibration schedule.\"\n","PRED3 = \"On June 10, 2025, at 9:15 AM in the production area of Building 2, the buffer preparation team conducted batch #16, a solution containing sodium hydroxide, under the supervision of Master Technician Rahul Mehta, on process control measures. Initially, they expected pH readings within the specified range of 3.8 to 4.3. After checking, they noticed that the pH meters were uncalibrated.\"\n","PRED4 = \"On June 10, 2025, at 9:15 AM, the buffer preparation process at the Production Building 2 of the Formulation Area encountered an incorrect pH adjustment in the buffer solution. The pH meter had not been calibrated before its use, leading to an uncontrolled pH level. This oversight resulted in a significant deviation from the desired pH range, causing a potential safety hazard.\"\n","#at 9:15 AM,\n","import sys, os\n","from pathlib import Path\n","sys.path.append(os.getcwd())\n","sys.path.append(os.getcwd() + '/app')\n","\n","from app.mods.metricsEvaluator import MetricsEvaluator\n","\n","me = MetricsEvaluator()"],"metadata":{"id":"XW-pNV37dW62"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["me.set_cross_encoder_score(REF, [PRED])\n","print(me.get_cross_encoder_score())\n","me.set_cross_encoder_score(REF, [PRED2])\n","print(me.get_cross_encoder_score())\n","me.set_cross_encoder_score(REF, [PRED3])\n","print(me.get_cross_encoder_score())\n","me.set_cross_encoder_score(REF, [PRED4])\n","print(me.get_cross_encoder_score())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0ITAp1Ar7Cp","executionInfo":{"status":"ok","timestamp":1755615705039,"user_tz":-120,"elapsed":112,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"b4d11518-858e-4dcb-c7f6-efca215a5018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.]\n","[1.]\n","[1.]\n","[1.]\n"]}]},{"cell_type":"code","source":["me.set_bi_encoder_score(REF, [PRED], is_test_bench=False)\n","print(me.get_bi_encoder_score())\n","me.set_bi_encoder_score(REF, [PRED2])\n","print(me.get_bi_encoder_score())\n","me.set_bi_encoder_score(REF, [PRED3])\n","print(me.get_bi_encoder_score())\n","me.set_bi_encoder_score(REF, [PRED4])\n","print(me.get_bi_encoder_score())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sEh30lAiuI6","executionInfo":{"status":"ok","timestamp":1755614179566,"user_tz":-120,"elapsed":85,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"510ead90-9c06-44f1-ee7f-5485a6664de5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.        0.7809284]\n","[1.         0.73692465]\n","[1.         0.72478765]\n","[1.        0.7777794]\n"]}]},{"cell_type":"code","source":["!python -V"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_HyboresflJ","executionInfo":{"status":"ok","timestamp":1755614309810,"user_tz":-120,"elapsed":178,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"2229f897-1647-4907-ac51-f6f08bf9fdf8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.11.13\n"]}]},{"cell_type":"code","source":["!pip -q install -r requirements_colab.txt\n","!pip install --upgrade torch torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":866},"id":"xs5Rm0jyxGWW","executionInfo":{"status":"ok","timestamp":1755614854464,"user_tz":-120,"elapsed":17854,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"e10cbf21-1698-4a82-fe71-177544c5218d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Collecting torchvision\n","  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch) (75.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torchvision\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torchvision-0.23.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torchvision"]},"id":"1560b2c3eac54c21a8eab145c32ea7b5"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Grid Search on Tiny Models"],"metadata":{"id":"dJ1cStGxHAjJ"}},{"cell_type":"markdown","source":["## HuggingFaceTB/SmolLM2-360M-Instruct & HuggingFaceTB/SmolLM2-135M-Instruct\n","\n"],"metadata":{"id":"3fvH32ZaHEOo"}},{"cell_type":"code","source":["!python app/reportParamGridSearch.py --model_id HuggingFaceTB/SmolLM2-135M-Instruct  --non-threaded --prompt_method A B C --max_workers 4 --dataset_filename pharma_dev_reports_collection.xlsx --start_idx 1 --end_idx 80  --temperature 0.3 0.7 1.0 1.3 --top_p 0.3 0.6 0.9 --top_k 50 --max_new_tokens 300 --do_sample True & python app/reportParamGridSearch.py --model_id HuggingFaceTB/SmolLM2-360M-Instruct  --non-threaded --prompt_method A B C --max_workers 4 --dataset_filename pharma_dev_reports_collection.xlsx --start_idx 1 --end_idx 80  --temperature 0.3 0.7 1.0 1.3 --top_p 0.3 0.6 0.9 --top_k 50 --max_new_tokens 300 --do_sample True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GCHjelWnGpP-","executionInfo":{"status":"ok","timestamp":1755658015432,"user_tz":-120,"elapsed":37828389,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"71c80291-e1be-4f8a-c37d-0a2718ccb304"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 34.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.23it/s]\n","Ref_row:63 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.22it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:44:48 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 653 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...Why?  Why?  Why?  Why? ', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.06it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.21it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:45:20 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1636 [type=json_invalid, input_value='{\"title\": \"What was the ...t was the contamination', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.07it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:45:23 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1424 [type=json_invalid, input_value='{ \"title\": \"Report on th...wing information: what,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.98it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 53.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.31it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.67it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.96it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.67it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:46:00 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1211 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...of batch LQX-100 during', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 39.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.68it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.88it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:46:03 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1691 [type=json_invalid, input_value='{ \"title\": \"Report on In...ncident was impacted by', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.94it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.27it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.76it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.24it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.25it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 69.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.71it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.24it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.11it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.28it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.98it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:46:47 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1578 [type=json_invalid, input_value='{ \"title\": \"Report on Br... back to the laboratory', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 54.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.85it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:47:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1050 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...rce assessment, March 3', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 42.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.36it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.48it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:47:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1427 [type=json_invalid, input_value='{ \"title\": \"Report on ev... container. Both of the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.84it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:47:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 370 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...00000000000000000000000', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.33it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.36it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:47:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 319 [type=json_invalid, input_value='{ \"title\": \"Report on Ev...-00-00-00-00-00-00-00-0', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 80.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.61it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.54it/s]\n","Ref_row:64 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.01it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:48:24 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1507 [type=json_invalid, input_value='{\"title\": \"What was the ...days. The investigation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 72.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.68it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.67it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 35.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.05it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.52it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.46it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.04it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:49:04 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1317 [type=json_invalid, input_value='{\"title\": \"What was the ...product sample after 09', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 59.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.69it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.99it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.75it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:49:10 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1525 [type=json_invalid, input_value='{ \"title\": \"Report on th...e samples were found to', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 56.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.07it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.56it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.60it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 34.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 33.69it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:49:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 319 [type=json_invalid, input_value='{ \"title\": \"Report on Ev...-00-00-00-00-00-00-00-0', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 45.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 33.12it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.76it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.56it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.45it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.75it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.05it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:50:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1609 [type=json_invalid, input_value='{ \"title\": \"Report on In...r was informed that the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 25.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.78it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.30it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.39it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 27.73it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.00it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.92it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.68it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.75it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.82it/s]\n","Ref_row:64 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.60it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.52it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 27.33it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 57.64it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:51:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1006 [type=json_invalid, input_value='{\"title\": \"What was the ...or?  Why was the error?', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 60.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.22it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.84it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.71it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.09it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:52:27 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1006 [type=json_invalid, input_value='{\"title\": \"What was the ...or?  Why was the error?', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 73.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.69it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.35it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.31it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.71it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:53:00 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 397 [type=json_invalid, input_value='{\"title\": \"What was the ...:20 16:20 16:20 16:20 1', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 63.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.41it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.71it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.81it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.86it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 45.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 36.62it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:53:36 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1002 [type=json_invalid, input_value='{\"title\": \"Documentation...en, and when, and when,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 64.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.05it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 35.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.81it/s]\n","Ref_row:64 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.23it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.14it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 31.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.33it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 42.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.41it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.52it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.29it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.09it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.12it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:54:09 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1796 [type=json_invalid, input_value='{\"title\": \"What was the ...h production record was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 38.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.50it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.69it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.58it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.27it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.72it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.11it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.74it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 45.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.46it/s]\n","Ref_row:65 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 28.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.53it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.24it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.07it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.68it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 43.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.22it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.29it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.19it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.42it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.87it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 42.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.98it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.77it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.85it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:55:13 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1251 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...e error corrected?  Why', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 82.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.64it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 36.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.54it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 24.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.55it/s]\n","Ref_row:65 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.99it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.61it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.90it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:55:46 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1249 [type=json_invalid, input_value='{\"title\": \"What was the ... the human error?  What', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 31.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.98it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.00it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.43it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.24it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.70it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.66it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:56:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 484 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...discovery) 2025-01-15 1', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.37it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.07it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.98it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 55.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.17it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.32it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.12it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.45it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:57:02 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1095 [type=json_invalid, input_value='{\"title\": \"What was the ...ch manufacturing record', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 64.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.31it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.88it/s]\n","Ref_row:65 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 28.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 48.26it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.09it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 67.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.83it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 43.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.48it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 32.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.13it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:57:48 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1311 [type=json_invalid, input_value='{ \"title\": \"documentatio...nted or downloaded on a', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches:   0% 0/1 [00:00<?, ?it/s]Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 42.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.73it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.38it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.07it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.82it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.48it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.58it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.62it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 36.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.92it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 29.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.27it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.90it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 55.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.15it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.07it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 30.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.42it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.17it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.99it/s]\n","Ref_row:66 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.04it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.44it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 32.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.41it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.04it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:59:09 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1064 [type=json_invalid, input_value='{ \"title\": \"Report on pH...dition of the acid/base', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 60.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.22it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 68.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.70it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 43.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.14it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.22it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.70it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.09it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 42.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.17it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 00:59:49 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1343 [type=json_invalid, input_value='{ \"title\": \"Report on pH....  The deviation report', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 56.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.84it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 71.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.91it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 43.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.80it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.97it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.74it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.79it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.66it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 27.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.17it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:00:52 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1298 [type=json_invalid, input_value='{\"title\": \"What was the ...e consequence?  Why was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 40.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.34it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.49it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.43it/s]\n","Ref_row:66 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.09it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.05it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:01:24 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1298 [type=json_invalid, input_value='{\"title\": \"What was the ...e consequence?  Why was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 38.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.32it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 48.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.89it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.77it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:01:57 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1491 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...r the malfunction? What', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 47.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.58it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 27.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.54it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.13it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.55it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:02:31 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1491 [type=json_invalid, input_value='{\"title\": \"What was the ...stigation, and what was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 61.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.12it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 33.75it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.28it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.44it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.88it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.13it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:03:20 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1582 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...deviation investigation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 48.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.80it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.70it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.20it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.67it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.04it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.09it/s]\n","Ref_row:66 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 48.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.68it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.83it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.39it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.35it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.73it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 54.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.29it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:04:00 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1063 [type=json_invalid, input_value='{\"title\": \"report\", \"rep...s 20250610, why: faulty', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 75.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.46it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.02it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.68it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 29.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.27it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.07it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.99it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 39.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.83it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:04:37 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 391 [type=json_invalid, input_value='{\"title\": \"What was the ...03:00-07:30, 03:00-07:3', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 83.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.37it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.93it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:05:08 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 363 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...44444444444444444444444', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.73it/s]\n","Ref_row:67 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:05:12 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1607 [type=json_invalid, input_value='{\"title\": \"What was the ... then inspected for any', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 63.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.47it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 53.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.23it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.89it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.07it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.38it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:05:59 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1571 [type=json_invalid, input_value='{ \"title\": \"Report on HV...ule, and Peter Carlson,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 37.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.48it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:06:07 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 899 [type=json_invalid, input_value='{\"title\": \"What was the ...corded at 03:00 and 07:', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 77.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.73it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:06:33 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1615 [type=json_invalid, input_value='{ \"title\": \"Report on HV...y deviation action. The', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 50.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.55it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.28it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:06:39 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1165 [type=json_invalid, input_value='{\"title\": \"What was the ...nt? The report is here.', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 33.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 52.09it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.21it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.11it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.66it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.13it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:07:11 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1520 [type=json_invalid, input_value='{ \"title\": \"Report on HV...iation was initiated by', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 21.90it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.46it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.09it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 52.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.08it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:07:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1574 [type=json_invalid, input_value='{ \"title\": \"Report on HV...ated in response to the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.14it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.91it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.33it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.38it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.89it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 50.69it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:08:25 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1714 [type=json_invalid, input_value='{ \"title\": \"Report on HV...er for further analysis', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.75it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.22it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 41.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.80it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.04it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.27it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 54.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.97it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.11it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.28it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:09:20 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1478 [type=json_invalid, input_value='{\"title\":\"Report on HVAC...o the missing scheduled', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 58.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.76it/s]\n","Ref_row:67 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.28it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.96it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.69it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.38it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.35it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:09:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 694 [type=json_invalid, input_value='{\"title\": \"equipment cal...scovery), when: April 1', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 61.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.36it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.71it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 26.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.95it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.24it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:10:29 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1298 [type=json_invalid, input_value='{\"title\": \"equipment cal... approved recalibration', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 47.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 25.96it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.68it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.54it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.35it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:11:02 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1103 [type=json_invalid, input_value='{\"title\": \"What: Equipme...er Wong, QC Manager –', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 55.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.28it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.76it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 36.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.37it/s]\n","Ref_row:67 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.36it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 53.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.58it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 43.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.75it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 64.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.43it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:11:34 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 694 [type=json_invalid, input_value='{\"title\": \"equipment cal...scovery), when: April 1', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.31it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.59it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.08it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:12:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1821 [type=json_invalid, input_value='{ \"title\": \"Report on co...on source assessment is', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 40.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.65it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:12:23 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 694 [type=json_invalid, input_value='{\"title\": \"equipment cal...scovery), when: April 1', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 34.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.39it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.91it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:12:56 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 318 [type=json_invalid, input_value='{\"title\": \"A\", \"report\":...00000000000000000000000', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.57it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.66it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.84it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:13:05 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 504 [type=json_invalid, input_value='{ \"title\": \"Report on co...\\\\\"  \\\\\"\\\\\"  \\\\\"\\\\\"  \\\\', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 33.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.90it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.03it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.94it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.31it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 59.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.99it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.09it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.33it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.13it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.39it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.21it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 57.92it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.71it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 33.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.97it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.57it/s]\n","Ref_row:68 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.90it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 30.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 30.72it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 50.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.36it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 60.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.56it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.05it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:14:49 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1152 [type=json_invalid, input_value='{\"title\": \"Equipment Cal...port: QC Testing Report', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.31it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:14:51 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1817 [type=json_invalid, input_value='{ \"title\": \"Report on co...rce assessment is being', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 64.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.57it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.45it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.55it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 56.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.47it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 33.83it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:15:44 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1465 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...The calibration was re-', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.69it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:15:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1751 [type=json_invalid, input_value='{ \"title\": \"Report on co...n. The contamination is', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.48it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.50it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 49.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.72it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.87it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:16:17 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1269 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...n opened (Ref: DEV-2024', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.37it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.32it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.64it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:16:49 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1498 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...ration was re-evaluated', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 42.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.43it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.99it/s]\n","Ref_row:68 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 55.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.65it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.70it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:17:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1465 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...The calibration was re-', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 53.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.22it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.51it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 59.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.28it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:18:05 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1715 [type=json_invalid, input_value='{ \"title\": \"Contaminatio...tected during the batch', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 60.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.09it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:18:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1404 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ... re-calibrated, and the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.18it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.62it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:18:38 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1408 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...s re-calibrated and ret', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.53it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:18:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1641 [type=json_invalid, input_value='{ \"title\": \"Contaminatio...atch. The contamination', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.96it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.44it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:19:10 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1495 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...formed for the affected', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 47.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.25it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.88it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.23it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.65it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.84it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:19:51 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 536 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...00000000000000000000000', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.01it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.46it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.38it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.63it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.09it/s]\n","Ref_row:68 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 24.76it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 30.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 29.32it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.98it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 57.18it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 48.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.17it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.90it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 55.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.91it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:20:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 451 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo... (when) 2024-02-20 22:1', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 59.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.95it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:21:20 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 491 [type=json_invalid, input_value='{\"title\":\"Documentation ...621579 Batch No. 250621', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 32.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.06it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:21:27 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 381 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo... 2024-0239 2024-0239 20', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.18it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.87it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.74it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.09it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.61it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 66.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.91it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 36.17it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 43.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 27.00it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.76it/s]\n","Ref_row:69 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 39.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.15it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 57.42it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.97it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.68it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.89it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.79it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 54.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.26it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.75it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.93it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.30it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.95it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 41.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 50.99it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 28.30it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.16it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.68it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 35.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 28.27it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:23:03 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 392 [type=json_invalid, input_value='{\"title\": \"Failure of St...02-39, 2024-02-40, 2024', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.47it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.09it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.29it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.04it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:23:41 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 710 [type=json_invalid, input_value='{\"title\": \"Failure of St...scovery), when: May 20,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 61.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.93it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.35it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.26it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:23:50 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1409 [type=json_invalid, input_value='{ \"title\": \"Report on Ba...ction: Correct document', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 119.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.21it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.68it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.69it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 25.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.35it/s]\n","Ref_row:69 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.68it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.43it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.27it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:24:28 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 856 [type=json_invalid, input_value='{ \"title\": \"Accurate Des...still). Batch 818288 is', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.65it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.51it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:24:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1217 [type=json_invalid, input_value='{\"title\": \"Failure of st...ed; the autoclave cycle', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.00it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.46it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.80it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.50it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.42it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.70it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.32it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.25it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.66it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.58it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.61it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.78it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 36.30it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.93it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 35.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.98it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.96it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 45.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 29.94it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.07it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.07it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.86it/s]\n","Ref_row:69 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:27:01 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 647 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ....0.2.3: ERROR: [5000000', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.31it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:27:09 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1358 [type=json_invalid, input_value='{ \"title\": \"Documentatio... the fact that the same', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.90it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 26.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 34.88it/s]\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.25it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.90it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 73.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.81it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 36.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.41it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.35it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.07it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:27:46 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1469 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...erator retraining? What', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.76it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:28:13 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1562 [type=json_invalid, input_value='{ \"title\": \"Report on Te...gation was initiated to', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.48it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:28:18 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1226 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...appened.  What happened', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.93it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:28:47 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 757 [type=json_invalid, input_value='{\"title\":\"Temperature ex... Cooler 3 2025-02-10-03', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 70.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.50it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:28:53 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1248 [type=json_invalid, input_value='{\"title\": \"What happened...ed, and why it happened', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 36.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.98it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.44it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.23it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 30.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.30it/s]\n","Ref_row:70 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.16it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:29:29 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 920 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...d why, and why, and why', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.69it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.70it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 53.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.99it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:30:00 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1526 [type=json_invalid, input_value='{ \"title\": \"Report on Te...g system malfunctioning', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.99it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:30:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1803 [type=json_invalid, input_value='{\"title\": \"What was the ... training, the operator', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 40.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 57.38it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:30:36 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1435 [type=json_invalid, input_value='{ \"title\": \"Report on Te...M-89A. The material was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 87.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.79it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:30:54 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1418 [type=json_invalid, input_value='{\"title\": \"What was the ... document?  How was the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.37it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.26it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.10it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:31:30 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1539 [type=json_invalid, input_value='{\"title\": \"What was the ...omaly detected; anomaly', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.25it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:31:33 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1587 [type=json_invalid, input_value='{ \"title\": \"Report on Te...t further contamination', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 118.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.12it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.35it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 94.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.44it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.28it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:32:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1600 [type=json_invalid, input_value='{ \"title\": \"Report on Te...ontingency actions. The', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 48.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.11it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.95it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:32:19 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1394 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...gency actions should be', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 85.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.86it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.83it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.18it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.24it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 46.97it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:32:47 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1638 [type=json_invalid, input_value='{ \"title\": \"Report on Te...leted and the deviation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.24it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.28it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:33:13 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 489 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...overy) 2024-06-05 07:30', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 49.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.06it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.92it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.86it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.00it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:33:53 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1166 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...ining? 21. What was the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.15it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.42it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.16it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:33:58 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 593 [type=json_invalid, input_value='{ \"title\": \"Report on Te...\\\"\\\\\"\\\\\"  \\\\\"\\\\\"\\\\\"\\\\\" ', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.93it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.01it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.17it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 30.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.88it/s]\n","Ref_row:70 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.27it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.35it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 30.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.28it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.38it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.73it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.95it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 31.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.75it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.62it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 34.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.39it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.56it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 32.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.30it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:35:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 812 [type=json_invalid, input_value='{ \"title\": \"Data\" ,\"repo...$  $$$$  $$$$  $$$$  $$', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.98it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.22it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.98it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.68it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.00it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 36.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 30.88it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.89it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.56it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.83it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.71it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:36:53 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 2064 [type=json_invalid, input_value='{\"title\": \"What was the ...n stopped. The operator', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 53.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.01it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.54it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.91it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:37:27 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1510 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo... was the reason for the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 64.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.21it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.41it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.87it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.43it/s]\n","Ref_row:70 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 52.79it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 32.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.93it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.33it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:38:09 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 601 [type=json_invalid, input_value='{\"title\": \"Report on the...T_HYDRATE_IN_DETECTION_', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.77it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.05it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.06it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 42.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.27it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 28.41it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.85it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.42it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:38:53 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1332 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...scription?  Description', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.48it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 29.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.98it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.18it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.98it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:39:35 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1496 [type=json_invalid, input_value='{\"title\": \"What was the ...customer notification? ', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 83.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.03it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:39:46 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1557 [type=json_invalid, input_value='{ \"title\": \"Report on Eq...lts showed no deviation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 80.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.79it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.30it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:40:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 472 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...5:50 (discovery) 2024-0', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.86it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 50.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.74it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 28.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.20it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.53it/s]\n","Ref_row:71 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:40:40 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1475 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...ason for the reason for', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 61.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.69it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.41it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 46.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.37it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 24.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 48.62it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.24it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.27it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.79it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 48.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.44it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.55it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.94it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:41:31 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1829 [type=json_invalid, input_value='{ \"title\": \"Report on Eq...deviation investigation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.26it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.37it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.79it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.14it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.12it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:42:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1563 [type=json_invalid, input_value='{ \"title\": \"Report on Eq...retested. The deviation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 42.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.36it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.01it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.16it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:42:40 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1779 [type=json_invalid, input_value='{ \"title\": \"Report on Eq...ation investigation was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 63.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.18it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:42:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1461 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...ver. The correction was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.92it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.98it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:43:14 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1644 [type=json_invalid, input_value='{ \"title\": \"Report on Eq... was found to be minor.', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 77.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.30it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.81it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.66it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 52.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 52.03it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 48.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 52.67it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.69it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:43:49 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1202 [type=json_invalid, input_value='{ \"title\": \"Report on Eq... 3, 2024. The deviation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 111.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.48it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.96it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.36it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.15it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.42it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 81.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.58it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:44:27 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1421 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...e HVAC failure caused a', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 51.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.15it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:44:31 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1627 [type=json_invalid, input_value='{ \"title\": \"Report on Eq...tion in the QC process,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.72it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.06it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.18it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 34.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.68it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 59.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.06it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:45:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1510 [type=json_invalid, input_value='{ \"title\": \"Report on Eq...tigation to investigate', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 73.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.32it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:45:17 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 387 [type=json_invalid, input_value='{\"title\": \"What: unexpec...0 20:00 20:00 20:00 20:', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.33it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.70it/s]\n","Ref_row:71 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.55it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.32it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.95it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.87it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:46:16 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1380 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...he cause of the failure', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 47.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.83it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.52it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.21it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:46:29 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1581 [type=json_invalid, input_value='{ \"title\": \"Calibration ... results reviewed, test', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 61.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.02it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.32it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.12it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.68it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:47:04 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 667 [type=json_invalid, input_value='{\"title\": \"Unexpected Fa...024 at 03:00 (discovery', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 82.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.33it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.43it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.17it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:47:28 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1581 [type=json_invalid, input_value='{ \"title\": \"Calibration ... results reviewed, test', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.32it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 39.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.83it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:47:48 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1167 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...task? What was the goal', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.97it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.79it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 91.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.97it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 52.79it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.55it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.04it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.51it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:48:37 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1403 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...f the temperature spike', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.34it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 59.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.70it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.25it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 42.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 46.00it/s]\n","Ref_row:71 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:49:10 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1541 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...aulty thermostat, which', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 55.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.97it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.42it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 54.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.13it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.00it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.07it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.44it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:49:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1602 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...le from the chamber and', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 61.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.75it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.43it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.87it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:50:29 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1453 [type=json_invalid, input_value='{ \"title\": \"Report on Fa...or malfunctioned during', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 52.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.41it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:50:37 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1520 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...e temperature deviation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 70.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.63it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:51:01 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 512 [type=json_invalid, input_value='{ \"title\": \"Report on Fa...\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 38.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.43it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:51:09 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1406 [type=json_invalid, input_value='{\"title\": \"Unexpected fa...is, Study Lead, and Dr.', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.25it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.32it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.84it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.20it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:51:51 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1541 [type=json_invalid, input_value='{ \"title\": \"Report: Fail...tive action to be taken', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.34it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:51:57 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1408 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...ntified as the cause of', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 73.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.79it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.47it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.62it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 43.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.61it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.85it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 33.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.83it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.73it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:52:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 321 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...00000000000000000-00000', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 119.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.29it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.10it/s]\n","Ref_row:72 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 34.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.19it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.02it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 55.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.82it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:53:19 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 842 [type=json_invalid, input_value='{\"title\": \"What was the ... RM-VT203? What was the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 47.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.32it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.36it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.37it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 23.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 34.58it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:53:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1338 [type=json_invalid, input_value='{ \"title\": \"Report on Fa...e batch was quarantined', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.46it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.79it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 53.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 24.37it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 22.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 28.44it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.48it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.59it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.17it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:54:37 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1508 [type=json_invalid, input_value='{ \"title\": \"Report on Fa...on was initiated by the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 72.00it/s]\n","Batches:   0% 0/1 [00:00<?, ?it/s]08/20/2025 01:54:38 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1467 [type=json_invalid, input_value='{\"title\": \"What was the ...eviation investigation?', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 58.56it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 36.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 26.34it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:55:10 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1599 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...lier notification? What', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 56.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.32it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:55:11 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1491 [type=json_invalid, input_value='{ \"title\": \"Report on Fa.... The report is concise', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.28it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.81it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.07it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 23.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 36.81it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.05it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.59it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 52.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.01it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.04it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 65.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.30it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.82it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:55:59 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1373 [type=json_invalid, input_value='{ \"title\": \"Report of th...this case, please paste', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.36it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.82it/s]\n","Ref_row:72 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.56it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:56:33 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 529 [type=json_invalid, input_value='{\"title\": \"Report on the...10:30 (Discovery), when', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.73it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.09it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.74it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.54it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.12it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.53it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.82it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.07it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.38it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.22it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.83it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 33.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.24it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.95it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.65it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.29it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.04it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 54.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.20it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.70it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.61it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:58:26 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 721 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...</br>  </br>  </br>  </', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.79it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 59.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.16it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.57it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 31.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.05it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.34it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.36it/s]\n","Ref_row:72 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 54.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.57it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 86.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.18it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 01:59:18 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1424 [type=json_invalid, input_value='{\"title\": \"Not correct, ...h will go through. They', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 36.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.43it/s]\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 34.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 30.63it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.95it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 49.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.28it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.76it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:00:02 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1337 [type=json_invalid, input_value='{ \"title\": \"Report on De...\\'s name and the reason', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 44.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.97it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:00:04 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 574 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...t 13:15 (Discovery) 202', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.46it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.54it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.55it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.75it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 41.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.43it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.52it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.76it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.47it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 67.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.23it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 55.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.04it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.40it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:01:01 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 323 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...4000%; 4100%; 4200%; 43', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 41.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.74it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.80it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:01:24 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1487 [type=json_invalid, input_value='{ \"title\": \"Report on As...e taken. An Operator is', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 63.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.80it/s]\n","Ref_row:73 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.97it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:01:36 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1747 [type=json_invalid, input_value='{\"title\": \"Sample miside...ted labeling procedures', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.00it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.75it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.98it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.24it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 26.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.14it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.47it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.40it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 32.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.15it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.37it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.85it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 70.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.68it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.60it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.85it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 66.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.91it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:02:44 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1482 [type=json_invalid, input_value='{\"title\": \"What was the ...he labeling procedures.', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 80.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.17it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.79it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.51it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.22it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.58it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.92it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.24it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.48it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.74it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.10it/s]\n","Ref_row:73 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.46it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.44it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.70it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:03:52 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1413 [type=json_invalid, input_value='{\"title\": \"Sample Miside...mistake in the labeling', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.01it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.12it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.91it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.67it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:04:25 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1216 [type=json_invalid, input_value='{\"title\":\"Sample misiden...rective measures; Other', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 64.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.52it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.11it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.25it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.00it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 37.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 42.62it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.62it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 36.73it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.16it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.73it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:05:35 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1350 [type=json_invalid, input_value='{ \"title\": \"Deviation in...ic Processing Suite G A', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.78it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 50.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.73it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.70it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.08it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.52it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.40it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 50.49it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 26.83it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.95it/s]\n","Ref_row:73 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.70it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.70it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.46it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.67it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 48.03it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.78it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.79it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.98it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 28.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 48.73it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.41it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.15it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.68it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.15it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.28it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 36.98it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.02it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.84it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.08it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:07:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 733 [type=json_invalid, input_value='{\"title\": \"What is the s...* * * * * * * * * * * *', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 52.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 46.47it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.74it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.69it/s]\n","Ref_row:74 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:07:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 952 [type=json_invalid, input_value='{\"title\": \"What was the ... lost? 21.  Why was the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 83.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.79it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 27.81it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.31it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.58it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 41.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.16it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.01it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.28it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.97it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.22it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.55it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.36it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.25it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.59it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.13it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.66it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 29.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.09it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:08:49 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1404 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...t was not deviated from', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 32.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 29.40it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.79it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.71it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.48it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 39.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.55it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 46.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.19it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 53.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.35it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.73it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:09:29 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1402 [type=json_invalid, input_value='{ \"title\": \"Report on th...nitiated. 18. Deviation', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.42it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 35.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.69it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.44it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.85it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.70it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:10:03 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1456 [type=json_invalid, input_value='{ \"title\": \"Report on mi...aking corrective action', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.87it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.26it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 48.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.22it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.90it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.47it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.78it/s]\n","Ref_row:74 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.80it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.47it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:10:50 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 485 [type=json_invalid, input_value='{\"title\": \"Failed to rec...58158158158158158158158', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.74it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.52it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.15it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.37it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.60it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 32.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.92it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 45.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.96it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.83it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.45it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.71it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.94it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 45.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 48.51it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.42it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.70it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:11:49 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1737 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...upervisor\\'s supervisor', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.43it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.69it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.60it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.78it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:12:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 430 [type=json_invalid, input_value='{\"title\": \"What\", \"repor...-07-19 20:00:00.000.000', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 76.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.72it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.09it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.45it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.83it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.79it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.44it/s]\n","Ref_row:74 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 67.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.58it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:13:00 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 879 [type=json_invalid, input_value='{\"title\": \"The cleanup r...when, when, when, when,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 55.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.48it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 56.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.88it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.49it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:13:07 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1521 [type=json_invalid, input_value='{ \"title\": \"Report on un...ility impact assessment', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 81.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.93it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.30it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.13it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.05it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.68it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.77it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.02it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.77it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:13:40 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1455 [type=json_invalid, input_value='{ \"title\": \"Report on un...s from the chamber, log', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 26.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.51it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.16it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.17it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 89.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.84it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.31it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.12it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:14:16 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1614 [type=json_invalid, input_value='{ \"title\": \"Report on Un...iation was initiated as', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 73.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 29.61it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 49.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.34it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.07it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.66it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:14:39 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1802 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...ation investigation was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 58.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.05it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:15:02 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 658 [type=json_invalid, input_value='{ \"title\": \"Report on un...\\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\\\', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.12it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.65it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 46.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 36.94it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:15:13 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 528 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ....S.B. (Ref: DEV-2024-03', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.88it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.25it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 80.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.96it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.99it/s]\n","Ref_row:75 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:15:56 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1583 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...rminated. The batch was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.75it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:15:57 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 809 [type=json_invalid, input_value='{\"title\": \"Detailed Repo...\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.51it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 49.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.45it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:16:31 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1448 [type=json_invalid, input_value='{ \"title\": \"Report on un... the initial assessment', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 63.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.09it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:16:38 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1935 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...tion was initiated. The', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.06it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:17:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1452 [type=json_invalid, input_value='{ \"title\": \"Report on un...as a result of a faulty', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.91it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 31.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.65it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:17:11 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 590 [type=json_invalid, input_value='{\"title\": \"Wrong tablet ...-03-19; 2024-03-19; 202', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 74.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.26it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 54.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.00it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.97it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.17it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.52it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:17:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1538 [type=json_invalid, input_value='{ \"title\": \"Report on un...actions are as follows:', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 41.44it/s]\n","Batches: 100% 1/1 [00:00<00:00, 29.57it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.74it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:18:16 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 891 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...tion?  Action?  Action?', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 63.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.24it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.95it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:18:48 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 891 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...tion?  Action?  Action?', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.92it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:19:07 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1546 [type=json_invalid, input_value='{ \"title\": \"Report on un... Technician, during the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.36it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.87it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:19:20 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1161 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo... report?  Action report', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.18it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.62it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:19:54 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 891 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...tion?  Action?  Action?', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.98it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:19:56 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 617 [type=json_invalid, input_value='{ \"title\": \"Report on un...\" \\\\\"\\\\\"\\\\\"\\\\\" \\\\\"\\\\\"\\\\', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.83it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 61.06it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.57it/s]\n","Ref_row:75 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 67.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.42it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 49.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 33.84it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 52.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.60it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:20:35 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1205 [type=json_invalid, input_value='{\"title\":\"What was the a...ging Line, Action: Oper', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 40.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 46.26it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.86it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.81it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:21:08 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1156 [type=json_invalid, input_value='{\"title\": \"What was the ...use of the spillage was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.93it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:21:32 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1690 [type=json_invalid, input_value='{ \"title\": \"Detailed rep...he deviation was logged', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 25.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 26.97it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:21:40 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 360 [type=json_invalid, input_value='{\"title\": \"Accidental Sp...00000000000000000000000', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 48.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.71it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.98it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.76it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.65it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.42it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.27it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.05it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.90it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.98it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.31it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.05it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.56it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.82it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.90it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:23:02 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 576 [type=json_invalid, input_value='{\"title\": \"What?\", \"repo...port filed) 2024-08-03 ', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.26it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 50.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.00it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.70it/s]\n","Ref_row:75 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.80it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.48it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.29it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.35it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.65it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:23:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 974 [type=json_invalid, input_value='{ \"title\": \"Description ...osis\\' }, { \\'fieldCode', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 64.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.96it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.27it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 34.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.33it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 76.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.81it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.97it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.10it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 55.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.31it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.61it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:24:29 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 366 [type=json_invalid, input_value='{\"title\":\"Report\",\"repor...MZ-10JY-PMZ-10JY-PMZ-10', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.92it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.43it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.49it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.64it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.23it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.69it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 39.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.39it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.05it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 31.32it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.83it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.14it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.54it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.17it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 27.06it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.65it/s]\n","Ref_row:76 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.96it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.53it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 44.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.88it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.70it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.08it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.15it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.44it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 42.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 35.99it/s]\n","***** Starting statistical analyisis for the experiment_id=HuggingFaceTB-SmolLM2-135M-Instruct-19-082025_16-19-07 ***** \n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-mean-HuggingFaceTB-SmolLM2-135M-Instruct-19-082025_16-19-07.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_A-HuggingFaceTB-SmolLM2-135M-Instruct-19-082025_16-19-07.xlsx\n","08/20/2025 02:26:21 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1441 [type=json_invalid, input_value='{ \"title\": \"Report on th... given in one paragraph', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 34.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 58.44it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_B-HuggingFaceTB-SmolLM2-135M-Instruct-19-082025_16-19-07.xlsx\n","Batches: 100% 1/1 [00:00<00:00, 60.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.48it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 27.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.25it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_C-HuggingFaceTB-SmolLM2-135M-Instruct-19-082025_16-19-07.xlsx\n","reportParamGridSearch time --- 609.7248634417851 minutes ---\n","Batches: 100% 1/1 [00:00<00:00, 77.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.81it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.07it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:26:58 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1149 [type=json_invalid, input_value='{ \"title\": \"Report on ev...y, contingency actions?', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 62.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.89it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.67it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:27:16 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 611 [type=json_invalid, input_value='{ \"title\": \"Report on ev...\\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\\\\"\\\\', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 114.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.71it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.64it/s]\n","Ref_row:76 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.73it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.23it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 89.34it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 104.18it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.63it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 106.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.70it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.49it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.82it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.04it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.01it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 95.87it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.28it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.44it/s]\n","Ref_row:76 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.25it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:29:11 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 462 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...15. 13:15. 13:15. 13:15', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 130.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.50it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.53it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.73it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 73.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.44it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:29:51 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 462 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...15. 13:15. 13:15. 13:15', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 111.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.35it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 118.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.05it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.80it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:30:13 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1482 [type=json_invalid, input_value='{ \"title\": \"Report on Mi... the sample was sent to', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 81.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.99it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.60it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.46it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.73it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.47it/s]\n","Ref_row:77 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 77.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.04it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:31:12 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1399 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...misidentification.  The', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 127.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.31it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:31:31 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1049 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...mple was retested again', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 108.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.32it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:31:50 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1244 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...mple was actually CTX-3', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 120.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.34it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.02it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:32:20 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1491 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...th a different organism', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 124.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.21it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.02it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:32:42 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1347 [type=json_invalid, input_value='{ \"title\": \"Report on Mi...mple was actually CTX-3', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 118.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.83it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.30it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.25it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 59.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.36it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.79it/s]\n","Ref_row:77 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.68it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.75it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.62it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.34it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.15it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.00it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.14it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.54it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 60.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.62it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.32it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.25it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.86it/s]\n","Ref_row:77 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 99.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 105.61it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 116.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.31it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 117.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.97it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.56it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 113.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.17it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.34it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.99it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:35:04 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1241 [type=json_invalid, input_value='{ \"title\": \"Report on Da... on March 30, 2024. The', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 90.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.72it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 118.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.04it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.37it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.23it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.92it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.15it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.34it/s]\n","Ref_row:78 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 113.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.37it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:35:54 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1580 [type=json_invalid, input_value='{ \"title\": \"Report on Da...essful and the data was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 103.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 109.63it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:36:13 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1469 [type=json_invalid, input_value='{ \"title\": \"Report on Da...ion started. The report', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 78.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.30it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:36:32 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1380 [type=json_invalid, input_value='{ \"title\": \"Report on Da... working to implement a', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 117.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.97it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:36:51 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1410 [type=json_invalid, input_value='{ \"title\": \"Report on Da... is well-structured and', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 92.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.53it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 110.76it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.02it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:37:26 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 995 [type=json_invalid, input_value='{ \"title\": \"Report on th... and Dev team, QA team,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 113.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.81it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 128.31it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 110.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 98.60it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.44it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:37:54 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 527 [type=json_invalid, input_value='{ \"title\": \"Report for t... <br>  <br>  <br>  <br>', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 112.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.62it/s]\n","Ref_row:78 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.01it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 92.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.32it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 59.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.28it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.52it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.59it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.24it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 116.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.46it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 107.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.12it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.35it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.29it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.53it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.57it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.99it/s]\n","Ref_row:78 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.64it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.38it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.24it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.79it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.40it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.67it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.09it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.50it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 94.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.96it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 106.12it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.22it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.85it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.31it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 112.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.55it/s]\n","Ref_row:79 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.97it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.06it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 123.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.19it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 129.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.92it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 96.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.79it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 79.76it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:40:04 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1222 [type=json_invalid, input_value='{ \"title\": \"Report gener...ided in the event is as', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 121.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.95it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:40:22 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1482 [type=json_invalid, input_value='{ \"title\": \"Report on MQ...tion was conducted, and', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 125.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.43it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 125.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.80it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 130.15it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.41it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 131.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 125.54it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.17it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.62it/s]\n","Ref_row:79 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.73it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.85it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:41:00 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1829 [type=json_invalid, input_value='{ \"title\": \"Cleaning pro... and revised to include', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 116.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.31it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.24it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:41:27 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1412 [type=json_invalid, input_value='{ \"title\": \"Detailed rep...ng was performed by the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 123.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.99it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.57it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 113.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 114.78it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.58it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.20it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:41:59 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1255 [type=json_invalid, input_value='{ \"title\": \"Wrong cleani..., cleaning SOP updated,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 118.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.04it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.94it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.20it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.25it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 121.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.64it/s]\n","Ref_row:79 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.91it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 93.10it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 102.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.42it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.56it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.13it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 109.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.93it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:42:57 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1508 [type=json_invalid, input_value='{ \"title\": \"Report on Au...sue. The report is also', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 118.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.86it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.17it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.34it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 122.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 116.70it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:43:27 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1268 [type=json_invalid, input_value='{ \"title\": \"Report on th...for you. I will provide', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 118.85it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.82it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.99it/s]\n","Ref_row:80 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 91.78it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.30it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.39it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.47it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.85it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 78.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.55it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.81it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.36it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/20/2025 02:44:17 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1286 [type=json_invalid, input_value='{ \"title\": \"Report for A...ored during the cleanup', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 98.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 99.58it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.62it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.05it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 118.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.28it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 80.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.83it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 103.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.28it/s]\n","Ref_row:80 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 104.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 102.54it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.28it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 108.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.91it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 128.87it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.37it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 120.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.47it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 105.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.98it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 115.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.58it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 119.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 118.42it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.83it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.77it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 117.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.01it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 111.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.40it/s]\n","Ref_row:80 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 114.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.89it/s]\n","***** Starting statistical analyisis for the experiment_id=HuggingFaceTB-SmolLM2-360M-Instruct-19-082025_16-19-13 ***** \n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-mean-HuggingFaceTB-SmolLM2-360M-Instruct-19-082025_16-19-13.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_A-HuggingFaceTB-SmolLM2-360M-Instruct-19-082025_16-19-13.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_B-HuggingFaceTB-SmolLM2-360M-Instruct-19-082025_16-19-13.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_C-HuggingFaceTB-SmolLM2-360M-Instruct-19-082025_16-19-13.xlsx\n","reportParamGridSearch time --- 630.0947401245435 minutes ---\n"]}]},{"cell_type":"markdown","source":["## Qwen/Qwen2.5-0.5B-Instruct"],"metadata":{"id":"F2m43xRsHKlW"}},{"cell_type":"code","source":["!python app/reportParamGridSearch.py --model_id Qwen/Qwen2.5-0.5B-Instruct --non-threaded --max_workers  4 --prompt_method B C --dataset_filename pharma_dev_reports_collection.xlsx --start_idx 1 --end_idx 2  --temperature 0.7 1.3 --top_p 0.3 0.9 --top_k 50 --max_new_tokens 300 --do_sample True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awksT-7GOYkm","executionInfo":{"status":"ok","timestamp":1755615472782,"user_tz":-120,"elapsed":166748,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"162e6922-ad9c-40ab-e6ee-0eafd363c962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-08-19 14:55:13.273844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1755615313.308470   23223 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1755615313.320179   23223 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1755615313.348724   23223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1755615313.348754   23223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1755615313.348761   23223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1755615313.348768   23223 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Parameters passed to main script: \n","{'max_workers': [4], 'threaded': False, 'model_id': ['Qwen/Qwen2.5-0.5B-Instruct'], 'prompt_method': ['B', 'C'], 'dataset_filename': 'pharma_dev_reports_collection.xlsx', 'start_idx': [1], 'end_idx': [2], 'temperature': [0.7, 1.3], 'top_p': [0.3, 0.9], 'top_k': [50], 'max_new_tokens': [300.0], 'do_sample': [True]}\n","08/19/2025 14:55:34 - mods.modelLoader - WARNING - No attribute frequency_penalty found in GenerationConfig, for model_id=Qwen/Qwen2.5-0.5B-Instruct\n","08/19/2025 14:55:34 - mods.modelLoader - WARNING - No attribute presence_penalty found in GenerationConfig, for model_id=Qwen/Qwen2.5-0.5B-Instruct\n","08/19/2025 14:55:34 - mods.modelLoader - WARNING - No attribute stop found in GenerationConfig, for model_id=Qwen/Qwen2.5-0.5B-Instruct\n","Generation parameters: \n","{'temperature': [0.7, 1.3], 'top_p': [0.3, 0.9], 'top_k': [50], 'max_new_tokens': [300.0], 'do_sample': [True]}\n","Results file is expected to have 16 rows.\n","******* Starting GRID SEARCH ***********\n","******* Starting NOT THREADED PROCESS ************\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 65.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 115.33it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 117.37it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.24it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 100.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 126.94it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 107.33it/s]\n","Batches: 100% 1/1 [00:00<00:00, 111.10it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 114.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.02it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 119.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.10it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 107.30it/s]\n","Batches: 100% 1/1 [00:00<00:00, 108.51it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 110.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 112.11it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 116.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.61it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 69.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.84it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 42.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.07it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 120.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 121.63it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 105.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 124.96it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 114.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 120.72it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 78.03it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.54it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.1}\n","Batches: 100% 1/1 [00:00<00:00, 108.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 119.63it/s]\n","***** Starting statistical analyisis for the experiment_id=Qwen-Qwen2.5-0.5B-Instruct-19-082025_14-55-37 ***** \n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-mean-Qwen-Qwen2.5-0.5B-Instruct-19-082025_14-55-37.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_B-Qwen-Qwen2.5-0.5B-Instruct-19-082025_14-55-37.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_C-Qwen-Qwen2.5-0.5B-Instruct-19-082025_14-55-37.xlsx\n","reportParamGridSearch time --- 2.5005958318710326 minutes ---\n"]}]},{"cell_type":"code","source":["# KILL SESSION TO AVOID LEAVING SESSION ON AND CONSUME GPU UNITS\n","\n","from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"54e-108TIfvA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training SmolLM2-360M-Instruct\n"],"metadata":{"id":"6JPNWTIgSq91"}},{"cell_type":"markdown","source":["## Importing and treating Excel Dataset"],"metadata":{"id":"Sdkl-q9gSw6c"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/GitHub/{repo}\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOMBMTzQjewb","executionInfo":{"status":"ok","timestamp":1756129102809,"user_tz":-120,"elapsed":167,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"71ae095a-b140-4495-a981-635ac7a1b275"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GitHub/reportingAgent\n","/content/drive/MyDrive/GitHub/reportingAgent\n"]}]},{"cell_type":"code","source":["!pip -q install pandas openpyxl"],"metadata":{"id":"QKrfg07FTsGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert Excel -> train/eval datasets for one-paragraph report SFT\n","# Requirements: pandas, openpyxl\n","# In Colab: !pip -q install pandas openpyxl\n","\n","import pandas as pd, re, json, os\n","from sklearn.model_selection import train_test_split\n","\n","# === user settings ===\n","excel_path = \"app/datasets/training/training_traffic_accident_reports.xlsx\"     # <-- put your file name here\n","sheet_name = \"TRAFFIC_ACCIDENT\"                  # or \"Sheet1\"\n","max_chars = 700                 # target paragraph limit\n","train_frac = 0.9\n","random_state = 42\n","out_dir = \"app/datasets/training\"\n","os.makedirs(out_dir, exist_ok=True)\n","\n","# Map flexible headers to canonical keys (lower-case, no spaces)\n","colmap = {\n","    \"what\": \"what\",\n","    \"when\": \"when\",\n","    \"where\": \"where\",\n","    \"who\":  \"who\",\n","    \"how\":  \"how\",\n","    \"why\":  \"why\",\n","    \"contingencyactions\": \"contingency_actions\",\n","    \"contingency actions\": \"contingency_actions\",\n","    \"report\": \"reference_report\",\n","    \"reference_report\": \"reference_report\",\n","}\n","\n","def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n","    new_cols = {}\n","    for c in df.columns:\n","        key = re.sub(r\"\\s+\", \" \", str(c)).strip().lower()\n","        key_nospace = key.replace(\" \", \"\")\n","        # # Handle duplicate \"what\" -> treat the *second* as \"who\" if there's no \"who\"\n","        # if key in (\"what\",):\n","        #     if \"what\" not in new_cols.values():\n","        #         new_cols[c] = \"what\"\n","        #     elif \"who\" not in new_cols.values():\n","        #         new_cols[c] = \"who\"\n","        #     else:\n","        #         new_cols[c] = \"what_extra\"\n","        #     continue\n","        # General mapping\n","        if key in colmap:\n","            new_cols[c] = colmap[key]\n","        elif key_nospace in colmap:\n","            new_cols[c] = colmap[key_nospace]\n","        else:\n","            new_cols[c] = key_nospace  # keep something sensible\n","    return df.rename(columns=new_cols)\n","\n","def one_line(s: str) -> str:\n","    if pd.isna(s): s = \"\"\n","    s = str(s).replace(\"\\n\", \" \")\n","    s = re.sub(r\"\\s+\", \" \", s).strip()\n","    return s\n","\n","# def soft_clip(s: str, max_chars: int) -> str:\n","#     if len(s) <= max_chars: return s\n","#     clipped = s[:max_chars]\n","#     # end at last sentence boundary if possible\n","#     end = max(clipped.rfind(\".\"), clipped.rfind(\"!\"), clipped.rfind(\"?\"))\n","#     return clipped[:end+1] if end > 50 else clipped\n","\n","def build_input(row: dict) -> str:\n","    # Compact 5W1H list — this is what your Colab tester expects as input\n","    parts = []\n","    if row.get(\"what\"): parts.append(f\"What: {row['what']}\")\n","    if row.get(\"when\"): parts.append(f\"When: {row['when']}\")\n","    if row.get(\"where\"): parts.append(f\"Where: {row['where']}\")\n","    if row.get(\"who\"): parts.append(f\"Who: {row['who']}\")\n","    if row.get(\"how\"): parts.append(f\"How: {row['how']}\")\n","    if row.get(\"why\"): parts.append(f\"Why: {row['why']}\")\n","    if row.get(\"contingency_actions\"): parts.append(f\"ContingencyActions: {row['contingency_actions']}\")\n","    return \"\\n\".join(parts)\n","\n","# --- Load & normalize ---\n","df = pd.read_excel(excel_path, sheet_name=sheet_name)\n","df = normalize_columns(df)\n","\n","# Keep only the columns we care about; fill missing\n","needed = [\"what\",\"when\",\"where\",\"who\",\"how\",\"why\",\"contingency_actions\",\"reference_report\"]\n","for k in needed:\n","    if k not in df.columns:\n","        df[k] = \"\"\n","df = df[needed].fillna(\"\")\n","\n","# Build input/target\n","records = []\n","too_long = 0\n","empty_targets = 0\n","for _, r in df.iterrows():\n","    row = {k: one_line(r[k]) for k in needed}\n","    inp = build_input(row)\n","    tgt = one_line(row[\"reference_report\"])\n","\n","    # if not tgt:\n","    #     # If reference report missing, assemble a fallback paragraph from fields (optional)\n","    #     tgt_parts = []\n","    #     if row[\"when\"]:  tgt_parts.append(row[\"when\"])\n","    #     if row[\"where\"]: tgt_parts.append(f\"in {row['where']}\")\n","    #     if row[\"who\"]:   tgt_parts.append(f\"{row['who']} \")\n","    #     if row[\"what\"]:  tgt_parts.append(f\"{row['what']}\")\n","    #     if row[\"how\"]:   tgt_parts.append(f\"using/with: {row['how']}\")\n","    #     if row[\"why\"]:   tgt_parts.append(f\"Root cause: {row['why']}.\")\n","    #     if row[\"contingency_actions\"]:\n","    #         tgt_parts.append(f\"Actions: {row['contingency_actions']}.\")\n","    #     tgt = one_line(\" \".join(tgt_parts))\n","    #     empty_targets += 1\n","\n","    # tgt = soft_clip(tgt, max_chars)\n","    if len(tgt) > max_chars: too_long += 1\n","\n","    records.append({\"input\": inp, \"target\": tgt})\n","\n","print(f\"Rows prepared: {len(records)}\")\n","# print(f\"Targets synthesized (missing reference report): {empty_targets}\")\n","print(f\"Targets still >{max_chars} chars after soft clip: {too_long}\")\n","\n","# Split train/eval\n","train_recs, eval_recs = train_test_split(records, test_size=1-train_frac, random_state=random_state)\n","\n","train_recs = records\n","\n","# Save JSON (array) and JSONL\n","def to_json(path, data):\n","    with open(path, \"w\", encoding=\"utf-8\") as f: json.dump(data, f, ensure_ascii=False, indent=2)\n","\n","def to_jsonl(path, data):\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        for d in data:\n","            f.write(json.dumps(d, ensure_ascii=False) + \"\\n\")\n","\n","to_json(os.path.join(out_dir, \"train.json\"), train_recs)\n","to_json(os.path.join(out_dir, \"eval.json\"),  eval_recs)\n","to_jsonl(os.path.join(out_dir, \"train.jsonl\"), train_recs)\n","to_jsonl(os.path.join(out_dir, \"eval.jsonl\"),  eval_recs)\n","\n","print(\"Wrote:\",\n","      os.path.join(out_dir, \"train.json\"),\n","      os.path.join(out_dir, \"eval.json\"),\n","      os.path.join(out_dir, \"train.jsonl\"),\n","      os.path.join(out_dir, \"eval.jsonl\"),\n","      sep=\"\\n - \")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3s5kibRSy-F","executionInfo":{"status":"ok","timestamp":1756118992483,"user_tz":-120,"elapsed":4525,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"0c2164ef-9253-4fb1-ea42-bbbff1b1c8bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Rows prepared: 699\n","Targets still >700 chars after soft clip: 0\n","Wrote:\n"," - app/datasets/training/train.json\n"," - app/datasets/training/eval.json\n"," - app/datasets/training/train.jsonl\n"," - app/datasets/training/eval.jsonl\n"]}]},{"cell_type":"markdown","source":["## Training from formatted jsonl output"],"metadata":{"id":"6zKLlvE2Szh4"}},{"cell_type":"code","source":["!pip -q install -U \"transformers>=4.43\" \"accelerate>=0.33\" \"datasets>=2.20\" \\\n","  \"trl>=0.9.6\" peft bitsandbytes evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YuyEHSLVri01","executionInfo":{"status":"ok","timestamp":1756118969688,"user_tz":-120,"elapsed":17172,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"89d1abc5-b45b-4776-e369-a9121f000eba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip -q install wandb"],"metadata":{"id":"tFUuTTkBFERL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === ONE-CELL QLoRA TRAINER: SmolLM2-360M-Instruct with trl.SFTConfig (no char clipping) ===\n","# Colab tip: Runtime -> Change runtime type -> GPU (T4)\n","\n","!pip -q install -U \"transformers>=4.43\" \"accelerate>=0.33\" \"datasets>=2.20\" \\\n","  \"trl>=0.9.6\" peft bitsandbytes\n","\n","import os, re, json, torch\n","from datasets import load_dataset\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import LoraConfig\n","from trl import SFTTrainer, SFTConfig\n","\n","MODEL_ID = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n","TRAINING_DIR = \"app/datasets/training\"\n","OUT_DIR  = TRAINING_DIR + \"/smollm2_360m_onepara_lora\"\n","\n","# 4-bit QLoRA base (tiny VRAM/RAM footprint)\n","bnb = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n","if tok.pad_token_id is None:\n","    tok.pad_token = tok.eos_token\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_ID,\n","    quantization_config=bnb,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n",")\n","model.config.use_cache = False  # needed for grad checkpointing\n","\n","# LoRA config (light but effective for ~500 rows)\n","peft_cfg = LoraConfig(\n","    r=8, lora_alpha=16, lora_dropout=0.05,\n","    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","ds = load_dataset(\"json\", data_files={\"train\":TRAINING_DIR+\"train.jsonl\",\"eval\":TRAINING_DIR+\"eval.jsonl\"})\n","\n","print(f\"DS_1: {ds}\")\n","\n","\n","def one_line(s: str) -> str:\n","    s = str(s).replace(\"\\n\",\" \")\n","    return re.sub(r\"\\s+\",\" \", s).strip()\n","\n","INSTR = (\n","  \"Write ONE SINGLE PARAGRAPH in English that includes ALL given facts: what happened, when, where, who, how, why \"\n","  \"(root cause), and contingency/corrective actions. Neutral tone. No bullet points, no headings, no lists, no JSON. \"\n","  \"DO NOT invent details. Output must be a single line (no line breaks).\"\n",")\n","RESP_TMPL = \"### Response:\\n\"  # SFTTrainer will mask everything before this marker as prompt\n","MAX_LEN = 1024\n","\n","def find_subsequence(xs: list[int], ys: list[int]) -> int:\n","    \"\"\"Return start index of ys inside xs, or -1 if not found.\"\"\"\n","    n, m = len(xs), len(ys)\n","    if m == 0 or m > n: return -1\n","    for i in range(n - m + 1):\n","        if xs[i:i+m] == ys:\n","            return i\n","    return -1\n","\n","def tokenize_and_mask(example: dict) -> dict:\n","    # Build full prompt -> \"### Instruction ... INPUT ... ### Response:\\n + target\"\n","    text_in  = one_line(example[\"input\"])\n","    text_out = one_line(example[\"target\"])\n","    full = f\"### Instruction:\\n{INSTR}\\n\\nINPUT:\\n{text_in}\\n\\n{RESP_TMPL}{text_out}\"\n","\n","    enc = tok(\n","        full,\n","        truncation=True,\n","        max_length=MAX_LEN,\n","        padding=False,             # pad later in collator\n","        return_tensors=None\n","    )\n","    input_ids = enc[\"input_ids\"]\n","    labels    = input_ids.copy()\n","\n","    # Locate response template and mask everything before the end of it\n","    rt_ids = tok(RESP_TMPL, add_special_tokens=False)[\"input_ids\"]\n","    start = find_subsequence(input_ids, rt_ids)\n","    if start == -1:\n","        # If marker not found (rare after truncation), skip supervision on whole sample\n","        labels[:] = [-100] * len(labels)\n","    else:\n","        # Mask up to the end of the template tokens\n","        cut = start + len(rt_ids)\n","        labels[:cut] = [-100] * cut\n","\n","    return {\n","        \"input_ids\": input_ids,\n","        \"attention_mask\": enc[\"attention_mask\"],\n","        \"labels\": labels\n","    }\n","\n","ds_tok = ds.map(tokenize_and_mask, remove_columns=ds[\"train\"].column_names, desc=\"Tokenizing & masking\")\n","\n","print(f\"DS_2: {ds_tok}\")\n","\n","ds_tok = ds_tok.remove_columns([c for c in ds_tok[\"train\"].column_names\n","                                if c not in (\"input_ids\",\"attention_mask\",\"labels\")])\n","\n","# Make sure the dataset yields torch tensors with those keys\n","ds_tok.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n","print(f\"DS_3: {ds_tok}\")\n","\n","# Simple collator: pad inputs and labels to max length in batch\n","class CausalLMPadCollator:\n","    def __init__(self, tokenizer, label_pad_id=-100):\n","        self.tok = tokenizer\n","        self.label_pad_id = label_pad_id\n","\n","    def __call__(self, features: list[dict]) -> dict[str, torch.Tensor]:\n","        max_len = max(len(f[\"input_ids\"]) for f in features)\n","        input_ids, attn, labels = [], [], []\n","        for f in features:\n","            pad = max_len - len(f[\"input_ids\"])\n","            input_ids.append(f[\"input_ids\"] + [self.tok.pad_token_id] * pad)\n","            attn.append(f[\"attention_mask\"] + [0] * pad)\n","            labels.append(f[\"labels\"] + [self.label_pad_id] * pad)\n","        return {\n","            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n","            \"attention_mask\": torch.tensor(attn, dtype=torch.long),\n","            \"labels\": torch.tensor(labels, dtype=torch.long),\n","        }\n","\n","collator = CausalLMPadCollator(tok)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yd8qW0laSvS8","executionInfo":{"status":"ok","timestamp":1756125220440,"user_tz":-120,"elapsed":19044,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"8d39f3cb-6f29-4b53-9d16-43060a69d4f5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["DS_1: DatasetDict({\n","    train: Dataset({\n","        features: ['input', 'target'],\n","        num_rows: 699\n","    })\n","    eval: Dataset({\n","        features: ['input', 'target'],\n","        num_rows: 70\n","    })\n","})\n","DS_2: DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 699\n","    })\n","    eval: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 70\n","    })\n","})\n","DS_3: DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 699\n","    })\n","    eval: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 70\n","    })\n","})\n"]}]},{"cell_type":"code","source":["!pip -q install wandb"],"metadata":{"id":"6Hyk7naoE_V7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","\n","import wandb\n","IS_WANDB = False\n","if IS_WANDB:\n","  os.environ[\"WANDB_PROJECT\"] = \"accident-reporter\"\n","  os.environ[\"WANDB_WATCH\"] = \"false\"          # don't auto-log gradients\n","  os.environ[\"WANDB_SILENT\"] = \"true\"\n","  from google.colab import userdata\n","  wand_db_token = userdata.get('wandb_token')\n","  wandb.login(key=wand_db_token)  # paste token (or set WANDB_API_KEY env var)\n","else:\n","  os.environ[\"WANDB_DISABLED\"] = \"true\"\n"],"metadata":{"id":"urxJazHIFBhO","executionInfo":{"status":"ok","timestamp":1756125224638,"user_tz":-120,"elapsed":45,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# --- SFTConfig (replaces TrainingArguments) ---\n","sft_cfg = SFTConfig(\n","    output_dir=OUT_DIR,\n","    num_train_epochs=2,                       # 2 epochs is plenty for ~500 rows\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=16,           # eff batch ~= 64\n","    gradient_checkpointing=False,             #Turn off checkpointing (needs a bit more VRAM on T4, but SmolLM2-360M QLoRA usually fits):\n","    learning_rate=1.5e-4,\n","    lr_scheduler_type=\"cosine\",\n","    warmup_ratio=0.03,\n","    logging_steps=10,\n","    eval_strategy=\"steps\",\n","    eval_steps=100,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    save_total_limit=2,\n","    fp16=True,                                # T4-friendly\n","    optim=\"paged_adamw_8bit\",\n","    max_grad_norm=0.5,\n","    max_length =MAX_LEN,                      # handled by SFTTrainer when set here\n","    # dataset_text_field=\"text\", # Removed as data is already tokenized\n","    packing=False,\n","    remove_unused_columns=False,           # important for pre-tokenized inputs\n","    report_to=\"none\"  # wandb\n",")\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=sft_cfg,                             # <-- using SFTConfig\n","    train_dataset=ds_tok[\"train\"], # Use the tokenized dataset\n","    eval_dataset=ds_tok[\"eval\"],   # Use the tokenized dataset\n","    data_collator = collator,\n","    peft_config=peft_cfg,\n",")\n","trainer.train()\n","\n","# Save LoRA adapter\n","adapter_dir = f\"{OUT_DIR}/adapter\"\n","trainer.model.save_pretrained(adapter_dir)\n","tok.save_pretrained(adapter_dir)\n","print(\"Saved LoRA adapter to:\", adapter_dir)\n","\n","# ---------------------- Inference (no char clipping) ----------------------\n","@torch.no_grad()\n","def build_infer_prompt(user_text: str) -> str:\n","    return \"### Instruction:\\n\" + INSTR + \"\\n\\nINPUT:\\n\" + one_line(user_text) + f\"\\n\\n{RESP_TMPL}\"\n","\n","@torch.no_grad()\n","def generate_one_paragraph(user_text: str, max_new_tokens: int = 220,\n","                           temperature: float = 0.0, top_p: float = 1.0) -> str:\n","    prompt = build_infer_prompt(user_text)\n","    ids = tok(prompt, return_tensors=\"pt\").to(trainer.model.device)\n","    out = trainer.model.generate(\n","        **ids,\n","        max_new_tokens=max_new_tokens,\n","        do_sample=(temperature>0),\n","        temperature=temperature,\n","        top_p=top_p,\n","        eos_token_id=tok.eos_token_id\n","    )\n","    gen = tok.decode(out[0], skip_special_tokens=True).split(RESP_TMPL, 1)[-1]\n","    return one_line(gen)  # single line, but no length clipping\n","\n","# Quick check on a couple eval samples\n","eval_split = load_dataset(\"json\", data_files={\"eval\":TRAINING_DIR+\"eval.jsonl\"})[\"eval\"] # Load from the correct directory\n","for i in range(min(3, len(eval_split))):\n","    print(\"-\", generate_one_paragraph(eval_split[i][\"input\"]))\n","\n","# Log metrics in wandb\n","# wandb.log({\n","#   \"eval/paragraphness\": no_breaks / N,      # % with no '\\n'\n","#   \"eval/<=400_chars\": within_len / N,\n","#   \"eval/slot_coverage\": slot_cov,           # if you compute it\n","# })\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"zohBF398ATP2","executionInfo":{"status":"ok","timestamp":1756125592358,"user_tz":-120,"elapsed":347349,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"a44f733d-8cf3-4e31-db60-ab4e2893c810"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [22/22 03:45, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]},{"output_type":"stream","name":"stdout","text":["Saved LoRA adapter to: app/datasets/training/smollm2_360m_onepara_lora/adapter\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["- On June 1, 2024, at 13:38, Vehicle A (taxi) and Vehicle B (bus) collided on Market Street near River Plaza. The collision occurred when Vehicle A began to change lanes parallel to Vehicle B, resulting in scraping sides. Passengers checked, police and company supervisors notified. ### Explanation: The incident occurred on Market Street near River Plaza, involving Vehicle A (taxi) and Vehicle B (bus). The collision occurred when Vehicle A began to change lanes parallel to Vehicle B, resulting in scraping sides. Passengers checked, police and company supervisors notified. ### Question: What was the cause of the collision? ### Answer: The cause of the collision was the collision between Vehicle A (taxi) and Vehicle B (bus) on Market Street near River Plaza. Passengers checked, police and company supervisors notified. ### Explanation: The incident occurred on Market Street near River Plaza, involving Vehicle A (taxi) and Vehicle B (bus). The collision occurred when\n"]},{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["- Mr. Paul Evans, a sedan, failed to brake in time at red light behind SUV, Ms. Linda Harper, a SUV, moved off road, no serious injuries, and ambulance checked both drivers ### Explanation: The accident occurred at the intersection of Main Street and 4th Avenue on March 14, 2024, at 08:12. Both vehicles, a sedan (Vehicle A) and a SUV (Vehicle B), failed to brake in time at the red light. The sedan, Mr. Evans, was involved in the accident, while Ms. Harper was in the SUV. Both drivers were taken to the hospital for treatment. The accident was neutralized by police on scene and both vehicles moved off the road. No serious injuries were sustained, and an ambulance was dispatched to the scene. ### Additional Information: The accident was caused by driver inattention, specifically by the sedan, which failed to brake in time at the red light. The SUV, Ms. Harper,\n","- On October 16, 2024, at 20:17, taxi Mr. Alex Sampaio and vehicle Ms. Elise Bauer collided in the Riverside Roundabout. Both drivers were involved in the accident. Police clarified roles, documented damage, and maintained traffic. ### Explanation: The accident occurred on the Riverside Roundabout in October 2024, at 20:17. Both drivers, Ms. Elise Bauer and Mr. Alex Sampaio, were involved in the collision. Police clarified roles, documented damage, and maintained traffic. ### Additional Information: The accident was reported to the police and the damage was documented. The accident was not reported to the media. ### Question: What was the cause of the collision? ### Answer: The cause of the collision was the failure of the traffic signal in the Riverside Roundabout. ### Explanation: The traffic signal in the Riverside Roundabout was malfunctioning, causing the traffic to stop. This caused the\n"]}]},{"cell_type":"markdown","source":["## Push the trained model to HF\n","We want to push the new adapter as a merged model, into the base model to HF)"],"metadata":{"id":"wTSr-5FoIK0s"}},{"cell_type":"code","source":["from peft import PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","BASE_ID = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n","TRAINED_MODEL_DIR = TRAINING_DIR + \"/smollm2_accident_reporter_merged\" # 1 paragraph specialized model\n","tok = AutoTokenizer.from_pretrained(BASE_ID, use_fast=True)\n","base = AutoModelForCausalLM.from_pretrained(BASE_ID, torch_dtype=\"auto\", device_map=\"auto\")\n","# Merge the base model with the trained one and push to HF\n","merged = PeftModel.from_pretrained(base, OUT_DIR + \"/adapter\").merge_and_unload()\n","merged.save_pretrained(TRAINED_MODEL_DIR); tok.save_pretrained(TRAINED_MODEL_DIR)\n"],"metadata":{"id":"R44XB5rEIKkq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756127115081,"user_tz":-120,"elapsed":6806,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"924da1d0-0e8c-4ba8-b071-76b71a1b0455"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('app/datasets/training//smollm2_accident_reporter_merged/tokenizer_config.json',\n"," 'app/datasets/training//smollm2_accident_reporter_merged/special_tokens_map.json',\n"," 'app/datasets/training//smollm2_accident_reporter_merged/chat_template.jinja',\n"," 'app/datasets/training//smollm2_accident_reporter_merged/vocab.json',\n"," 'app/datasets/training//smollm2_accident_reporter_merged/merges.txt',\n"," 'app/datasets/training//smollm2_accident_reporter_merged/added_tokens.json',\n"," 'app/datasets/training//smollm2_accident_reporter_merged/tokenizer.json')"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Be sure the base model’s license allows redistribution (SmolLM2 is Apache-2.0). Then:\n"],"metadata":{"id":"Pj42J1TLJaDO"}},{"cell_type":"code","source":["TRAINED_MODEL_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aWpzxYX6dgz-","executionInfo":{"status":"ok","timestamp":1756129267995,"user_tz":-120,"elapsed":55,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"76055632-de49-4b7b-b4e7-796a5e488274"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'app/datasets/training/smollm2_accident_reporter_merged'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["from huggingface_hub import HfApi, create_repo, upload_folder, login\n","repo_id = \"zBotta/smollm2-accident-reporter-360m\"\n","from google.colab import userdata\n","hf_token = userdata.get('hf_token')\n","\n","login(token=hf_token)\n","\n","api = HfApi(token=hf_token)\n","# api.create_repo(repo_id, private=False, repo_type=\"model\")\n","upload_folder(folder_path=TRAINED_MODEL_DIR, repo_id=repo_id, repo_type=\"model\")\n","print(\"Pushed:\", repo_id)"],"metadata":{"id":"vOBJxE7vJXpK","colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["18c19d669c4f49f6b8bd22ccf8336596","c17e2bc8b4a54a86a4a832cdffb77bef","e03ead8593b34b0fb5cc6dea29bd24ed","afd5e57dbb314634af555c20dd557e2c","c1aa6e0633f24df38f70587a2c19a669","f854478b7b704eb48e18e1012316aeb7","8be9d2bde5384971829c9d4235bf69ad","2bf2d71ca57848e2bfbcea88235cc02e","6831fbc76a7044e38c1266b9abe01d9d","36eb45d08dfd4f3abc0d31b09411a417","7a942e473b7c4189a5065825ddb50fe3","36fa8dd002a5448c9c310c60eb411c0a","40613beeefbe4b81a6897942b5727b44","666c794759b54469a0c21e01901c70da","57ac790166714428ae6385e7dc9c83e0","63afc55e213d4ed08bbb9e57963691c2","cd4d3fb25cc74c878bca6591aad77179","0047c645a37b42eea8be831b6d0a8501","bd3abb8a24e44fc3bff54dc9053d93c6","e86b5dd9b47249ca84cd32b434e243c4","4b9d31d52efa4dfcb8bcfb19a2cbf379","99fe8d365406433d9294d2ca218d8111","10ddc72219644195b53a5bffdae9ca0e","36e6f2b784464f57a84ea47c1de0b462","a8c181ad1d7c42ee947146c09781d6c5","657c7fe1cd694e6f86ac40d928a55a66","ea3834b055654687bc81087baf64f3ee","33a9feae5e334f6db6e7f82da5c0d4ca","3b5f0e74637542918dddad28dcf30294","640099882a55480ba4ee986912660ad4","385986716a1c4e2c9244a24f69adda46","cb3b2d23af3746069df784974b15a9ee","0e02d13a39db47adb644a189c18efb89"]},"executionInfo":{"status":"ok","timestamp":1756129711619,"user_tz":-120,"elapsed":34984,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"2b02a867-452d-4563-abb4-f9954ed7d3e3"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":["Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c19d669c4f49f6b8bd22ccf8336596"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["New Data Upload                         : |          |  0.00B /  0.00B            "],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36fa8dd002a5448c9c310c60eb411c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  ...t_reporter_merged/model.safetensors:   2%|2         | 16.7MB /  724MB            "],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ddc72219644195b53a5bffdae9ca0e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Pushed: zBotta/smollm2-accident-reporter-360m\n"]}]},{"cell_type":"markdown","source":["# Grid Search on trained model"],"metadata":{"id":"JF2rrRz-hGGD"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from google.colab import userdata\n","github_token = userdata.get('zbotta_token')\n","\n","token = github_token\n","username = \"zbotta\"\n","repo = 'reportingAgent'\n","%cd /content/drive/MyDrive/GitHub/{repo}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLG_KdJXo3tW","executionInfo":{"status":"ok","timestamp":1756132409969,"user_tz":-120,"elapsed":2679,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"a1162d2f-d891-4150-cdd3-6d454e0b3496"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/GitHub/reportingAgent\n"]}]},{"cell_type":"code","source":["!pip install -r requirements_colab.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3n-gjEoh8ur","executionInfo":{"status":"ok","timestamp":1756132254591,"user_tz":-120,"elapsed":52492,"user":{"displayName":"Mati Bottarini","userId":"12309550559523072958"}},"outputId":"c9b4c93c-d656-401e-9230-92564ba59106"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: absl-py~=1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 1)) (1.4.0)\n","Requirement already satisfied: aiohappyeyeballs~=2.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 2)) (2.6.1)\n","Requirement already satisfied: aiohttp~=3.12.15 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 3)) (3.12.15)\n","Requirement already satisfied: aiosignal~=1.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 4)) (1.4.0)\n","Requirement already satisfied: annotated-types~=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 5)) (0.7.0)\n","Requirement already satisfied: anyio~=4.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 6)) (4.10.0)\n","Requirement already satisfied: attrs~=25.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 7)) (25.3.0)\n","Requirement already satisfied: audioread~=3.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 8)) (3.0.1)\n","Collecting bert-score~=0.3.13 (from -r requirements_colab.txt (line 9))\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: certifi~=2025.8.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 10)) (2025.8.3)\n","Requirement already satisfied: charset-normalizer~=3.4.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 11)) (3.4.3)\n","Requirement already satisfied: click~=8.2.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 12)) (8.2.1)\n","Requirement already satisfied: cloudpickle~=3.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 13)) (3.1.1)\n","Collecting colorama~=0.4.6 (from -r requirements_colab.txt (line 14))\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: contourpy~=1.3.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 15)) (1.3.3)\n","Requirement already satisfied: cycler~=0.12.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 16)) (0.12.1)\n","Requirement already satisfied: datasets~=4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 17)) (4.0.0)\n","Requirement already satisfied: dill~=0.3.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 18)) (0.3.8)\n","Requirement already satisfied: distributed~=2025.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 19)) (2025.5.0)\n","Collecting diskcache~=5.6.3 (from -r requirements_colab.txt (line 20))\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: distro~=1.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 21)) (1.9.0)\n","Requirement already satisfied: docstring_parser~=0.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 22)) (0.17.0)\n","Requirement already satisfied: docutils~=0.21.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 23)) (0.21.2)\n","Collecting dotenv~=0.9.9 (from -r requirements_colab.txt (line 24))\n","  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n","Requirement already satisfied: et_xmlfile~=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 25)) (2.0.0)\n","Collecting evaluate~=0.4.5 (from -r requirements_colab.txt (line 26))\n","  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: Farama-Notifications~=0.0.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 27)) (0.0.4)\n","Requirement already satisfied: fastapi~=0.116.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 28)) (0.116.1)\n","Collecting filelock~=3.18.0 (from -r requirements_colab.txt (line 29))\n","  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: fonttools~=4.59.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 30)) (4.59.1)\n","Requirement already satisfied: frozenlist~=1.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 31)) (1.7.0)\n","Requirement already satisfied: fsspec~=2025.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 32)) (2025.3.0)\n","Collecting genson~=1.3.0 (from -r requirements_colab.txt (line 33))\n","  Downloading genson-1.3.0-py3-none-any.whl.metadata (28 kB)\n","Collecting groq~=0.26.0 (from -r requirements_colab.txt (line 34))\n","  Downloading groq-0.26.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: h11~=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 35)) (0.16.0)\n","Requirement already satisfied: httpcore~=1.0.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 36)) (1.0.9)\n","Requirement already satisfied: httpx~=0.28.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 37)) (0.28.1)\n","Requirement already satisfied: huggingface-hub~=0.34.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 38)) (0.34.4)\n","Requirement already satisfied: idna~=3.10 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 39)) (3.10)\n","Requirement already satisfied: iniconfig~=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 40)) (2.1.0)\n","Collecting instructor~=1.10.0 (from -r requirements_colab.txt (line 41))\n","  Downloading instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n","Collecting interegular~=0.3.3 (from -r requirements_colab.txt (line 42))\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Collecting iso3166~=2.1.1 (from -r requirements_colab.txt (line 43))\n","  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: Jinja2~=3.1.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 44)) (3.1.6)\n","Requirement already satisfied: jiter~=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 45)) (0.10.0)\n","Requirement already satisfied: joblib~=1.5.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 46)) (1.5.1)\n","Collecting jsonpath-ng~=1.7.0 (from -r requirements_colab.txt (line 47))\n","  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: jsonpickle~=4.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 48)) (4.1.1)\n","Requirement already satisfied: jsonpointer~=3.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 49)) (3.0.0)\n","Requirement already satisfied: jsonschema~=4.25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 50)) (4.25.1)\n","Requirement already satisfied: jsonschema-specifications~=2025.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 51)) (2025.4.1)\n","Requirement already satisfied: kiwisolver~=1.4.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 52)) (1.4.9)\n","Collecting lark~=1.2.2 (from -r requirements_colab.txt (line 53))\n","  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: markdown-it-py~=4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 54)) (4.0.0)\n","Requirement already satisfied: MarkupSafe~=3.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 55)) (3.0.2)\n","Requirement already satisfied: matplotlib~=3.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 56)) (3.10.0)\n","Requirement already satisfied: mdurl~=0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 57)) (0.1.2)\n","Requirement already satisfied: mpmath~=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 58)) (1.3.0)\n","Requirement already satisfied: multidict~=6.6.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 59)) (6.6.4)\n","Requirement already satisfied: multiprocess~=0.70.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 60)) (0.70.16)\n","Requirement already satisfied: nest-asyncio~=1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 61)) (1.6.0)\n","Requirement already satisfied: networkx~=3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 62)) (3.5)\n","Requirement already satisfied: nltk~=3.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 63)) (3.9.1)\n","Requirement already satisfied: numpy~=2.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 64)) (2.0.2)\n","Collecting openai~=1.99.9 (from -r requirements_colab.txt (line 65))\n","  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: openpyxl~=3.1.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 66)) (3.1.5)\n","Collecting outlines~=1.1.1 (from -r requirements_colab.txt (line 67))\n","  Downloading outlines-1.1.1-py3-none-any.whl.metadata (27 kB)\n","Collecting outlines_core~=0.1.26 (from -r requirements_colab.txt (line 68))\n","  Downloading outlines_core-0.1.27-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: packaging~=25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 69)) (25.0)\n","Requirement already satisfied: pandas~=2.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 70)) (2.2.2)\n","Requirement already satisfied: pillow~=11.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 71)) (11.3.0)\n","Requirement already satisfied: pluggy~=1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 72)) (1.6.0)\n","Requirement already satisfied: ply~=3.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 73)) (3.11)\n","Requirement already satisfied: propcache~=0.3.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 74)) (0.3.2)\n","Requirement already satisfied: pyarrow~=18.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 75)) (18.1.0)\n","Requirement already satisfied: pydantic~=2.11.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 76)) (2.11.7)\n","Requirement already satisfied: pydantic_core~=2.33.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 77)) (2.33.2)\n","Requirement already satisfied: Pygments~=2.19.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 78)) (2.19.2)\n","Requirement already satisfied: pyparsing~=3.2.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 79)) (3.2.3)\n","Requirement already satisfied: pytest~=8.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 80)) (8.4.1)\n","Requirement already satisfied: python-dateutil~=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 81)) (2.9.0.post0)\n","Requirement already satisfied: python-louvain~=0.16 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 82)) (0.16)\n","Requirement already satisfied: python-dotenv~=1.1.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 83)) (1.1.1)\n","Requirement already satisfied: pytz~=2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 84)) (2025.2)\n","Requirement already satisfied: PyYAML~=6.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 85)) (6.0.2)\n","Requirement already satisfied: referencing~=0.36.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 86)) (0.36.2)\n","Requirement already satisfied: regex~=2024.11.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 87)) (2024.11.6)\n","Collecting reportlab>=3.6 (from -r requirements_colab.txt (line 88))\n","  Downloading reportlab-4.4.3-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: requests~=2.32.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 89)) (2.32.4)\n","Requirement already satisfied: rich~=13.9.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 90)) (13.9.4)\n","Collecting rouge_score~=0.1.2 (from -r requirements_colab.txt (line 91))\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: rpds-py~=0.27.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 92)) (0.27.0)\n","Requirement already satisfied: safetensors~=0.6.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 93)) (0.6.2)\n","Requirement already satisfied: scikit-learn~=1.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 94)) (1.6.1)\n","Requirement already satisfied: scipy~=1.16.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 95)) (1.16.1)\n","Requirement already satisfied: sentence-transformers~=5.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 96)) (5.1.0)\n","Requirement already satisfied: shellingham~=1.5.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 97)) (1.5.4)\n","Requirement already satisfied: six~=1.17.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 98)) (1.17.0)\n","Requirement already satisfied: sniffio~=1.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 99)) (1.3.1)\n","Requirement already satisfied: starlette~=0.47.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 100)) (0.47.2)\n","Collecting streamlit>=1.35 (from -r requirements_colab.txt (line 101))\n","  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n","Collecting streamlit-extras>=0.4.0 (from -r requirements_colab.txt (line 102))\n","  Downloading streamlit_extras-0.7.6-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: sympy~=1.13.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 103)) (1.13.3)\n","Collecting tenacity~=9.1.2 (from -r requirements_colab.txt (line 104))\n","  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: threadpoolctl~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 105)) (3.6.0)\n","Requirement already satisfied: tokenizers~=0.21.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 106)) (0.21.4)\n","Requirement already satisfied: torch~=2.8 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 107)) (2.8.0+cu126)\n","Requirement already satisfied: tqdm~=4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 108)) (4.67.1)\n","Collecting transformers~=4.53.3 (from -r requirements_colab.txt (line 109))\n","  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer~=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 110)) (0.16.0)\n","Requirement already satisfied: typing-inspection~=0.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 111)) (0.4.1)\n","Requirement already satisfied: typing_extensions~=4.14.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 112)) (4.14.1)\n","Requirement already satisfied: tzdata~=2025.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 113)) (2025.2)\n","Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 114)) (2.5.0)\n","Requirement already satisfied: xxhash~=3.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 115)) (3.5.0)\n","Requirement already satisfied: yarl~=1.20.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements_colab.txt (line 116)) (1.20.1)\n","Requirement already satisfied: dask==2025.5.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (2025.5.0)\n","Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (1.1.1)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (5.9.5)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (2.4.0)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (3.1.0)\n","Requirement already satisfied: toolz>=0.11.2 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (0.12.1)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (6.4.2)\n","Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (3.0.0)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask==2025.5.0->distributed~=2025.5.0->-r requirements_colab.txt (line 19)) (1.4.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub~=0.34.4->-r requirements_colab.txt (line 38)) (1.1.7)\n","Collecting airportsdata (from outlines~=1.1.1->-r requirements_colab.txt (line 67))\n","  Downloading airportsdata-20250811-py3-none-any.whl.metadata (9.1 kB)\n","Collecting outlines_core~=0.1.26 (from -r requirements_colab.txt (line 68))\n","  Downloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.5.2)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.29.5)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (0.10.2)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.35->-r requirements_colab.txt (line 101)) (3.1.45)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit>=1.35->-r requirements_colab.txt (line 101))\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Collecting altex>=0.2.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading altex-0.2.0-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: entrypoints>=0.4 in /usr/local/lib/python3.12/dist-packages (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (0.4)\n","Collecting htbuilder>=0.6.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading htbuilder-0.9.0.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting markdownlit>=0.0.7 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading markdownlit-0.0.7-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: plotly>=5.23.0 in /usr/local/lib/python3.12/dist-packages (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (5.24.1)\n","Requirement already satisfied: prometheus-client>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (0.22.1)\n","Collecting snowflake-snowpark-python>=1.30.0 (from snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading snowflake_snowpark_python-1.37.0-py3-none-any.whl.metadata (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting st-annotated-text>=4.0.1 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading st_annotated_text-4.0.2-py3-none-any.whl.metadata (2.4 kB)\n","Collecting st-theme>=1.2.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading st_theme-1.2.3-py3-none-any.whl.metadata (6.9 kB)\n","Collecting streamlit-avatar>=0.1.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_avatar-0.1.3-py3-none-any.whl.metadata (2.1 kB)\n","Collecting streamlit-camera-input-live>=0.2.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting streamlit-card>=1.0.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_card-1.0.2-py3-none-any.whl.metadata (4.0 kB)\n","Collecting streamlit-embedcode>=0.1.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl.metadata (414 bytes)\n","Collecting streamlit-faker>=0.0.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_faker-0.0.4-py3-none-any.whl.metadata (2.1 kB)\n","Collecting streamlit-image-coordinates>=0.1.9 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_image_coordinates-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting streamlit-keyup>=0.2.4 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_keyup-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit-notify>=0.3.1 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_notify-0.3.1-py3-none-any.whl.metadata (3.4 kB)\n","Collecting streamlit-toggle-switch>=1.0.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl.metadata (395 bytes)\n","Collecting streamlit-vertical-slider>=2.5.5 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl.metadata (2.2 kB)\n","Collecting validators>=0.33.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (75.2.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch~=2.8->-r requirements_colab.txt (line 107)) (3.4.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.35->-r requirements_colab.txt (line 101)) (2.1.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35->-r requirements_colab.txt (line 101)) (4.0.12)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (3.8.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (5.4.0)\n","Collecting favicon (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading favicon-0.7.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Collecting pymdown-extensions (from markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading pymdown_extensions-10.16.1-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from snowflake-snowpark-python>=1.30.0->snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (0.45.1)\n","Collecting snowflake-connector-python<4.0.0,>=3.14.0 (from snowflake-snowpark-python>=1.30.0->snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading snowflake_connector_python-3.17.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of snowflake-snowpark-python to determine which version is compatible with other requirements. This could take a while.\n","Collecting snowflake-snowpark-python>=1.30.0 (from snowflake-snowpark-python[pandas]>=1.30.0->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading snowflake_snowpark_python-1.36.0-py3-none-any.whl.metadata (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.35.0-py3-none-any.whl.metadata (150 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.34.0-py3-none-any.whl.metadata (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.4/148.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.33.0-py3-none-any.whl.metadata (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.32.0-py3-none-any.whl.metadata (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.31.1-py3-none-any.whl.metadata (136 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading snowflake_snowpark_python-1.31.0-py3-none-any.whl.metadata (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is still looking at multiple versions of snowflake-snowpark-python to determine which version is compatible with other requirements. This could take a while.\n","  Downloading snowflake_snowpark_python-1.30.0-py3-none-any.whl.metadata (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting streamlit-extras>=0.4.0 (from -r requirements_colab.txt (line 102))\n","  Downloading streamlit_extras-0.7.5-py3-none-any.whl.metadata (4.2 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading streamlit_extras-0.7.1-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading streamlit_extras-0.7.0-py3-none-any.whl.metadata (3.7 kB)\n","Collecting htbuilder==0.6.2 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading htbuilder-0.6.2-py3-none-any.whl.metadata (5.9 kB)\n","Collecting plotly==5.23.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading plotly-5.23.0-py3-none-any.whl.metadata (7.3 kB)\n","Collecting prometheus-client==0.20.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting protobuf<7,>=3.20 (from streamlit>=1.35->-r requirements_colab.txt (line 101))\n","  Downloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n","Collecting st-annotated-text==4.0.1 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading st_annotated_text-4.0.1-py3-none-any.whl.metadata (2.2 kB)\n","Collecting streamlit-faker==0.0.3 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_faker-0.0.3-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit-image-coordinates==0.1.9 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit-keyup==0.2.4 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading streamlit_keyup-0.2.4-py3-none-any.whl.metadata (2.0 kB)\n","Collecting streamlit>=1.35 (from -r requirements_colab.txt (line 101))\n","  Downloading streamlit-1.37.0-py2.py3-none-any.whl.metadata (8.5 kB)\n","Collecting validators==0.33.0 (from streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading validators-0.33.0-py3-none-any.whl.metadata (3.8 kB)\n","INFO: pip is looking at multiple versions of streamlit to determine which version is compatible with other requirements. This could take a while.\n","Collecting streamlit-extras>=0.4.0 (from -r requirements_colab.txt (line 102))\n","  Downloading streamlit_extras-0.6.0-py3-none-any.whl.metadata (4.0 kB)\n","Collecting faker (from streamlit-faker>=0.0.3->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102))\n","  Downloading faker-37.5.3-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.35->-r requirements_colab.txt (line 101)) (5.0.2)\n","Requirement already satisfied: beautifulsoup4>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from favicon->markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (4.13.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.7->streamlit-extras>=0.4.0->-r requirements_colab.txt (line 102)) (2.7)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n","Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n","Downloading genson-1.3.0-py3-none-any.whl (21 kB)\n","Downloading groq-0.26.0-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading instructor-1.10.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n","Downloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n","Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.99.9-py3-none-any.whl (786 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines-1.1.1-py3-none-any.whl (100 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.2/343.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading reportlab-4.4.3-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_extras-0.6.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n","Downloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n","Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading st_annotated_text-4.0.2-py3-none-any.whl (9.1 kB)\n","Downloading st_theme-1.2.3-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_avatar-0.1.3-py3-none-any.whl (779 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n","Downloading streamlit_card-1.0.2-py3-none-any.whl (680 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n","Downloading streamlit_faker-0.0.4-py3-none-any.whl (14 kB)\n","Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl (7.0 kB)\n","Downloading streamlit_keyup-0.3.0-py3-none-any.whl (7.5 kB)\n","Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit_vertical_slider-2.5.5-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading airportsdata-20250811-py3-none-any.whl (912 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading altex-0.2.0-py3-none-any.whl (25 kB)\n","Downloading faker-37.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n","Downloading pymdown_extensions-10.16.1-py3-none-any.whl (266 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: rouge_score, htbuilder\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e30ec6bd21d4ec6529f44aaefdb387a0cf0e4d044c62969ab2f9d8730040e26b\n","  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n","  Building wheel for htbuilder (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for htbuilder: filename=htbuilder-0.9.0-py3-none-any.whl size=12786 sha256=239e32b47a68c89afb3490b4904c55e112d30032e743121709490e0eeee2a5a9\n","  Stored in directory: /root/.cache/pip/wheels/e3/4e/ff/760211ab527c50cca237ac2c2458fc7614a7d15624cdceb537\n","Successfully built rouge_score htbuilder\n","Installing collected packages: genson, validators, tenacity, reportlab, pymdown-extensions, lark, jsonpath-ng, iso3166, interegular, htbuilder, filelock, faker, dotenv, diskcache, colorama, airportsdata, st-annotated-text, rouge_score, pydeck, favicon, openai, groq, transformers, outlines_core, instructor, streamlit, outlines, evaluate, bert-score, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, streamlit-avatar, st-theme, altex, streamlit-faker, markdownlit, streamlit-extras\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 8.5.0\n","    Uninstalling tenacity-8.5.0:\n","      Successfully uninstalled tenacity-8.5.0\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.19.1\n","    Uninstalling filelock-3.19.1:\n","      Successfully uninstalled filelock-3.19.1\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.100.0\n","    Uninstalling openai-1.100.0:\n","      Successfully uninstalled openai-1.100.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.55.2\n","    Uninstalling transformers-4.55.2:\n","      Successfully uninstalled transformers-4.55.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-adk 1.11.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed airportsdata-20250811 altex-0.2.0 bert-score-0.3.13 colorama-0.4.6 diskcache-5.6.3 dotenv-0.9.9 evaluate-0.4.5 faker-37.5.3 favicon-0.7.0 filelock-3.18.0 genson-1.3.0 groq-0.26.0 htbuilder-0.9.0 instructor-1.10.0 interegular-0.3.3 iso3166-2.1.1 jsonpath-ng-1.7.0 lark-1.2.2 markdownlit-0.0.7 openai-1.99.9 outlines-1.1.1 outlines_core-0.1.26 pydeck-0.9.1 pymdown-extensions-10.16.1 reportlab-4.4.3 rouge_score-0.1.2 st-annotated-text-4.0.2 st-theme-1.2.3 streamlit-1.48.1 streamlit-avatar-0.1.3 streamlit-camera-input-live-0.2.0 streamlit-card-1.0.2 streamlit-embedcode-0.1.2 streamlit-extras-0.6.0 streamlit-faker-0.0.4 streamlit-image-coordinates-0.1.9 streamlit-keyup-0.3.0 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-2.5.5 tenacity-9.1.2 transformers-4.53.3 validators-0.35.0\n"]}]},{"cell_type":"markdown","source":["Let's compare using only two lines of the Test set **traffic_accident_reports_collection.xlsx**. We are comparing:\n","-"],"metadata":{"id":"dolyKLEDh3CW"}},{"cell_type":"code","source":["!python app/reportParamGridSearch.py --model_id zBotta/smollm2-accident-reporter-360m  --non-threaded --prompt_method A B C --max_workers 4 --dataset_filename traffic_accident_reports_collection.xlsx --start_idx 1 --end_idx 80  --temperature 0.3 0.7 1.0 1.3 --top_p 0.3 0.6 0.9 --top_k 50 --max_new_tokens 300 --do_sample True & python app/reportParamGridSearch.py --model_id HuggingFaceTB/SmolLM2-360M-Instruct  --non-threaded --prompt_method A B C --max_workers 4 --dataset_filename traffic_accident_reports_collection.xlsx --start_idx 1 --end_idx 2  --temperature 0.3 0.7 1.0 1.3 --top_p 0.3 0.6 0.9 --top_k 50 --max_new_tokens 300 --do_sample True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BI_pzidchH_8","outputId":"2d241678-2322-4cd8-935d-f62bd1f25b4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-08-25 15:14:44.748350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1756134884.805916   13054 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1756134884.824498   13054 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1756134884.859128   13054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1756134884.859173   13054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1756134884.859181   13054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1756134884.859187   13054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-08-25 15:14:44.866543: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-08-25 15:14:45.075174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1756134885.132140   13053 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1756134885.141895   13053 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1756134885.165895   13053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1756134885.165931   13053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1756134885.165940   13053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1756134885.165948   13053 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-08-25 15:14:45.173560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Parameters passed to main script: \n","{'max_workers': [4], 'threaded': False, 'model_id': ['zBotta/smollm2-accident-reporter-360m'], 'prompt_method': ['A', 'B', 'C'], 'dataset_filename': 'traffic_accident_reports_collection.xlsx', 'start_idx': [1], 'end_idx': [80], 'temperature': [0.3, 0.7, 1.0, 1.3], 'top_p': [0.3, 0.6, 0.9], 'top_k': [50], 'max_new_tokens': [300.0], 'do_sample': [True]}\n","Parameters passed to main script: \n","{'max_workers': [4], 'threaded': False, 'model_id': ['HuggingFaceTB/SmolLM2-360M-Instruct'], 'prompt_method': ['A', 'B', 'C'], 'dataset_filename': 'traffic_accident_reports_collection.xlsx', 'start_idx': [1], 'end_idx': [2], 'temperature': [0.3, 0.7, 1.0, 1.3], 'top_p': [0.3, 0.6, 0.9], 'top_k': [50], 'max_new_tokens': [300.0], 'do_sample': [True]}\n","08/25/2025 15:15:10 - mods.modelLoader - WARNING - No attribute frequency_penalty found in GenerationConfig, for model_id=HuggingFaceTB/SmolLM2-360M-Instruct\n","08/25/2025 15:15:10 - mods.modelLoader - WARNING - No attribute presence_penalty found in GenerationConfig, for model_id=HuggingFaceTB/SmolLM2-360M-Instruct\n","08/25/2025 15:15:10 - mods.modelLoader - WARNING - No attribute stop found in GenerationConfig, for model_id=HuggingFaceTB/SmolLM2-360M-Instruct\n","Generation parameters: \n","{'temperature': [0.3, 0.7, 1.0, 1.3], 'top_p': [0.3, 0.6, 0.9], 'top_k': [50], 'max_new_tokens': [300.0], 'do_sample': [True]}\n","08/25/2025 15:15:10 - mods.modelLoader - WARNING - No attribute frequency_penalty found in GenerationConfig, for model_id=zBotta/smollm2-accident-reporter-360m\n","08/25/2025 15:15:10 - mods.modelLoader - WARNING - No attribute presence_penalty found in GenerationConfig, for model_id=zBotta/smollm2-accident-reporter-360m\n","08/25/2025 15:15:10 - mods.modelLoader - WARNING - No attribute stop found in GenerationConfig, for model_id=zBotta/smollm2-accident-reporter-360m\n","Generation parameters: \n","{'temperature': [0.3, 0.7, 1.0, 1.3], 'top_p': [0.3, 0.6, 0.9], 'top_k': [50], 'max_new_tokens': [300.0], 'do_sample': [True]}\n","Results file is expected to have 72 rows.\n","******* Starting GRID SEARCH ***********\n","******* Starting NOT THREADED PROCESS ************\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 95.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 122.95it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Results file is expected to have 2880 rows.\n","******* Starting GRID SEARCH ***********\n","******* Starting NOT THREADED PROCESS ************\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 58.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.97it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.90it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 38.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 87.65it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 85.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.66it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 42.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.66it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 91.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 113.57it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.48it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 69.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.99it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 46.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 32.63it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.16it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:16:18 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1341 [type=json_invalid, input_value='{ \"title\": \"Report on Ve...e accident is a minivan', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 32.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 33.79it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:16:21 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1449 [type=json_invalid, input_value='{ \"title\": \"Report on Ve...wing actions were taken', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 58.04it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.19it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.11it/s]\n","Batches: 100% 1/1 [00:00<00:00, 60.13it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:16:51 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1288 [type=json_invalid, input_value='{ \"title\": \"Report on Ve...olved in the accident. ', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.45it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.31it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.42it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 83.75it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.60it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:17:24 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1252 [type=json_invalid, input_value='{ \"title\": \"Report on Ve...ndro Ruiz – crossover', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 71.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.78it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.31it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.34it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 40.74it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.75it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.10it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.12it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:18:04 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1545 [type=json_invalid, input_value='{ \"title\": \"Report on Ve...port. The vehicle A was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 67.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.90it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.10it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 66.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.15it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:18:15 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1409 [type=json_invalid, input_value='{ \"title\": \"Report on Ve... report was filed and a', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 86.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.91it/s]\n","Ref_row:1 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.54it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 37.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.37it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:18:43 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 431 [type=json_invalid, input_value='{\"title\":\"Report\",\"repor...2pm, 5:42pm, 5:42pm, 5:', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.42it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 86.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.53it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 71.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.04it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.64it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:18:55 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1314 [type=json_invalid, input_value='{ \"title\": \"Report on Ve... The incident was filed', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 43.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.79it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 79.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.67it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 70.41it/s]\n","Batches: 100% 1/1 [00:00<00:00, 101.84it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 57.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.45it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 79.65it/s]\n","Batches: 100% 1/1 [00:00<00:00, 43.34it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 50.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.93it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 21.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 30.71it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:19:42 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1443 [type=json_invalid, input_value='{ \"title\": \"Report on Ve...nt was determined to be', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 72.14it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.76it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:19:44 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1479 [type=json_invalid, input_value='{ \"title\": \"Report of Ve... clear the intersection', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 66.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.16it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.74it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.87it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.40it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.48it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 33.39it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.44it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.49it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.40it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.41it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 80.52it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:20:38 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1547 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re... The report is provided', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.64it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 63.84it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.22it/s]\n","Ref_row:1 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.99it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.77it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.34it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.02it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 76.15it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.89it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.36it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 90.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.85it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 41.69it/s]\n","Batches: 100% 1/1 [00:00<00:00, 48.05it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 38.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.66it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 85.60it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.96it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 86.73it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 63.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.53it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:22:15 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1284 [type=json_invalid, input_value='{ \"title\": \"Vehicle coll...tersection. The vehicle', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 30.83it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.40it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.02it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.51it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.21it/s]\n","Batches: 100% 1/1 [00:00<00:00, 53.13it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.55it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.77it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 57.50it/s]\n","Batches: 100% 1/1 [00:00<00:00, 54.40it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 75.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.45it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.93it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.05it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 51.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 51.63it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:23:16 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 378 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...07:55, 07:55, 07:55, 07', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 90.35it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.52it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.01it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 72.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 70.99it/s]\n","Ref_row:1 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.16it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.86it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:23:48 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 349 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...07:56, 07:56, 07:56, 07', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 89.38it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.26it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.90it/s]\n","Batches: 100% 1/1 [00:00<00:00, 83.72it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.92it/s]\n","Batches: 100% 1/1 [00:00<00:00, 55.73it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:24:40 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1464 [type=json_invalid, input_value='{ \"title\": \"Report on th...ocal police department.', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.96it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.95it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:24:42 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 372 [type=json_invalid, input_value='{\"title\":\"Three-vehicle ... 07:55, 07:56, 07:55, 0', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 68.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.18it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.28it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.68it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.96it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:25:24 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1219 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...e report was created in', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","08/25/2025 15:25:24 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 378 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re... 07:55, 07:56, 07:55, 0', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.46it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.00it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.03it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 81.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.69it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:25:57 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1535 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...escription of Injuries,', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 78.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.14it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:26:01 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 870 [type=json_invalid, input_value='{ \"title\": \"Report on th...ctions: 33. Contingency', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 27.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 41.37it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:26:31 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1412 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...dden braking by Vehicle', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 39.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 97.53it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:26:34 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 349 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...07:56, 07:56, 07:56, 07', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 56.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.38it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 66.88it/s]\n","Batches: 100% 1/1 [00:00<00:00, 91.13it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 47.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 50.90it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:27:03 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1021 [type=json_invalid, input_value='{ \"title\": \"Report on Ev...e B); Mr. Tom Novak –', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 72.10it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.18it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:27:15 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1478 [type=json_invalid, input_value='{ \"title\": \"Report on th...e incident was reported', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 80.46it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.87it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 84.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 64.26it/s]\n","Ref_row:2 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 63.81it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 39.89it/s]\n","Batches: 100% 1/1 [00:00<00:00, 38.20it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 82.05it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.71it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:28:06 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1487 [type=json_invalid, input_value='{ \"title\": \"Report on th...e incident was reported', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 42.94it/s]\n","Batches: 100% 1/1 [00:00<00:00, 45.33it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 25.97it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.13it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.23it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.46it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:29:01 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1294 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re... concise manner, and it', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.22it/s]\n","Batches: 100% 1/1 [00:00<00:00, 46.17it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:29:16 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1458 [type=json_invalid, input_value='{ \"title\": \"Report on th...urate and coherent. The', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 70.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.84it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:29:33 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1504 [type=json_invalid, input_value='{ \"title\": \"Report on th...tted to the authorities', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 57.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 49.03it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:29:50 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1401 [type=json_invalid, input_value='{ \"title\": \"Report on th... minor and the severity', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 41.32it/s]\n","Batches: 100% 1/1 [00:00<00:00, 46.12it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 84.45it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.36it/s]\n","Batches: 100% 1/1 [00:00<00:00, 65.91it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 69.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.11it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.18it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.47it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:30:39 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1215 [type=json_invalid, input_value='{ \"title\": \"Report on th...ntrol, and the accident', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 69.95it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.21it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:30:41 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1442 [type=json_invalid, input_value='{ \"title\": \"Report on th...vided. The title of the', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 86.54it/s]\n","Batches: 100% 1/1 [00:00<00:00, 81.17it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 33.56it/s]\n","Batches: 100% 1/1 [00:00<00:00, 39.69it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:31:14 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1224 [type=json_invalid, input_value='{ \"title\": \"Report on Th...d in the need for first', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 74.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 74.56it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.45it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.02it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 75.93it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 69.07it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.04it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 58.71it/s]\n","Batches: 100% 1/1 [00:00<00:00, 62.81it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:31:53 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1539 [type=json_invalid, input_value='{ \"title\": \"Report on th... accurate and coherent.', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 60.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 66.86it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.81it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.77it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 61.98it/s]\n","Batches: 100% 1/1 [00:00<00:00, 59.70it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.39it/s]\n","Ref_row:2 & prompt_method=B: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.76it/s]\n","Batches: 100% 1/1 [00:00<00:00, 78.87it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 48.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 44.00it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 74.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.78it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 65.20it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.94it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.91it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.21it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 88.72it/s]\n","Batches: 100% 1/1 [00:00<00:00, 77.63it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 62.12it/s]\n","Batches: 100% 1/1 [00:00<00:00, 71.39it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 81.99it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.92it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 66.27it/s]\n","Batches: 100% 1/1 [00:00<00:00, 73.86it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 39.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 52.49it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 67.57it/s]\n","Batches: 100% 1/1 [00:00<00:00, 94.40it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 40.19it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.57it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 55.26it/s]\n","Batches: 100% 1/1 [00:00<00:00, 40.82it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.51it/s]\n","Batches: 100% 1/1 [00:00<00:00, 72.52it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 32.63it/s]\n","Batches: 100% 1/1 [00:00<00:00, 57.52it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 41.29it/s]\n","Batches: 100% 1/1 [00:00<00:00, 47.65it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 71.01it/s]\n","Batches: 100% 1/1 [00:00<00:00, 82.99it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 70.35it/s]\n","Batches: 100% 1/1 [00:00<00:00, 56.32it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 52.25it/s]\n","Batches: 100% 1/1 [00:00<00:00, 37.88it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.24it/s]\n","Batches: 100% 1/1 [00:00<00:00, 92.57it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.13it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.29it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 64.67it/s]\n","Batches: 100% 1/1 [00:00<00:00, 68.00it/s]\n","Ref_row:2 & prompt_method=C: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 68.61it/s]\n","Batches: 100% 1/1 [00:00<00:00, 69.73it/s]\n","***** Starting statistical analyisis for the experiment_id=HuggingFaceTB-SmolLM2-360M-Instruct-25-082025_15-15-14 ***** \n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-mean-HuggingFaceTB-SmolLM2-360M-Instruct-25-082025_15-15-14.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_A-HuggingFaceTB-SmolLM2-360M-Instruct-25-082025_15-15-14.xlsx\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_B-HuggingFaceTB-SmolLM2-360M-Instruct-25-082025_15-15-14.xlsx\n","08/25/2025 15:35:04 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1420 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re... to the authorities and', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 65.70it/s]\n","Batches: 100% 1/1 [00:00<00:00, 67.64it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Saving df to excel in: /content/drive/MyDrive/GitHub/reportingAgent/app/results/analysis/an-stats-pm_C-HuggingFaceTB-SmolLM2-360M-Instruct-25-082025_15-15-14.xlsx\n","reportParamGridSearch time --- 20.19454689025879 minutes ---\n","08/25/2025 15:35:25 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1382 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re... accident was Vehicle A', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 125.42it/s]\n","Batches: 100% 1/1 [00:00<00:00, 132.94it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.3, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 74.48it/s]\n","Batches: 100% 1/1 [00:00<00:00, 85.40it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:35:45 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1448 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...artment. The report was', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 114.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 117.30it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n","Batches: 100% 1/1 [00:00<00:00, 123.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 131.19it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 0.7, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 87.06it/s]\n","Batches: 100% 1/1 [00:00<00:00, 88.03it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:36:13 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1159 [type=json_invalid, input_value='{ \"title\": \"Report\", \"re...Rita Zhang, a hatchback', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 123.62it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.39it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:36:31 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1378 [type=json_invalid, input_value='{ \"title\": \"Report on Ve...al police and emergency', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 122.43it/s]\n","Batches: 100% 1/1 [00:00<00:00, 123.38it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.0, 'top_p': 0.9, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","Batches: 100% 1/1 [00:00<00:00, 124.66it/s]\n","Batches: 100% 1/1 [00:00<00:00, 130.95it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.3, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n","08/25/2025 15:36:51 - mods.dataHandler - ERROR - Error while unpacking title or report from model output. Error: 1 validation error for Report\n","  Invalid JSON: EOF while parsing a string at line 1 column 1442 [type=json_invalid, input_value='{ \"title\": \"Report on Ve... the roundabout without', input_type=str]\n","    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n","Batches: 100% 1/1 [00:00<00:00, 116.82it/s]\n","Batches: 100% 1/1 [00:00<00:00, 127.02it/s]\n","Ref_row:3 & prompt_method=A: Generating text with the following parameters:\n","{'temperature': 1.3, 'top_p': 0.6, 'top_k': 50, 'max_new_tokens': 300.0, 'do_sample': True, 'repetition_penalty': 1.0}\n"]}]},{"cell_type":"code","source":["# KILL SESSION TO AVOID LEAVING SESSION ON AND CONSUME GPU UNITS\n","\n","from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"lfEA1XoazFKA"},"execution_count":null,"outputs":[]}]}